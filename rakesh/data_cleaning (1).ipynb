{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-kKbzqtVS4b",
        "outputId": "a5989f6a-4080-4c51-d665-9451adabab07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake Data:\n",
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
            "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...    News   \n",
            "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
            "2  On Friday, it was revealed that former Milwauk...    News   \n",
            "3  On Christmas day, Donald Trump announced that ...    News   \n",
            "4  Pope Francis used his annual Christmas Day mes...    News   \n",
            "\n",
            "                date  \n",
            "0  December 31, 2017  \n",
            "1  December 31, 2017  \n",
            "2  December 30, 2017  \n",
            "3  December 29, 2017  \n",
            "4  December 25, 2017  \n",
            "\n",
            "True Data:\n",
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
            "\n",
            "                 date  \n",
            "0  December 31, 2017   \n",
            "1  December 29, 2017   \n",
            "2  December 31, 2017   \n",
            "3  December 30, 2017   \n",
            "4  December 29, 2017   \n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "fake_data = pd.read_csv('/content/drive/MyDrive/Fake.csv')\n",
        "true_data = pd.read_csv('/content/drive/MyDrive/True.csv')\n",
        "print(\"Fake Data:\")\n",
        "print(fake_data.head())\n",
        "print(\"\\nTrue Data:\")\n",
        "print(true_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32KVPfBUyPt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "fake_data = pd.read_csv('/content/drive/MyDrive/Fake.csv')\n",
        "true_data = pd.read_csv('/content/drive/MyDrive/True.csv')\n",
        "\n",
        "# Function to convert all text columns to lowercase\n",
        "def lowercase_text_columns(df):\n",
        "    for column in df.select_dtypes(include='object').columns:\n",
        "        df[column] = df[column].str.lower()\n",
        "    return df\n",
        "\n",
        "# Apply the function to both datasets\n",
        "fake_data_lower = lowercase_text_columns(fake_data)\n",
        "true_data_lower = lowercase_text_columns(true_data)\n",
        "\n",
        "# Save the preprocessed files\n",
        "fake_data_lower.to_csv('Fake_Lowercase.csv', index=False)\n",
        "true_data_lower.to_csv('True_Lowercase.csv', index=False)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Lowercase conversion complete. Files saved as Fake_Lowercase.csv and True_Lowercase.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbigramY4Amv",
        "outputId": "39e23a5b-9ce5-42c7-cc5e-357a424aaae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase conversion complete. Files saved as Fake_Lowercase.csv and True_Lowercase.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the preprocessed lowercase dataset\n",
        "fake_data_lower = pd.read_csv('Fake_Lowercase.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(fake_data_lower.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5tz6ZLt_kyL",
        "outputId": "33001791-ba41-4210-cde0-a597a2210b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0   donald trump sends out embarrassing new year’...   \n",
            "1   drunk bragging trump staffer started russian ...   \n",
            "2   sheriff david clarke becomes an internet joke...   \n",
            "3   trump is so obsessed he even has obama’s name...   \n",
            "4   pope francis just called out donald trump dur...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  donald trump just couldn t wish all americans ...    news   \n",
            "1  house intelligence committee chairman devin nu...    news   \n",
            "2  on friday, it was revealed that former milwauk...    news   \n",
            "3  on christmas day, donald trump announced that ...    news   \n",
            "4  pope francis used his annual christmas day mes...    news   \n",
            "\n",
            "                date  \n",
            "0  december 31, 2017  \n",
            "1  december 31, 2017  \n",
            "2  december 30, 2017  \n",
            "3  december 29, 2017  \n",
            "4  december 25, 2017  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the preprocessed lowercase dataset\n",
        "true_data_lower = pd.read_csv('True_Lowercase.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(true_data_lower.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUP9vRx8_q2l",
        "outputId": "700d0219-3ce2-4af9-8499-5b2f9c0cecf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  as u.s. budget fight looms, republicans flip t...   \n",
            "1  u.s. military to accept transgender recruits o...   \n",
            "2  senior u.s. republican senator: 'let mr. muell...   \n",
            "3  fbi russia probe helped by australian diplomat...   \n",
            "4  trump wants postal service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  washington (reuters) - the head of a conservat...  politicsnews   \n",
            "1  washington (reuters) - transgender people will...  politicsnews   \n",
            "2  washington (reuters) - the special counsel inv...  politicsnews   \n",
            "3  washington (reuters) - trump campaign adviser ...  politicsnews   \n",
            "4  seattle/washington (reuters) - president donal...  politicsnews   \n",
            "\n",
            "                 date  \n",
            "0  december 31, 2017   \n",
            "1  december 29, 2017   \n",
            "2  december 31, 2017   \n",
            "3  december 30, 2017   \n",
            "4  december 29, 2017   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the datasets\n",
        "true_news = pd.read_csv('/content/True_Lowercase.csv')\n",
        "fake_news = pd.read_csv('/content/Fake_Lowercase.csv')\n",
        "\n",
        "# Define a function to clean text using re module\n",
        "def clean_text(text):\n",
        "    # Remove non-alphabetic characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply the function to clean the text column in both datasets\n",
        "true_news['cleaned_text'] = true_news['text'].apply(clean_text)\n",
        "fake_news['cleaned_text'] = fake_news['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "zzYYgeFMAL1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display samples of the cleaned data\n",
        "print(\"Cleaned_True_Lowercase:\")\n",
        "print(true_news[['text', 'cleaned_text']].head())\n",
        "\n",
        "print(\"\\nCleaned_Fake_Lowercase.csv:\")\n",
        "print(fake_news[['text', 'cleaned_text']].head())\n",
        "\n",
        "# Save the cleaned datasets for further use\n",
        "true_news.to_csv('Cleaned_True_Lowercase.csv', index=False)\n",
        "fake_news.to_csv('Cleaned_Fake_Lowercase.csv', index=False)\n",
        "\n",
        "# Provide download links for the cleaned files in Colab\n",
        "from google.colab import files\n",
        "files.download('Cleaned_True_Lowercase.csv')\n",
        "files.download('Cleaned_Fake_Lowercase.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "bYq2g3RFAfYG",
        "outputId": "ab3d39c7-ec2c-458d-fef1-b0fdfc54d225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned_True_Lowercase:\n",
            "                                                text  \\\n",
            "0  washington (reuters) - the head of a conservat...   \n",
            "1  washington (reuters) - transgender people will...   \n",
            "2  washington (reuters) - the special counsel inv...   \n",
            "3  washington (reuters) - trump campaign adviser ...   \n",
            "4  seattle/washington (reuters) - president donal...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  washington reuters the head of a conservative ...  \n",
            "1  washington reuters transgender people will be ...  \n",
            "2  washington reuters the special counsel investi...  \n",
            "3  washington reuters trump campaign adviser geor...  \n",
            "4  seattlewashington reuters president donald tru...  \n",
            "\n",
            "Cleaned_Fake_Lowercase.csv:\n",
            "                                                text  \\\n",
            "0  donald trump just couldn t wish all americans ...   \n",
            "1  house intelligence committee chairman devin nu...   \n",
            "2  on friday, it was revealed that former milwauk...   \n",
            "3  on christmas day, donald trump announced that ...   \n",
            "4  pope francis used his annual christmas day mes...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  donald trump just couldn t wish all americans ...  \n",
            "1  house intelligence committee chairman devin nu...  \n",
            "2  on friday it was revealed that former milwauke...  \n",
            "3  on christmas day donald trump announced that h...  \n",
            "4  pope francis used his annual christmas day mes...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a97b4cb5-ca1a-44ac-895b-07cb12575ae4\", \"Cleaned_True_Lowercase.csv\", 102718155)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42da5917-44db-4321-8914-156f78ec2de2\", \"Cleaned_Fake_Lowercase.csv\", 120408157)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLTK if not already installed\n",
        "!pip install nltk\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define a function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    # Check if text is a string before splitting\n",
        "    if isinstance(text, str):\n",
        "        words = text.split()  # Split text into words\n",
        "        filtered_words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "        return ' '.join(filtered_words)  # Join words back into text\n",
        "    else:\n",
        "        # Handle non-string values (e.g., return as is or replace with empty string)\n",
        "        return text  # or return \"\"\n",
        "\n",
        "# Load datasets\n",
        "true_news = pd.read_csv('/content/Cleaned_True_Lowercase.csv')\n",
        "fake_news = pd.read_csv('/content/Cleaned_Fake_Lowercase.csv')\n",
        "\n",
        "# Apply stopwords removal\n",
        "true_news['text_no_stopwords'] = true_news['cleaned_text'].apply(remove_stopwords)\n",
        "fake_news['text_no_stopwords'] = fake_news['cleaned_text'].apply(remove_stopwords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUlyLYKJAmrD",
        "outputId": "71a546ee-aa79-459c-e3be-76cf103262e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some cleaned data\n",
        "print(\"Sample from True News after Stopwords Removal:\")\n",
        "print(true_news[['cleaned_text', 'text_no_stopwords']].head())\n",
        "\n",
        "print(\"\\nSample from Fake News after Stopwords Removal:\")\n",
        "print(fake_news[['cleaned_text', 'text_no_stopwords']].head())\n",
        "\n",
        "# Save the cleaned data for further use\n",
        "true_news.to_csv('Stopwords_True.csv', index=False)\n",
        "fake_news.to_csv('Stopwords_Fake.csv', index=False)\n",
        "\n",
        "# Download files in Colab\n",
        "from google.colab import files\n",
        "# Download the files that were actually created\n",
        "files.download('Stopwords_True.csv')  # Changed from 'Stopwords_True.csv'\n",
        "files.download('Stopwords_Fake.csv')  # Changed from 'Stopwords_Fake.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "xA4r3fSHAvrn",
        "outputId": "12443b9e-a278-431b-89b3-6b5081cc0e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample from True News after Stopwords Removal:\n",
            "                                        cleaned_text  \\\n",
            "0  washington reuters the head of a conservative ...   \n",
            "1  washington reuters transgender people will be ...   \n",
            "2  washington reuters the special counsel investi...   \n",
            "3  washington reuters trump campaign adviser geor...   \n",
            "4  seattlewashington reuters president donald tru...   \n",
            "\n",
            "                                   text_no_stopwords  \n",
            "0  washington reuters head conservative republica...  \n",
            "1  washington reuters transgender people allowed ...  \n",
            "2  washington reuters special counsel investigati...  \n",
            "3  washington reuters trump campaign adviser geor...  \n",
            "4  seattlewashington reuters president donald tru...  \n",
            "\n",
            "Sample from Fake News after Stopwords Removal:\n",
            "                                        cleaned_text  \\\n",
            "0  donald trump just couldn t wish all americans ...   \n",
            "1  house intelligence committee chairman devin nu...   \n",
            "2  on friday it was revealed that former milwauke...   \n",
            "3  on christmas day donald trump announced that h...   \n",
            "4  pope francis used his annual christmas day mes...   \n",
            "\n",
            "                                   text_no_stopwords  \n",
            "0  donald trump wish americans happy new year lea...  \n",
            "1  house intelligence committee chairman devin nu...  \n",
            "2  friday revealed former milwaukee sheriff david...  \n",
            "3  christmas day donald trump announced would bac...  \n",
            "4  pope francis used annual christmas day message...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c387250d-f9d8-42ff-abe8-847bbfbd1c35\", \"Stopwords_True.csv\", 139558906)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8f40c1c1-a1bf-4253-9cad-d1057679b270\", \"Stopwords_Fake.csv\", 161308895)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the punkt tokenizer model, and make sure to also download 'punkt_tab'\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the cleaned datasets with stopwords removed\n",
        "true_news_cleaned = pd.read_csv('/content/Stopwords_True.csv')\n",
        "fake_news_cleaned = pd.read_csv('/content/Stopwords_Fake.csv')\n",
        "\n",
        "# Define a function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        return word_tokenize(text)  # Tokenize text into words\n",
        "    else:\n",
        "        return []  # Return an empty list for non-string values\n",
        "\n",
        "# Apply tokenization to the stopword-removed text\n",
        "true_news_cleaned['tokens'] = true_news_cleaned['text_no_stopwords'].apply(tokenize_text)\n",
        "fake_news_cleaned['tokens'] = fake_news_cleaned['text_no_stopwords'].apply(tokenize_text)\n",
        "\n",
        "# Display tokenized samples\n",
        "print(\"\\nSample Tokens from True News:\")\n",
        "print(true_news_cleaned[['text_no_stopwords', 'tokens']].head())\n",
        "\n",
        "print(\"\\nSample Tokens from Fake News:\")\n",
        "print(fake_news_cleaned[['text_no_stopwords', 'tokens']].head())\n",
        "\n",
        "# Save the tokenized data\n",
        "true_news_cleaned.to_csv('Tokenized_True.csv', index=False)\n",
        "fake_news_cleaned.to_csv('Tokenized_Fake.csv', index=False)\n",
        "\n",
        "# Download the tokenized files in Colab\n",
        "from google.colab import files  # Make sure to import files if it's not already imported\n",
        "# Download the files that were actually created\n",
        "files.download('Tokenized_True.csv')  # Changed from 'True_Tokenized.csv' to 'Tokenized_True.csv'\n",
        "files.download('Tokenized_Fake.csv')  # Changed from 'Fake_Tokenized.csv' to 'Tokenized_Fake.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "5RyFdjikA4im",
        "outputId": "b8b4d4fd-fead-4415-8b45-8d068deabe9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Tokens from True News:\n",
            "                                   text_no_stopwords  \\\n",
            "0  washington reuters head conservative republica...   \n",
            "1  washington reuters transgender people allowed ...   \n",
            "2  washington reuters special counsel investigati...   \n",
            "3  washington reuters trump campaign adviser geor...   \n",
            "4  seattlewashington reuters president donald tru...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [washington, reuters, head, conservative, repu...  \n",
            "1  [washington, reuters, transgender, people, all...  \n",
            "2  [washington, reuters, special, counsel, invest...  \n",
            "3  [washington, reuters, trump, campaign, adviser...  \n",
            "4  [seattlewashington, reuters, president, donald...  \n",
            "\n",
            "Sample Tokens from Fake News:\n",
            "                                   text_no_stopwords  \\\n",
            "0  donald trump wish americans happy new year lea...   \n",
            "1  house intelligence committee chairman devin nu...   \n",
            "2  friday revealed former milwaukee sheriff david...   \n",
            "3  christmas day donald trump announced would bac...   \n",
            "4  pope francis used annual christmas day message...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [donald, trump, wish, americans, happy, new, y...  \n",
            "1  [house, intelligence, committee, chairman, dev...  \n",
            "2  [friday, revealed, former, milwaukee, sheriff,...  \n",
            "3  [christmas, day, donald, trump, announced, wou...  \n",
            "4  [pope, francis, used, annual, christmas, day, ...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a16831e0-550a-4d3c-b959-08d4c608e6ae\", \"Tokenized_True.csv\", 191033133)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34853193-322b-465d-8b4e-5c89600ed72a\", \"Tokenized_Fake.csv\", 218544723)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the punkt tokenizer model, and make sure to also download 'punkt_tab'\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the cleaned datasets with stopwords removed\n",
        "# Make sure the path to the CSV files is correct.\n",
        "# If you ran the previous cells in the same session,\n",
        "# the files should be in the current working directory.\n",
        "# Otherwise, adjust the path accordingly.\n",
        "true_news_cleaned = pd.read_csv('Stopwords_True.csv')\n",
        "fake_news_cleaned = pd.read_csv('Stopwords_Fake.csv')\n",
        "\n",
        "# Define a function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        return word_tokenize(text)  # Tokenize text into words\n",
        "    else:\n",
        "        return []  # Return an empty list for non-string values\n",
        "\n",
        "# Apply tokenization to the stopword-removed text\n",
        "true_news_cleaned['tokens'] = true_news_cleaned['text_no_stopwords'].apply(tokenize_text)\n",
        "fake_news_cleaned['tokens'] = fake_news_cleaned['text_no_stopwords'].apply(tokenize_text)\n",
        "\n",
        "# Display tokenized samples\n",
        "print(\"\\nSample Tokens from True News:\")\n",
        "print(true_news_cleaned[['text_no_stopwords', 'tokens']].head())\n",
        "\n",
        "print(\"\\nSample Tokens from Fake News:\")\n",
        "print(fake_news_cleaned[['text_no_stopwords', 'tokens']].head"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1J2nUzfdwE8y",
        "outputId": "47c41dd4-4890-4e4f-ed6e-92d4e8094890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-17-01bdd2ce40b3>, line 33)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-01bdd2ce40b3>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    print(fake_news_cleaned[['text_no_stopwords', 'tokens']].head\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2w5mzioyXSB",
        "outputId": "dffba919-8005-48ec-a2a2-dfcde2fd18d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the punkt tokenizer model, and make sure to also download 'punkt_tab'\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the cleaned datasets with stopwords removed\n",
        "# Make sure the path to the CSV files is correct.\n",
        "# If you ran the previous cells in the same session,\n",
        "# the files should be in the current working directory.\n",
        "# Otherwise, adjust the path accordingly.\n",
        "true_news_cleaned = pd.read_csv('Stopwords_True.csv')\n",
        "fake_news_cleaned = pd.read_csv('Stopwords_Fake.csv')\n",
        "\n",
        "# Define a function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        return word_tokenize(text)  # Tokenize text into words\n",
        "    else:\n",
        "        return []  # Return an empty list for non-string values\n",
        "\n",
        "# Apply tokenization to the stopword-removed text\n",
        "true_news_cleaned['tokens'] = true_news_cleaned['text_no_stopwords'].apply(tokenize_text)\n",
        "fake_news_cleaned['tokens'] = fake_news_cleaned['text_no_stopwords'].apply(tokenize_text)\n",
        "\n",
        "# Display tokenized samples\n",
        "print(\"\\nSample Tokens from True News:\")\n",
        "print(true_news_cleaned[['text_no_stopwords', 'tokens']].head())\n",
        "\n",
        "print(\"\\nSample Tokens from Fake News:\")\n",
        "print(fake_news_cleaned[['text_no_stopwords', 'tokens']].head())\n",
        "\n",
        "# Save the tokenized data\n",
        "true_news_cleaned.to_csv('Tokenized_True.csv', index=False)\n",
        "fake_news_cleaned.to_csv('Tokenized_Fake.csv', index=False)\n",
        "\n",
        "# Download the tokenized files in Colab\n",
        "from google.colab import files  # Make sure to import files if it's not already imported\n",
        "# Download the files that were actually created\n",
        "files.download('Tokenized_True.csv')  # Changed from 'True_Tokenized.csv' to 'Tokenized_True.csv'\n",
        "files.download('Tokenized_Fake.csv')  # Changed from 'Fake_Tokenized.csv' to 'Tokenized_Fake.csv'"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "YY8fmMJ7wMgm",
        "outputId": "836d2af3-b428-4959-9d8a-4d482205ecac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Tokens from True News:\n",
            "                                   text_no_stopwords  \\\n",
            "0  washington reuters head conservative republica...   \n",
            "1  washington reuters transgender people allowed ...   \n",
            "2  washington reuters special counsel investigati...   \n",
            "3  washington reuters trump campaign adviser geor...   \n",
            "4  seattlewashington reuters president donald tru...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [washington, reuters, head, conservative, repu...  \n",
            "1  [washington, reuters, transgender, people, all...  \n",
            "2  [washington, reuters, special, counsel, invest...  \n",
            "3  [washington, reuters, trump, campaign, adviser...  \n",
            "4  [seattlewashington, reuters, president, donald...  \n",
            "\n",
            "Sample Tokens from Fake News:\n",
            "                                   text_no_stopwords  \\\n",
            "0  donald trump wish americans happy new year lea...   \n",
            "1  house intelligence committee chairman devin nu...   \n",
            "2  friday revealed former milwaukee sheriff david...   \n",
            "3  christmas day donald trump announced would bac...   \n",
            "4  pope francis used annual christmas day message...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [donald, trump, wish, americans, happy, new, y...  \n",
            "1  [house, intelligence, committee, chairman, dev...  \n",
            "2  [friday, revealed, former, milwaukee, sheriff,...  \n",
            "3  [christmas, day, donald, trump, announced, wou...  \n",
            "4  [pope, francis, used, annual, christmas, day, ...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d4b3bf9-dbd2-48fe-a990-dac46319a3e0\", \"Tokenized_True.csv\", 191033133)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34f7f814-7628-4b47-aceb-291cdf71c0ba\", \"Tokenized_Fake.csv\", 218544723)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the punkt tokenizer model, and make sure to also download 'punkt_tab'\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the cleaned datasets with stopwords removed\n",
        "# Make sure the path to the CSV files is correct."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKjdE70JwT2h",
        "outputId": "f591c725-6836-4686-ebf3-8510495c67f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "source": [
        "import pandas as pd # Make sure you import pandas\n",
        "\n",
        "true_news_tokenized = pd.DataFrame({'column1': [1, 2, 3], 'column2': ['a', 'b', 'c']}) # Replace with your desired data\n",
        "true_news_tokenized.to_csv('Tokenized_True.csv', index=False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "NVpCMY2JtJ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the tokenized datasets\n",
        "true_news_tokenized = pd.read_csv('/content/Tokenized_Fake.csv')\n",
        "fake_news_tokenized = pd.read_csv('/content/Tokenized_Fake.csv')\n",
        "# Define a function to reconstruct text from tokens\n",
        "def add_punctuation(tokens):\n",
        "    if isinstance(tokens, str):\n",
        "        # Convert string representation of list back to Python list\n",
        "        tokens = eval(tokens)  # Ensure the input is properly formatted as a list\n",
        "        return ' '.join(tokens)  # Join tokens with spaces to reconstruct text\n",
        "    else:\n",
        "        return \"\"  # Handle non-string cases\n",
        "\n",
        "# Apply the punctuation-adding function to the tokenized data\n",
        "true_news_tokenized['reconstructed_text'] = true_news_tokenized['tokens'].apply(add_punctuation)\n",
        "fake_news_tokenized['reconstructed_text'] = fake_news_tokenized['tokens'].apply(add_punctuation)\n",
        "\n",
        "# Display samples to verify results\n",
        "print(\"Sample Reconstructed Text from True News:\")\n",
        "print(true_news_tokenized[['tokens', 'reconstructed_text']].head())\n",
        "\n",
        "print(\"\\nSample Reconstructed Text from Fake News:\")\n",
        "print(fake_news_tokenized[['tokens', 'reconstructed_text']].head())\n",
        "\n",
        "# Save the datasets with reconstructed text\n",
        "true_news_tokenized.to_csv('Reconstructed_True.csv', index=False)\n",
        "fake_news_tokenized.to_csv('Reconstructed_Fake.csv', index=False)\n",
        "\n",
        "# Download the files in Colab\n",
        "from google.colab import files\n",
        "files.download('Reconstructed_True.csv')\n",
        "files.download('Reconstructed_Fake.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "2G8x1gTiucLI",
        "outputId": "679ad995-85cf-4394-8f1c-c0ff6faf942e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Reconstructed Text from True News:\n",
            "                                              tokens  \\\n",
            "0  ['donald', 'trump', 'wish', 'americans', 'happ...   \n",
            "1  ['house', 'intelligence', 'committee', 'chairm...   \n",
            "2  ['friday', 'revealed', 'former', 'milwaukee', ...   \n",
            "3  ['christmas', 'day', 'donald', 'trump', 'annou...   \n",
            "4  ['pope', 'francis', 'used', 'annual', 'christm...   \n",
            "\n",
            "                                  reconstructed_text  \n",
            "0  donald trump wish americans happy new year lea...  \n",
            "1  house intelligence committee chairman devin nu...  \n",
            "2  friday revealed former milwaukee sheriff david...  \n",
            "3  christmas day donald trump announced would bac...  \n",
            "4  pope francis used annual christmas day message...  \n",
            "\n",
            "Sample Reconstructed Text from Fake News:\n",
            "                                              tokens  \\\n",
            "0  ['donald', 'trump', 'wish', 'americans', 'happ...   \n",
            "1  ['house', 'intelligence', 'committee', 'chairm...   \n",
            "2  ['friday', 'revealed', 'former', 'milwaukee', ...   \n",
            "3  ['christmas', 'day', 'donald', 'trump', 'annou...   \n",
            "4  ['pope', 'francis', 'used', 'annual', 'christm...   \n",
            "\n",
            "                                  reconstructed_text  \n",
            "0  donald trump wish americans happy new year lea...  \n",
            "1  house intelligence committee chairman devin nu...  \n",
            "2  friday revealed former milwaukee sheriff david...  \n",
            "3  christmas day donald trump announced would bac...  \n",
            "4  pope francis used annual christmas day message...  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34117b2d-19d3-4874-b221-1730da8e2ddb\", \"Reconstructed_True.csv\", 259448346)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_291b3153-00bf-4182-a58f-d4cc0b9b83c6\", \"Reconstructed_Fake.csv\", 259448346)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}