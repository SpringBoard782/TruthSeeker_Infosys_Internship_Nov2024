{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7942e9-7fb0-4bfe-8bb1-55e806c24f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"\n",
    "Hello Welcome, to session of NLP Tutorials. We will perform preprocessing.\n",
    "I can't believe this happenin! NLP is, like, super exciting @times & we don't even know why. Ism't it Rishabh Mehta?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ce124b-e70c-4d32-b177-ecf037d46de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello Welcome, to session of NLP Tutorials. We will perform preprocessing.\n",
      "I can't believe this happenin! NLP is, like, super exciting @times & we don't even know why. Ism't it Rishabh Mehta?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d676d5c3-99b8-49d5-a1cf-47b8aab171d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664b4808-175f-4662-bbb4-27ad6acf826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hello welcome, to session of nlp tutorials. we will perform preprocessing.\n",
      "i can't believe this happenin! nlp is, like, super exciting @times & we don't even know why. ism't it rishabh mehta?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12b4f98-1061-4970-89fa-8c2ae188b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hello welcome to session of nlp tutorials we will perform preprocessing\n",
      "i cant believe this happenin nlp is like super exciting times  we dont even know why ismt it rishabh mehta\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text=re.sub(r'[^\\w\\s]',\"\",corpus)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbbcda5-e840-487c-ad61-543ae499d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbba337-f0d7-4737-935a-ac305f8568f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba416912-3e7d-410f-84a9-0255d26ac35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8577277-ba9f-4efe-ae61-15413976b0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellowelcomesessionnlptutorialsperformpreprocessingcantbelievehappeninnlplikesuperexcitingtimesdontevenknowismtrishabhmehta'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"\".join([word for word in text.split() if word not in stop_words])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "815b7ffb-dad8-4cd2-9703-f8818979362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.1.0-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125f4438-4111-4a54-9b1d-12b2d8b6baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contractions import contractions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21834230-1aff-47c8-971c-92b2db553b13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8a6642-0849-402a-85a6-8b52a5ee1296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "404c7f14-1aa7-489a-8093-9de2f5a45670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07fa19aa-6290-456d-86e1-158d1bc34c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"hellowelcomesessionnlptutorialsperformpreprocessingcantbelievehappeninnlplikesuperexcitingtimesdontevenknowismtrishabhmehta\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(text).correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e959531-9e8e-4001-8c51-9ced19cbb45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17421002-8e27-412a-a990-5d340b9fe146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nhello welcome, to session of nlp tutorials.',\n",
       " 'we will perform preprocessing.',\n",
       " \"i can't believe this happenin!\",\n",
       " \"nlp is, like, super exciting @times & we don't even know why.\",\n",
       " \"ism't it rishabh mehta?\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d98598-5f26-4177-b994-195a3381a6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'session',\n",
       " 'of',\n",
       " 'nlp',\n",
       " 'tutorials',\n",
       " '.',\n",
       " 'we',\n",
       " 'will',\n",
       " 'perform',\n",
       " 'preprocessing',\n",
       " '.',\n",
       " 'i',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'believe',\n",
       " 'this',\n",
       " 'happenin',\n",
       " '!',\n",
       " 'nlp',\n",
       " 'is',\n",
       " ',',\n",
       " 'like',\n",
       " ',',\n",
       " 'super',\n",
       " 'exciting',\n",
       " '@',\n",
       " 'times',\n",
       " '&',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'even',\n",
       " 'know',\n",
       " 'why',\n",
       " '.',\n",
       " \"ism't\",\n",
       " 'it',\n",
       " 'rishabh',\n",
       " 'mehta',\n",
       " '?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec83b43-a9d1-4fd2-a7ab-17eb574472ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hello welcome, to session of nlp tutorials. we will perform preprocessing.\n",
      "i can't believe this happenin! nlp is, like, super exciting @times & we don't even know why. ism't it rishabh mehta?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "415f1a9c-2853-49af-a030-bc7f8132b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'session',\n",
       " 'of',\n",
       " 'nlp',\n",
       " 'tutorials',\n",
       " '.',\n",
       " 'we',\n",
       " 'will',\n",
       " 'perform',\n",
       " 'preprocessing',\n",
       " '.',\n",
       " 'i',\n",
       " 'can',\n",
       " \"'\",\n",
       " 't',\n",
       " 'believe',\n",
       " 'this',\n",
       " 'happenin',\n",
       " '!',\n",
       " 'nlp',\n",
       " 'is',\n",
       " ',',\n",
       " 'like',\n",
       " ',',\n",
       " 'super',\n",
       " 'exciting',\n",
       " '@',\n",
       " 'times',\n",
       " '&',\n",
       " 'we',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'even',\n",
       " 'know',\n",
       " 'why',\n",
       " '.',\n",
       " 'ism',\n",
       " \"'\",\n",
       " 't',\n",
       " 'it',\n",
       " 'rishabh',\n",
       " 'mehta',\n",
       " '?']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeba348f-7b16-4fb3-a616-db2d413fb2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'session',\n",
       " 'of',\n",
       " 'nlp',\n",
       " 'tutorials.',\n",
       " 'we',\n",
       " 'will',\n",
       " 'perform',\n",
       " 'preprocessing.',\n",
       " 'i',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'believe',\n",
       " 'this',\n",
       " 'happenin',\n",
       " '!',\n",
       " 'nlp',\n",
       " 'is',\n",
       " ',',\n",
       " 'like',\n",
       " ',',\n",
       " 'super',\n",
       " 'exciting',\n",
       " '@',\n",
       " 'times',\n",
       " '&',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'even',\n",
       " 'know',\n",
       " 'why.',\n",
       " \"ism't\",\n",
       " 'it',\n",
       " 'rishabh',\n",
       " 'mehta',\n",
       " '?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()  \n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efdd0be4-9426-49cf-afc6-7497d2db79de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Text:\n",
      "hellowelcomesessionnlptutorialsperformpreprocessingcantbelievehappeninnlplikesuperexcitingtimesdontevenknowismtrishabhmehta\n",
      "Lemmatized Text:\n",
      "hellowelcomesessionnlptutorialsperformpreprocessingcantbelievehappeninnlplikesuperexcitingtimesdontevenknowismtrishabhmehta\n"
     ]
    }
   ],
   "source": [
    "# Stemming and Lemmatization\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# We Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# We are pplying stemming\n",
    "stemmed_text = \" \".join([stemmer.stem(word) for word in word_tokenize(text)])\n",
    "print(\"Stemmed Text:\")\n",
    "print(stemmed_text)\n",
    "\n",
    "# Now we are applying lemmatization\n",
    "lemmatized_text = \" \".join([lemmatizer.lemmatize(word) for word in word_tokenize(text)])\n",
    "print(\"Lemmatized Text:\")\n",
    "print(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6780103-e501-4e08-8d58-c7e6c43d6171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
