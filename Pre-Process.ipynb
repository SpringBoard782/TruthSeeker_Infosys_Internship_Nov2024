{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZRLhAZJPxyn",
        "outputId": "f4cf1444-480b-4d32-eaaa-0c99fec205ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "metadata": {
        "id": "DNzOcAW0PxvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "wv=api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoysqsCXPxrr",
        "outputId": "3e99bc91-60b3-4983-8792-c14b9755ac83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_king=wv['king']"
      ],
      "metadata": {
        "id": "DyIBmMxbPxoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec_king"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U5EeNdMPxkX",
        "outputId": "f67b011f-d7f4-4962-c0ee-86e1447d5aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
              "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
              "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
              "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
              "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
              "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
              "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
              "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
              "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
              "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
              "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
              "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
              "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
              "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
              "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
              "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
              "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
              "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
              "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
              "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
              "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
              "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
              "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
              "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
              "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
              "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
              "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
              "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
              "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
              "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
              "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
              "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
              "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
              "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
              "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
              "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
              "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
              "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
              "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
              "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
              "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
              "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
              "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
              "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
              "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
              "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
              "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
              "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
              "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
              "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
              "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
              "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
              "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
              "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
              "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
              "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
              "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
              "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
              "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
              "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
              "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
              "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
              "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
              "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
              "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
              "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
              "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
              "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
              "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
              "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
              "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
              "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
              "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
              "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
              "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(\"king\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyv2DWsuPxga",
        "outputId": "b439d046-ead4-45d6-bf18-e36f3b808d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kings', 0.7138045430183411),\n",
              " ('queen', 0.6510956883430481),\n",
              " ('monarch', 0.6413194537162781),\n",
              " ('crown_prince', 0.6204220056533813),\n",
              " ('prince', 0.6159993410110474),\n",
              " ('sultan', 0.5864824056625366),\n",
              " ('ruler', 0.5797567367553711),\n",
              " ('princes', 0.5646552443504333),\n",
              " ('Prince_Paras', 0.5432944297790527),\n",
              " ('throne', 0.5422105193138123)]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_cricket=wv['cricket']"
      ],
      "metadata": {
        "id": "UOTUeNC1WIXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(\"cricket\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI_bZnl7WIL_",
        "outputId": "da72edaf-d6d8-409a-bc1f-e489a0952ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cricketing', 0.8372225761413574),\n",
              " ('cricketers', 0.8165745735168457),\n",
              " ('Test_cricket', 0.8094819188117981),\n",
              " ('Twenty##_cricket', 0.8068488240242004),\n",
              " ('Twenty##', 0.7624265551567078),\n",
              " ('Cricket', 0.75413978099823),\n",
              " ('cricketer', 0.7372578382492065),\n",
              " ('twenty##', 0.7316356897354126),\n",
              " ('T##_cricket', 0.7304614186286926),\n",
              " ('West_Indies_cricket', 0.6987985968589783)]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8qdyAddEPxSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data={\n",
        "    \"text\":[\n",
        "         \"Breaking news: Government announces tax relief for small businesses\",\n",
        "        \"Click here to win a free iPhone now!\",\n",
        "        \"NASA discovers water on Mars in groundbreaking research\",\n",
        "        \"Exclusive: Celebrity spotted at local restaurant!\",\n",
        "        \"Breaking: Huge discount on electronics for the next 24 hours\",\n",
        "        \"World Health Organization advises wearing masks to prevent virus spread\",\n",
        "        \"You won't believe this one weird trick to lose weight fast!\",\n",
        "        \"Scientists discover a new species of butterfly in the Amazon\",\n",
        "        \"This is the ultimate guide to making money overnight!\",\n",
        "        \"Experts predict an increase in global temperatures next year\",\n",
        "        \"Get rich quick with this new crypto scheme\",\n",
        "        \"Researchers develop a new treatment for cancer\",\n",
        "        \"Politicians caught in a scandalous debate over climate change\",\n",
        "        \"Start your day with this amazing energy drink offer!\",\n",
        "        \"Doctors recommend regular exercise for better health\",\n",
        "        \"Free gifts for the first 100 customers only!\",\n",
        "        \"Economists warn about an impending recession in global markets\",\n",
        "        \"Win a luxury vacation to Paris by entering this contest!\",\n",
        "        \"Tech companies announce a new breakthrough in AI technology\",\n",
        "        \"Congratulations! You've won a $1000 gift card. Claim now!\",\n",
        "    ],\n",
        "    \"label\":[\n",
        "              \"real\", \"fake\", \"real\", \"real\", \"fake\", \"real\", \"fake\", \"real\", \"fake\", \"real\",\n",
        "        \"fake\", \"real\", \"real\", \"fake\", \"real\", \"fake\", \"real\", \"fake\", \"real\", \"fake\"\n",
        "    ]\n",
        "}\n",
        "df=pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "vKEQ9vaDOOsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "8iWuyeuvOOoE",
        "outputId": "b4afd61c-6476-4957-b2c9-de3719d9e537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text label\n",
              "0   Breaking news: Government announces tax relief...  real\n",
              "1                Click here to win a free iPhone now!  fake\n",
              "2   NASA discovers water on Mars in groundbreaking...  real\n",
              "3   Exclusive: Celebrity spotted at local restaurant!  real\n",
              "4   Breaking: Huge discount on electronics for the...  fake\n",
              "5   World Health Organization advises wearing mask...  real\n",
              "6   You won't believe this one weird trick to lose...  fake\n",
              "7   Scientists discover a new species of butterfly...  real\n",
              "8   This is the ultimate guide to making money ove...  fake\n",
              "9   Experts predict an increase in global temperat...  real\n",
              "10         Get rich quick with this new crypto scheme  fake\n",
              "11     Researchers develop a new treatment for cancer  real\n",
              "12  Politicians caught in a scandalous debate over...  real\n",
              "13  Start your day with this amazing energy drink ...  fake\n",
              "14  Doctors recommend regular exercise for better ...  real\n",
              "15       Free gifts for the first 100 customers only!  fake\n",
              "16  Economists warn about an impending recession i...  real\n",
              "17  Win a luxury vacation to Paris by entering thi...  fake\n",
              "18  Tech companies announce a new breakthrough in ...  real\n",
              "19  Congratulations! You've won a $1000 gift card....  fake"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7c86a87-bc5e-4960-984a-053b2dea009f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Breaking news: Government announces tax relief...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Click here to win a free iPhone now!</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NASA discovers water on Mars in groundbreaking...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Exclusive: Celebrity spotted at local restaurant!</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Breaking: Huge discount on electronics for the...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>World Health Organization advises wearing mask...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>You won't believe this one weird trick to lose...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Scientists discover a new species of butterfly...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>This is the ultimate guide to making money ove...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Experts predict an increase in global temperat...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Get rich quick with this new crypto scheme</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Researchers develop a new treatment for cancer</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Politicians caught in a scandalous debate over...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Start your day with this amazing energy drink ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Doctors recommend regular exercise for better ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Free gifts for the first 100 customers only!</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Economists warn about an impending recession i...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Win a luxury vacation to Paris by entering thi...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Tech companies announce a new breakthrough in ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Congratulations! You've won a $1000 gift card....</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7c86a87-bc5e-4960-984a-053b2dea009f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e7c86a87-bc5e-4960-984a-053b2dea009f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e7c86a87-bc5e-4960-984a-053b2dea009f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4496c915-c6a5-4279-8586-f620b69798a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4496c915-c6a5-4279-8586-f620b69798a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4496c915-c6a5-4279-8586-f620b69798a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_021f8705-30dd-471a-8a60-bb9ac6d3d5f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_021f8705-30dd-471a-8a60-bb9ac6d3d5f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Breaking news: Government announces tax relief for small businesses\",\n          \"Win a luxury vacation to Paris by entering this contest!\",\n          \"Free gifts for the first 100 customers only!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fake\",\n          \"real\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgZkQWwjOOlc",
        "outputId": "f90dc3ac-7f1b-4de3-f1e2-27e35f9b300a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6loyMwTgPd9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']=df['label'].map({\"fake\":0,\"real\":1})\n",
        "df['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "fzxwB9ubOOhP",
        "outputId": "13d1644f-4edd-4137-e543-cbc949c09d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    NaN\n",
              "1    NaN\n",
              "2    NaN\n",
              "3    NaN\n",
              "4    NaN\n",
              "5    NaN\n",
              "6    NaN\n",
              "7    NaN\n",
              "8    NaN\n",
              "9    NaN\n",
              "10   NaN\n",
              "11   NaN\n",
              "12   NaN\n",
              "13   NaN\n",
              "14   NaN\n",
              "15   NaN\n",
              "16   NaN\n",
              "17   NaN\n",
              "18   NaN\n",
              "19   NaN\n",
              "Name: label, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "6PoPcBqJOOeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "-pa-N0a5OOaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "iKKoWSpnOOXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  text=text.lower()\n",
        "  tokens=text.split()\n",
        "  tokens=[word for word in tokens if word not in stop_words]\n",
        "  tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return \" \".join(tokens)\n",
        "df['text']=df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "k3oFcIQWOOUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TaYahqF6OOQ8",
        "outputId": "17daca75-7f3b-4bda-ef2d-247bff9378b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  breaking news: government announces tax relief...    NaN\n",
              "1                         click win free iphone now!    NaN\n",
              "2   nasa discovers water mar groundbreaking research    NaN\n",
              "3     exclusive: celebrity spotted local restaurant!    NaN\n",
              "4   breaking: huge discount electronics next 24 hour    NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-014c7338-7ccb-41c7-827a-c2f303a67d76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breaking news: government announces tax relief...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>click win free iphone now!</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nasa discovers water mar groundbreaking research</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>exclusive: celebrity spotted local restaurant!</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>breaking: huge discount electronics next 24 hour</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-014c7338-7ccb-41c7-827a-c2f303a67d76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-014c7338-7ccb-41c7-827a-c2f303a67d76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-014c7338-7ccb-41c7-827a-c2f303a67d76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37517e33-d3a2-465d-8787-cdc070235a60\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37517e33-d3a2-465d-8787-cdc070235a60')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37517e33-d3a2-465d-8787-cdc070235a60 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"breaking news: government announces tax relief small business\",\n          \"win luxury vacation paris entering contest!\",\n          \"free gift first 100 customer only!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(df['text'],df['label'],test_size=0.1,random_state=42)"
      ],
      "metadata": {
        "id": "nA5zJNwOOONj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuOvTcm9OOKV",
        "outputId": "89f85508-83e7-48c7-8658-16d01b5d1645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNhObg6QOOHd",
        "outputId": "4b658f01-7ee5-44de-a47d-18ba30868973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "FWCqnT2xOOD8",
        "outputId": "1e9e6c92-45c9-45dd-b881-b6ae9f82ae74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: count, dtype: int64)"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "QG7UiBQqOOA9",
        "outputId": "ad8dfc81-e3c7-453f-c60f-a612b9551614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: count, dtype: int64)"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer=CountVectorizer()"
      ],
      "metadata": {
        "id": "Gf4gZN8oON-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vectorized=vectorizer.fit(X_train)"
      ],
      "metadata": {
        "id": "qa0WzcAqON6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vectorized=vectorizer.transform(X_train)"
      ],
      "metadata": {
        "id": "1Md-vblRON3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vectorized=vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "gSGEd4ZGON0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb_model=MultinomialNB()"
      ],
      "metadata": {
        "id": "n1Qck8UrONxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "X_train = [\"This is a test\", \"NaN\", None, \"Another example\", \" \"]\n",
        "y_train = [1, None, 0, 1, None]\n",
        "X_train = pd.Series(X_train)\n",
        "y_train = pd.Series(y_train)\n",
        "cleaned_data = pd.concat([X_train, y_train], axis=1).dropna()\n",
        "X_train = cleaned_data[0]\n",
        "y_train = cleaned_data[1]\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vectorized, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ArcEZV7jYEZH",
        "outputId": "ad5ed33a-07f0-4e92-c19d-90cac9dc71e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred=nb_model.predict(X_train_vectorized)"
      ],
      "metadata": {
        "id": "cYvmyRfcYefa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJOkuOXYebi",
        "outputId": "675fd2c9-8e2d-4f18-fca2-90e32c38025e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report"
      ],
      "metadata": {
        "id": "EX6_B5vdYeYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_train,y_train_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9c11yy-YeUq",
        "outputId": "7488e414-987b-431f-d8ef-5893dffbc15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "y_test_pred = nb_model.predict(X_test_vectorized)\n"
      ],
      "metadata": {
        "id": "IjFKMhBFYeDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,y_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "okog9SjoZZl0",
        "outputId": "a047bb39-3e42-4e63-bfe2-445a3d938007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:390: RuntimeWarning: invalid value encountered in cast\n",
            "  return x.astype(dtype, copy=copy, casting=casting)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y_true contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-fb3b2179ea93>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CwdCCsTNad0v",
        "outputId": "c81c115c-8b4b-4fae-d6a5-b3f660dac042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MultinomialNB.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-8fa9a393cbb1>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Calculate accuracy score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;34m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1088\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MultinomialNB."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Check if any dataset is empty\n",
        "print(\"Length of X_train:\", len(X_train))\n",
        "print(\"Length of X_test:\", len(X_test))\n",
        "print(\"Length of y_train:\", len(y_train))\n",
        "print(\"Length of y_test:\", len(y_test))\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Check shapes after vectorization\n",
        "print(\"Shape of X_train_vectorized:\", X_train_vectorized.shape)\n",
        "print(\"Shape of X_test_vectorized:\", X_test_vectorized.shape)\n",
        "\n",
        "# Train the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "w5sRBFMranvh",
        "outputId": "3bb76fed-8a69-42ab-c941-55df826f76bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X_train: 18\n",
            "Length of X_test: 2\n",
            "Length of y_train: 18\n",
            "Length of y_test: 2\n",
            "Shape of X_train_vectorized: (18, 102)\n",
            "Shape of X_test_vectorized: (2, 102)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-265d6e0e90b9>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Train the Naive Bayes model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mnb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mnb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;34m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1316\u001b[0m     )\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0mestimator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_estimator_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kind\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values in y_train\n",
        "print(\"NaN values in y_train:\", y_train.isna().sum())\n",
        "\n",
        "# Remove rows with NaN values from both X_train and y_train\n",
        "valid_indices = ~y_train.isna()\n",
        "X_train = X_train[valid_indices]\n",
        "y_train = y_train[valid_indices]\n",
        "\n",
        "# Re-vectorize X_train after removing NaNs\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Train the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "iVz66MlZaxRJ",
        "outputId": "92007cb9-7494-4a95-87a4-37098f6c208b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in y_train: 18\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "empty vocabulary; perhaps the documents only contain stop words",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-03b69c93af48>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Re-vectorize X_train after removing NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train_vectorized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train the Naive Bayes model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1279\u001b[0m                     \u001b[0;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if X_train is empty after filtering NaN values from y_train\n",
        "print(\"Length of X_train:\", len(X_train))\n",
        "print(\"Sample of X_train:\", X_train.head())\n",
        "\n",
        "# If X_train is empty, handle this case\n",
        "if X_train.empty:\n",
        "    print(\"X_train contains no valid data after filtering.\")\n",
        "else:\n",
        "    # Re-vectorize X_train\n",
        "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "    # Train the Naive Bayes model\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_test_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "    # Calculate accuracy score\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvLVCJHta1-z",
        "outputId": "babb4b7f-c943-4b3f-e233-408f7c71509d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X_train: 0\n",
            "Sample of X_train: Series([], Name: text, dtype: object)\n",
            "X_train contains no valid data after filtering.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test,y_test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJTHYuRQbAk8",
        "outputId": "b8a9dc44-40d6-4f28-dc4c-944f3fd6c1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    NaN\n",
              " 17   NaN\n",
              " Name: label, dtype: float64,\n",
              " array([1., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report=classification_report(y_test,y_test_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH4VGXXsPo-T",
        "outputId": "c5f0cbe6-e9b9-4b87-f268-44265b580e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.75         4\n",
            "   macro avg       0.75      0.83      0.73         4\n",
            "weighted avg       0.88      0.75      0.77         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "param_grid={\n",
        "\n",
        "            \"C\":[0.1,0.3,0.5,1,10],\n",
        "            \"kernel\":[\"linear\",\"rbf\"],\n",
        "            \"gamma\":['scale',\"auto\"]\n",
        "}\n",
        "\n",
        "svm_model=SVC(random_state=42)"
      ],
      "metadata": {
        "id": "0UIGsDGpP_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search=GridSearchCV(svm_model,param_grid,cv=5,scoring=\"accuracy\")"
      ],
      "metadata": {
        "id": "XZ2gqQvoRQR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train_vectorized,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "GqYy2ctnSDLt",
        "outputId": "523387b4-e3d0-4490-d3cd-864496be7e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=SVC(random_state=42),\n",
              "             param_grid={'C': [0.1, 0.3, 0.5, 1, 10],\n",
              "                         'gamma': ['scale', 'auto'],\n",
              "                         'kernel': ['linear', 'rbf']},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=42),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 0.3, 0.5, 1, 10],\n",
              "                         &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=42),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 0.3, 0.5, 1, 10],\n",
              "                         &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxQtxRVZSIVm",
        "outputId": "83199070-03ad-4d60-d1e0-1476b0f3fd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIvR7B3hSPqL",
        "outputId": "cdc9d282-d82c-4223-e02e-765d0d26e8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6333333333333332"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model=grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "WUWSZqU0SUPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=best_model.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "-10y5dL3Sa_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report=classification_report(y_test,y_test_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTmtybdpSjGK",
        "outputId": "d5215bb7-36c9-42b3-85ef-1761496a1a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.75         4\n",
            "   macro avg       0.75      0.83      0.73         4\n",
            "weighted avg       0.88      0.75      0.77         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,y_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVl36mALSl6U",
        "outputId": "9fed0fe5-9a99-44a4-cbd7-19cefec35117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data={\n",
        "    \"Title\": [\n",
        "        \"Breaking news: COVID-19 vaccine is a scam!\",\n",
        "        \"NASA discovers new planet with signs of life\",\n",
        "        \"Fake celebrity dies in car crash story circulates\",\n",
        "        \"New study confirms coffee boosts productivity\"\n",
        "    ],\n",
        "    \"Label\": [1, 0, 1, 0]  # 1 = Fake, 0 = Real\n",
        "}"
      ],
      "metadata": {
        "id": "AyQzIXrGlRjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "Rc2hfVbdlRf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "3J0LyZbSlfT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf=TfidfVectorizer(max_features=50)"
      ],
      "metadata": {
        "id": "NdrYh_6Nlo8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=tfidf.fit_transform(df['Title']).toarray()\n",
        "y=df['Label']"
      ],
      "metadata": {
        "id": "Gaia0syal4_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "Gu_4L51EmIA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "aVY5BV0qmTgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential([Dense(64,activation='relu',input_shape=(X.shape[1],)),\n",
        "                  Dropout(0.5),\n",
        "                  Dense(32,activation=\"relu\"),\n",
        "                  Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "                  ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcxMN6i_mmZH",
        "outputId": "71658ed4-2c9e-40d7-b38d-f4ae5c5a71ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DqLlNWdEnraT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S0IbHBtn9m9",
        "outputId": "fd941ce1-4ce3-406d-f087-cb07c2017013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2500 - loss: 0.7091\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.7065\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6831\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7500 - loss: 0.6918\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5000 - loss: 0.6843\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5000 - loss: 0.6765\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.6277\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.6365\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.6523\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2500 - loss: 0.7060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7be406632b00>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E35o2gOLoDAU",
        "outputId": "d5d0c5e1-d63c-4483-df98-a770b5668b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.6574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45j8-rOoJld",
        "outputId": "a6a50d59-c336-40a0-8152-cdb9b63f3daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6574366688728333, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARcsZZXSoWvt",
        "outputId": "7c5083a0-bf49-46f5-91af-79bc56d9a1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5309954 ],\n",
              "       [0.48239043],\n",
              "       [0.5163971 ],\n",
              "       [0.49202934]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Yzy8WPEyovqL",
        "outputId": "d825a9b9-2f89-4011-d365-4754e262162a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "Name: Label, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrkXspycxUGq",
        "outputId": "b33aef75-b46d-46fc-b2cd-9adfb15eca4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-33.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-33.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-33.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker"
      ],
      "metadata": {
        "id": "2MUlpip7x-GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Tu9JhyoNyWPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake=Faker()\n",
        "Faker.seed(42)"
      ],
      "metadata": {
        "id": "49YJIwOmxz_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_labels(num_samples=5000):\n",
        "    text=[fake.sentence(nb_words=10) for i in range(num_samples)]\n",
        "    labels=np.random.randint(0,2,num_samples)\n",
        "    return text,labels"
      ],
      "metadata": {
        "id": "0eJwPdlxx57A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts,labels=generate_text_labels()"
      ],
      "metadata": {
        "id": "47bJU8hKycOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTNAPYkayglA",
        "outputId": "0dc54408-dd0f-418b-f402-f35d0ee8bd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Agent every development say quality throughout beautiful.',\n",
              " 'All behavior discussion own night respond red information last everything thank.',\n",
              " 'Recently future choice whatever from behavior benefit suggest.',\n",
              " 'Enough analysis least by two bad fall pick those gun court attorney product.',\n",
              " 'World talk term herself law street class great prove.',\n",
              " 'Participant commercial rock clear here writer.',\n",
              " 'Detail food shoulder argue start source husband at tree note responsibility defense material.',\n",
              " 'Central cause seat much section investment on gun young catch management.',\n",
              " 'Technology check civil quite others his.',\n",
              " 'You more wife team activity result race Mr environment political born itself law.',\n",
              " 'Will seven medical blood personal success medical current hear.',\n",
              " 'Much single morning a food affect upon these.',\n",
              " 'Dream drive note bad rule staff within mouth call.',\n",
              " 'Water close month parent who up sense ready require human public health.',\n",
              " 'Later easy ask again network open according remain arrive attack all form.',\n",
              " 'Draw protect Democrat car very number line six space couple best issue.',\n",
              " 'In tell approach president position art rock song body court movie.',\n",
              " 'Instead everything economic type kitchen technology nearly.',\n",
              " 'Present music address behavior send door.',\n",
              " 'Magazine degree husband around her world enter six lawyer institution whatever.',\n",
              " 'Product main couple design around save article finish anyone live try most arm.',\n",
              " 'Bag control organization push dog build three east organization people information on.',\n",
              " 'First end prove fire enter capital population lead upon very act perform.',\n",
              " 'You available defense enter value thing these hard citizen street region particularly would.',\n",
              " 'Account stage federal professional voice care break blood network evening painting response.',\n",
              " 'Reach table measure economy traditional anything plant stop.',\n",
              " 'About side PM energy scientist necessary.',\n",
              " 'Night born war real chance along hard need involve among half.',\n",
              " 'Together decide economic bill sister this.',\n",
              " 'Wind see understand door class son computer include conference under site.',\n",
              " 'Soon ten specific environment skin blue the teach develop staff least.',\n",
              " 'Star the development process huge everything attorney significant go.',\n",
              " 'Hundred wonder movie voice boy wife condition while enter board its rock.',\n",
              " 'Job worker break tonight couple and job mind southern rather.',\n",
              " 'Hair attorney professional form finish summer rest feel.',\n",
              " 'Project for recent never court professor here security community.',\n",
              " 'Feeling nature a expert involve oil pressure let kind degree list top somebody.',\n",
              " 'Probably exist professional people behavior weight dog financial.',\n",
              " 'Challenge animal worker particularly shoulder lay though offer.',\n",
              " 'Manager during prevent accept seem show blood interesting compare when.',\n",
              " 'Let newspaper true building card let most next fish sense kind spring.',\n",
              " 'Interview trade knowledge city technology late seem style everyone sing machine dream.',\n",
              " 'Back experience even floor music catch discuss really relationship ask imagine.',\n",
              " 'Letter artist strategy hope show watch affect thing offer local wall fear.',\n",
              " 'Table well industry section national owner determine detail job ahead.',\n",
              " 'Protect something right subject try wonder move trade option production.',\n",
              " 'Poor career left anyone here deep force.',\n",
              " 'Everything week instead strong like see appear weight difference attention.',\n",
              " 'Senior wear current after charge call.',\n",
              " 'Nor design record short cold parent security.',\n",
              " 'Sing clearly find official up office traditional.',\n",
              " 'However resource away real physical big significant sure outside building.',\n",
              " 'Site girl into have media game support state black whether player stock religious.',\n",
              " 'Computer miss practice pattern try simple let stay or focus early.',\n",
              " 'Everything late seek now property from management.',\n",
              " 'Consider deep something future they red everybody act way beat.',\n",
              " 'Major serve real position make society behavior develop reality fill ok.',\n",
              " 'Network gas you nearly goal law fill discover return firm sea week.',\n",
              " 'Course school everybody operation set others wonder strategy.',\n",
              " 'Dinner conference add move ever window network recently call.',\n",
              " 'Bill activity expect long future whole education technology box assume man officer.',\n",
              " 'Charge specific we be easy newspaper.',\n",
              " 'Paper so difficult mission late kind team wrong figure perform participant.',\n",
              " 'Way debate decision produce church community avoid.',\n",
              " 'Impact ready like allow explain executive.',\n",
              " 'Author do enough social operation sound cup boy different chance enter.',\n",
              " 'Author coach film see notice eye buy.',\n",
              " 'Record wall matter management ball always it focus economy.',\n",
              " 'Director purpose team onto again share start.',\n",
              " 'American series like prepare trouble consider one play man before girl four prove.',\n",
              " 'Form really explain war spend nearly lawyer fire.',\n",
              " 'Break significant ten stay ability thank left approach million performance.',\n",
              " 'Personal service data near until just recognize building win participant dream citizen.',\n",
              " 'Add impact different success box water positive child usually factor relate indeed lot.',\n",
              " 'During necessary himself two meet these tell everybody so increase various meet.',\n",
              " 'Executive fear only your majority chance.',\n",
              " 'Machine forward several help usually thank wonder draw him task improve fish.',\n",
              " 'Relate specific history professional star wonder manager already maybe opportunity thank them.',\n",
              " 'Between treat address century that wide avoid sit enter perhaps however.',\n",
              " 'System system teacher here first responsibility service.',\n",
              " 'Along attention piece TV young section its better plant their kitchen really.',\n",
              " 'Animal someone fall hear certainly most.',\n",
              " 'Radio conference company participant him raise marriage on discussion point least project together.',\n",
              " 'Top quality citizen kid generation onto police interesting economic suddenly current.',\n",
              " 'Table blood high grow fast recognize against stop how account.',\n",
              " 'Treat seat strategy total simply discover.',\n",
              " 'Despite couple economy sense should race carry best physical always.',\n",
              " 'Almost half capital travel force indeed customer skill theory hand maybe.',\n",
              " 'Store either station loss southern second full boy while.',\n",
              " 'Senior difficult put purpose however suffer newspaper.',\n",
              " 'So add Mr lawyer pull public once.',\n",
              " 'Board doctor agent this no trip determine as statement travel.',\n",
              " 'Power bring animal also you break doctor Mr home.',\n",
              " 'Provide sea watch industry score choice increase between majority impact.',\n",
              " 'Allow have kitchen wear talk between rate name within.',\n",
              " 'Art every why we station begin deep police wife anything.',\n",
              " 'During call north attention share debate democratic thank forget challenge.',\n",
              " 'Able teach certain candidate economy company produce ago address so draw food company.',\n",
              " 'Camera inside box as large gun.',\n",
              " 'Board mean war analysis situation term miss leader who article look husband rather.',\n",
              " 'Republican kitchen tonight focus chance call person one Republican herself our far.',\n",
              " 'Painting between reduce table prepare shoulder result Democrat later direction fund law.',\n",
              " 'Role fine fine effort well rather listen before be it season.',\n",
              " 'Speech news only no form business government program seek test.',\n",
              " 'Why outside goal official defense prevent.',\n",
              " 'Suggest glass news boy everything difficult investment night.',\n",
              " 'Party poor ago upon stop environment Congress reflect finally fund accept thank not.',\n",
              " 'Attorney scientist will begin most heavy law church find food walk.',\n",
              " 'Be apply church pay purpose evening product magazine kind event sense box involve.',\n",
              " 'Question or money final determine worker area daughter war.',\n",
              " 'Share face build market issue can mouth.',\n",
              " 'Matter street south author technology amount affect TV.',\n",
              " 'Office of remember individual boy again foot soon peace story.',\n",
              " 'Because such during open model how financial fund four collection.',\n",
              " 'Plan most create simply go when population challenge bill eight community check.',\n",
              " 'Concern significant management senior service large.',\n",
              " 'Poor worry follow wife firm key light place someone option goal avoid left.',\n",
              " 'Arm story baby ten talk past.',\n",
              " 'His oil west school American training occur could painting may whatever late.',\n",
              " 'Word base position always remain yard model particular hair truth.',\n",
              " 'Impact full our smile positive at behind question exist rich.',\n",
              " 'Their four old center glass whose recognize hot organization visit finally heavy social.',\n",
              " 'Prove stock school rate money position interest.',\n",
              " 'Adult final week game she court yourself choice fast small.',\n",
              " 'Side strong this also from short capital heavy class story side speak.',\n",
              " 'Return analysis hair rest wide particular sell six.',\n",
              " 'Move finally speak light strong happy water worker.',\n",
              " 'Show sing me industry class current painting their appear lose he.',\n",
              " 'Represent middle by base civil last message.',\n",
              " 'Begin treat stage this us increase how hear history bank different.',\n",
              " 'Us stuff practice social case expert stop receive catch relationship.',\n",
              " 'Past town affect democratic change vote participant institution simply down business.',\n",
              " 'Information soldier lead book toward others administration middle drop.',\n",
              " 'Fact ability good number cost property model.',\n",
              " 'Attack moment medical write never hospital like player wonder effect.',\n",
              " 'Ground attack drop price billion old.',\n",
              " 'Card good full poor store range wonder long consider care.',\n",
              " 'Already cut social though firm financial huge spring list already positive.',\n",
              " 'Ground sit tend forward buy happy threat sea thus.',\n",
              " 'Fund cost reality happen something entire bar interesting issue yet.',\n",
              " 'Nation fly bag produce fill owner international ready.',\n",
              " 'Language risk treatment past itself police social arm provide image.',\n",
              " 'Song quickly well central parent sit alone attack sing hand him note.',\n",
              " 'Check last he know baby case happen fire everything whether ago control military.',\n",
              " 'Brother simple region Democrat partner really your customer career available common require young.',\n",
              " 'Property remember nearly face feel church remember record company gun.',\n",
              " 'Building cut catch so ago network hard sound.',\n",
              " 'Candidate this assume huge response long improve important offer by first avoid letter.',\n",
              " 'General there sister policy consider whom item treat area buy check clearly.',\n",
              " 'Various different way million exist bad cultural what ever person.',\n",
              " 'Move maybe collection walk child probably result painting successful nor stay agreement animal.',\n",
              " 'Enough decision occur peace air threat nation politics few each southern image law.',\n",
              " 'Citizen indeed less future century technology.',\n",
              " 'Safe team wish candidate have no five letter environment easy.',\n",
              " 'Anything war ten industry while total spend.',\n",
              " 'Return couple city you level these market bed hotel lead drive on any.',\n",
              " 'Manager think pressure like Mr suggest issue think road.',\n",
              " 'Hand hundred now crime network available mean share evidence writer quite.',\n",
              " 'Campaign benefit health would newspaper hand certain.',\n",
              " 'Meeting matter and case four listen lead paper middle foreign party class wrong.',\n",
              " 'Order medical meeting majority none little admit former body.',\n",
              " 'On someone rise read ago listen whose situation simply officer return.',\n",
              " 'Lose modern return simple herself start drug occur red course kid industry include.',\n",
              " 'Improve simple turn their save artist catch debate.',\n",
              " 'Your long heavy what least mouth national put test race.',\n",
              " 'Particular court east newspaper different win father eye debate.',\n",
              " 'First give value somebody event business quality here woman stand west source.',\n",
              " 'Among western bad under pretty section degree still even.',\n",
              " 'Receive case past only drug prove most point appear including response beyond side.',\n",
              " 'Who within citizen present thing little.',\n",
              " 'Sense expert experience arrive shoulder present discussion school.',\n",
              " 'Tree company think compare try young.',\n",
              " 'Small control see the face also fear owner up friend lawyer.',\n",
              " 'Modern threat care mean evening speak former room possible responsibility add front.',\n",
              " 'Nothing serious compare task today still middle beautiful protect.',\n",
              " 'Word local very according himself land environment form.',\n",
              " 'Reveal activity president realize artist brother fill if maybe time region financial brother.',\n",
              " 'Happen determine whatever long lawyer writer health reduce tree.',\n",
              " 'Soon stay seven quite other skin moment month gun true born stock.',\n",
              " 'Dark Mr clearly take kind quite response major together knowledge argue car.',\n",
              " 'Lead around left southern rich how staff second official and general.',\n",
              " 'Must art thus worry line expert.',\n",
              " 'Shoulder she within position inside year him thank.',\n",
              " 'Heart radio product much president girl condition Mr more road.',\n",
              " 'Strong series without leg rest interest here discover.',\n",
              " 'Get every visit right both special information she this administration deal.',\n",
              " 'Order land public the each analysis keep.',\n",
              " 'Describe tell argue mean eye staff rule five our pull fly few.',\n",
              " 'Worry miss including every news option same.',\n",
              " 'Personal interview many win walk provide skill five.',\n",
              " 'Impact feel contain Mrs drive different tax certain leg arm include.',\n",
              " 'Newspaper care drug data position two suggest begin right couple environmental.',\n",
              " 'Owner them could seven right next look thank four whatever address view while.',\n",
              " 'Section senior trial receive region however dream.',\n",
              " 'Simply herself move grow end mention market better wonder light.',\n",
              " 'Trial have including none determine certainly end various often individual.',\n",
              " 'Cultural discover now early nearly want front.',\n",
              " 'Whom politics make collection some college result major true my politics arrive.',\n",
              " 'Stuff avoid stand any according case.',\n",
              " 'Discuss religious across media health pay project pattern low maintain according necessary activity morning.',\n",
              " 'Movie expert maybe recently issue vote conference truth modern.',\n",
              " 'Court money spring environment however health image north wrong.',\n",
              " 'Feel stock ball yard practice all if help.',\n",
              " 'Argue act commercial matter its six not teach believe month amount deep.',\n",
              " 'Little another avoid understand tonight nor allow up fire which onto sell require.',\n",
              " 'Up federal nor note support quality music himself science so ready.',\n",
              " 'May window approach join stuff future shoulder.',\n",
              " 'However similar ahead event yeah make green wait it quickly produce beat peace.',\n",
              " 'Require bank child Republican plant science first blood accept.',\n",
              " 'Know seven bill beautiful issue news mention billion bed.',\n",
              " 'Behavior our foot history factor hold be top toward within occur college herself.',\n",
              " 'Especially environmental certainly cold every feel site.',\n",
              " 'Edge east person order crime blood fight we forward per.',\n",
              " 'Key issue statement prepare organization feel owner receive look concern.',\n",
              " 'Why fact reason make office drug heavy staff hotel box nor.',\n",
              " 'Young conference should agree road wall decide something story attorney summer some pull.',\n",
              " 'Plan drug probably resource smile available wrong.',\n",
              " 'Old move type thank industry already why reduce speech order trial body.',\n",
              " 'Price great positive and worker quality hundred sell whole.',\n",
              " 'Black better develop section newspaper reach determine hear leg quickly real.',\n",
              " 'General agency bit indeed which break wait.',\n",
              " 'Give gas six miss give best reveal.',\n",
              " 'Five feel special boy support possible quality clearly worker during company.',\n",
              " 'Former interview left something picture control price how.',\n",
              " 'Third last involve above Democrat everything region somebody officer son Mr hand culture.',\n",
              " 'Energy television month police others particularly only.',\n",
              " 'Goal leader common purpose song try opportunity public finish draw.',\n",
              " 'Consumer really memory industry case himself control.',\n",
              " 'Really population yourself never majority cell fire late approach grow act carry.',\n",
              " 'White measure manager range indeed style major bar air set.',\n",
              " 'Allow different eye sit not significant manager member of.',\n",
              " 'Simple statement happen state among rest national wrong bill.',\n",
              " 'Fear yourself last give stage keep yes simply down.',\n",
              " 'Ready technology particular into pattern size spend south now mother others collection without.',\n",
              " 'Eye environment teach world quickly believe while size try.',\n",
              " 'Term camera tend economic represent stock seven put majority.',\n",
              " 'Plan physical heart away some shoulder idea seek reason theory lawyer maintain old.',\n",
              " 'Room learn professional group as move design.',\n",
              " 'Station manager follow exist natural candidate system small thus several animal.',\n",
              " 'Six least buy tax kid a when dark read car practice city usually ever.',\n",
              " 'Economy head tough close how figure record doctor pretty region.',\n",
              " 'Degree back order mind knowledge account.',\n",
              " 'Stage write institution car audience him room bill finish thing.',\n",
              " 'Him spend themselves political quality attention none.',\n",
              " 'Practice key reveal physical character in rather team beautiful beyond sell operation himself.',\n",
              " 'Fire cause everybody base network outside parent single real summer probably.',\n",
              " 'Day parent country hot position six soldier dream history.',\n",
              " 'Matter order month within would value car team nothing.',\n",
              " 'National common likely would authority onto add democratic two we.',\n",
              " 'Media pick may indeed reduce bar Mr pattern everyone finally memory.',\n",
              " 'Window choice force only shake power poor financial.',\n",
              " 'Role suffer around beat its law participant finally score scientist budget.',\n",
              " 'Reduce clearly well mission situation result cold.',\n",
              " 'Seek them run brother tonight friend investment.',\n",
              " 'Ask Republican office baby lawyer growth matter note happy effort bill off.',\n",
              " 'Direction meeting analysis television each line him.',\n",
              " 'Condition whether along sort research pretty different.',\n",
              " 'Indicate result even back head maybe top conference source.',\n",
              " 'West attention let executive suddenly force.',\n",
              " 'Lead hard factor six science drug happy will young simply run national somebody.',\n",
              " 'According improve do get style theory week.',\n",
              " 'Serve heavy scene film day work.',\n",
              " 'Man art young Republican behavior TV today mind red head window.',\n",
              " 'Oil measure PM hour option artist production.',\n",
              " 'Door end fire song red save fish.',\n",
              " 'Do want carry show board black last finish building.',\n",
              " 'Who debate final enter build citizen rather step recent American.',\n",
              " 'Chance represent why how any federal star community weight take.',\n",
              " 'Security economic left sound cause activity store work candidate statement head piece popular.',\n",
              " 'Only true avoid young cup position speak begin suggest speak business walk anything.',\n",
              " 'Item right many him interview government traditional every land chance pass pay positive.',\n",
              " 'Include nearly article evidence case current this moment piece soon some writer.',\n",
              " 'Look sit general not focus establish ago others ahead specific.',\n",
              " 'Around yard morning short yourself wind beyond prevent entire.',\n",
              " 'Shake way offer work home very.',\n",
              " 'Compare or south recently trial agreement red way.',\n",
              " 'Center way student special wife my compare also argue own after long forward.',\n",
              " 'Cut candidate response try such food against only true similar suffer team whether.',\n",
              " 'Relate product only from follow wish run join police maintain.',\n",
              " 'Company why really up skin development open compare fill read.',\n",
              " 'Concern ability reduce of surface side nothing.',\n",
              " 'Own TV whose determine not view cell seat.',\n",
              " 'Get floor player white start prove role from activity.',\n",
              " 'Economic attack either blue ability history run why.',\n",
              " 'Manage her national big look tell prepare reach class available suffer.',\n",
              " 'After end bit game thousand claim avoid walk within.',\n",
              " 'Order party lot all wall close threat church big day.',\n",
              " 'Important never understand music produce father benefit hotel.',\n",
              " 'Style child guess into far product outside current agent color factor bank such.',\n",
              " 'Size likely thus enter politics hold he high cost.',\n",
              " 'Enjoy let difficult environmental article sell.',\n",
              " 'Beat gas must wife operation network subject.',\n",
              " 'Industry movement term little think live bad total research maybe too song.',\n",
              " 'Challenge we last we cold deep cover amount bad raise dark state challenge.',\n",
              " 'Election treat trial attack hold however for everybody leader them skill performance mission.',\n",
              " 'Both change note old who beyond black single size test they.',\n",
              " 'Enough pressure occur list common idea peace race I how these.',\n",
              " 'Any little environmental head full soldier financial successful teach.',\n",
              " 'Win direction feel season similar fly rock.',\n",
              " 'Population could deep station scientist service test start middle city find medical career.',\n",
              " 'These ahead cover strategy student economic lead truth relate ever statement measure.',\n",
              " 'Race drop major land whether listen necessary.',\n",
              " 'Clear thus see read expect hit clear occur who tax.',\n",
              " 'Question especially important after sister should across treatment.',\n",
              " 'Over across education source figure whom poor interest.',\n",
              " 'Surface learn design few minute perhaps once account yourself whom.',\n",
              " 'No order executive range loss from everybody foot everybody prevent.',\n",
              " 'Could military drive arm tax special identify floor cause.',\n",
              " 'Pretty young else industry home along.',\n",
              " 'Staff gas require rather point little wait grow feel color price next family.',\n",
              " 'Campaign else space several consumer quite friend become great season film small.',\n",
              " 'He one less brother approach plant oil per line create.',\n",
              " 'Test high fear approach take case customer.',\n",
              " 'Would throughout would century television Congress ball forward would finish around.',\n",
              " 'Event seven collection share majority shake because pass plant idea whole.',\n",
              " 'Above move room wear throughout series most adult above safe.',\n",
              " 'Really general can himself open cold statement fear.',\n",
              " 'Lay minute model its rather card you majority seek.',\n",
              " 'Way truth idea direction road capital safe operation.',\n",
              " 'But represent society heart policy side perhaps order.',\n",
              " 'Product president after ready indicate herself.',\n",
              " 'Education reduce day rate act inside big minute performance red industry together memory.',\n",
              " 'Brother box blood cup current enjoy mission cut region far always many debate.',\n",
              " 'Former able public trade structure protect chance bed memory rich big eight.',\n",
              " 'Lead with enough anyone spend them system growth.',\n",
              " 'International break surface three act catch positive forget thus western.',\n",
              " 'There behavior spring consumer husband while even history surface.',\n",
              " 'Power someone both receive around wall city indeed opportunity soon question.',\n",
              " 'Particularly single particularly television they road through low.',\n",
              " 'Both in animal energy fire relate question should office north within prove.',\n",
              " 'Mind read peace item risk loss professional political chance step.',\n",
              " 'Approach poor church support system thank avoid man drive wife anyone development poor.',\n",
              " 'Stage bad know of because material firm wonder seat adult idea.',\n",
              " 'News a before page people fight.',\n",
              " 'None pressure lay future stay staff such forward should outside respond guy.',\n",
              " 'Box service develop game stop who factor miss reduce animal clearly.',\n",
              " 'State score important effect cultural building system.',\n",
              " 'Lead sit response blue increase unit study open.',\n",
              " 'Leader operation mean white above save network item one under sit.',\n",
              " 'Reality community spring billion price paper focus thing.',\n",
              " 'Woman trouble several event white wife laugh card include record security.',\n",
              " 'Successful natural finish say network design decide research rather.',\n",
              " 'Wonder practice when mean reason follow break.',\n",
              " 'No old wall report purpose throw move there institution actually.',\n",
              " 'Agent certainly prove customer seek claim expert.',\n",
              " 'Chair artist six daughter must grow laugh pattern push.',\n",
              " 'Ten score night down six sometimes explain professor unit hold what wish fine.',\n",
              " 'Approach season data than team kitchen difficult plant remember happy open school cultural.',\n",
              " 'Family concern radio cost community message help investment.',\n",
              " 'Enough claim suffer accept letter visit always up others similar personal successful feeling.',\n",
              " 'Nearly authority remain moment whatever minute skill city myself idea glass third professional.',\n",
              " 'Guess despite sell most you statement wonder across protect knowledge.',\n",
              " 'Truth during always those high someone box either rich agency might side method.',\n",
              " 'Knowledge analysis together court message way cold what Mrs account assume prove.',\n",
              " 'Ten interest billion Mrs reflect wish simple position.',\n",
              " 'Section child learn forward beautiful approach.',\n",
              " 'Newspaper offer direction else hold picture item admit pull.',\n",
              " 'Accept result as second animal summer group me face rate paper example.',\n",
              " 'High state air choose detail section someone support far plant fear.',\n",
              " 'Whatever action themselves center among of hour natural be decide.',\n",
              " 'Deep town surface central contain pattern education boy provide note.',\n",
              " 'Surface usually yes leave near fact.',\n",
              " 'Economy culture oil week ground provide.',\n",
              " 'Beyond people too fish late pattern figure once not.',\n",
              " 'Space when collection finish size Republican political everybody growth quickly.',\n",
              " 'There leg grow figure necessary compare parent success teach cause.',\n",
              " 'Cultural safe phone road throughout support place spend often shoulder defense already.',\n",
              " 'Myself your line simple hand development sign run fact.',\n",
              " 'May bed hair action draw who word range serious cell city.',\n",
              " 'We process whose save low grow despite maintain as hard amount deal traditional.',\n",
              " 'Hold truth thing always possible billion why plant event score.',\n",
              " 'Name community president half president structure might heavy trade might good test main.',\n",
              " 'Thought according think key discover method exactly change church own stage produce.',\n",
              " 'Specific result loss long decision claim street against amount of claim.',\n",
              " 'Mention three chair coach two might if wide point these road start water describe.',\n",
              " 'Yeah test color store over some star consider process enough right garden law.',\n",
              " 'Attention her car admit mission training range step painting concern top outside there.',\n",
              " 'Me brother lot candidate owner still to simple power miss have analysis.',\n",
              " 'Investment voice lot shoulder go source traditional student office international effort she.',\n",
              " 'Exist theory impact country remember smile official.',\n",
              " 'Mind heart day sound impact blood international.',\n",
              " 'Effect talk interest hand every quite sense including six lot have never effect.',\n",
              " 'Officer similar huge catch tell budget discover situation we.',\n",
              " 'Democrat hundred full nearly recent religious claim.',\n",
              " 'Source statement likely outside because enjoy.',\n",
              " 'Bag also his worker pass minute represent our watch star.',\n",
              " 'Keep cut prevent sound experience almost outside middle discuss college already dream.',\n",
              " 'Wish beautiful every human prove if.',\n",
              " 'Military say attention bed expect stop trip give.',\n",
              " 'Difficult white lawyer identify above company media next me.',\n",
              " 'Water sort what then spend offer reason whom none show.',\n",
              " 'Which learn leave only agree break attack plant yes quality.',\n",
              " 'Son include good movie red enjoy expert human.',\n",
              " 'Away use live government thus especially water raise travel material.',\n",
              " 'Dog drug enter director strong student green single.',\n",
              " 'Turn put professional pass share must amount.',\n",
              " 'He firm together thing off ever consumer share memory huge seek campaign.',\n",
              " 'Son long must maybe hour rather company with recently least ready activity.',\n",
              " 'Here beyond gun technology cost enjoy especially when.',\n",
              " 'Hand material decision red head take evidence conference capital office.',\n",
              " 'Sport result sound new task cultural son school.',\n",
              " 'South computer matter yet support military result size feel no nothing huge.',\n",
              " 'Art sport live picture last free guess night.',\n",
              " 'General in go quickly paper officer practice Mrs without.',\n",
              " 'Great pull maintain say threat high expert place certain.',\n",
              " 'Political up instead partner if trade bad gas.',\n",
              " 'First fact environment popular even know television guy only whole.',\n",
              " 'Cold take by doctor edge season see decision however believe view.',\n",
              " 'Nature ago however share bar energy choice pressure those finally easy exist.',\n",
              " 'Call money color along ground trip ten level that various nature career way much.',\n",
              " 'Our piece player nor model police finally girl music source kind hand employee.',\n",
              " 'Action model serve carry expert movement reach man sense.',\n",
              " 'Across involve fall discuss account health in night house.',\n",
              " 'Resource position stock determine bad personal might son.',\n",
              " 'Space range expect sea speak include table consumer face PM pay evening performance.',\n",
              " 'Fly charge wide against win example by just.',\n",
              " 'Do character management game find son.',\n",
              " 'Less social form such weight argue simply author like court.',\n",
              " 'Stage stock business should eat side kitchen scene almost.',\n",
              " 'Same behind program decade home which view city rock seat near.',\n",
              " 'Education police cup thought tell design both.',\n",
              " 'Foot cold everybody build smile across among situation little other he.',\n",
              " 'Eat matter rather full wide service art.',\n",
              " 'Popular red social call discussion word small series south just.',\n",
              " 'Again help right economy always religious next my.',\n",
              " 'Couple cost girl run every story trial never attention choice fast enjoy.',\n",
              " 'Law simply media safe third people hair per fly as.',\n",
              " 'Standard couple raise she child executive important focus benefit probably analysis visit.',\n",
              " 'Them dark magazine better number student price moment.',\n",
              " 'Eight hand paper audience us decade man threat bag song art newspaper voice.',\n",
              " 'State some around pay more same strong back democratic mind big.',\n",
              " 'Mother country moment eat personal condition see indeed.',\n",
              " 'Short office purpose reflect interview bit society.',\n",
              " 'Husband front citizen your kitchen good firm yard foot he share issue rise.',\n",
              " 'Drive nation heart nearly season growth laugh where a alone expect administration career.',\n",
              " 'According worker Democrat fire sign wall state try memory.',\n",
              " 'Unit choice also green catch happen old do specific begin hundred truth safe.',\n",
              " 'Society common stay ready office traditional organization feel room office.',\n",
              " 'Sister two free they its us building.',\n",
              " 'Section support up plant place approach modern floor.',\n",
              " 'Change maybe determine anything rule hotel knowledge organization measure develop face hour car.',\n",
              " 'Live seat nature energy huge its recently.',\n",
              " 'Lose cup house number night young modern.',\n",
              " 'Author since food under become public interest give fly.',\n",
              " 'Pretty show college glass start sort perhaps key under do rate choose rock.',\n",
              " 'Both approach we unit than star add.',\n",
              " 'Figure likely forward science deep national seek.',\n",
              " 'Low role center recognize adult on professional analysis color exist smile peace apply.',\n",
              " 'At produce production tree growth blue.',\n",
              " 'Test power discuss herself with between firm term mother.',\n",
              " 'Current whom night Republican always two figure majority.',\n",
              " 'Adult range green few you without every artist.',\n",
              " 'These three spring ahead never exactly charge today prevent.',\n",
              " 'Role minute question their rather individual of.',\n",
              " 'Wife travel forget my deal catch must son television finally relate.',\n",
              " 'Travel involve training show prevent north citizen attack mouth rest contain style.',\n",
              " 'Risk she they increase in kitchen value.',\n",
              " 'Charge could capital ago worry pay paper partner others.',\n",
              " 'Reach grow read live maybe painting Republican hear.',\n",
              " 'Man case cover allow share address establish including score write.',\n",
              " 'At until worry term majority foot leader east.',\n",
              " 'Simply part station result hour voice occur movie political region although.',\n",
              " 'Later still amount yet million how same.',\n",
              " 'Hold share while couple keep this similar experience coach family try ready tough.',\n",
              " 'Stop later reveal both single visit receive career including late condition.',\n",
              " 'To time think bed food possible represent clearly run before relationship plant be.',\n",
              " 'Risk window partner civil nearly analysis color friend the television.',\n",
              " 'Than condition Republican information finally shoulder land phone.',\n",
              " 'Together whether about she activity marriage material.',\n",
              " 'Part management describe process law kind.',\n",
              " 'Outside each natural people newspaper stay any challenge president already take project study.',\n",
              " 'Former because board year claim expect produce record occur.',\n",
              " 'Concern lay often use behavior federal happy her attack interview nearly fall care.',\n",
              " 'Forget including decide decade around number without more because.',\n",
              " 'Value worry expert participant first moment yet government can none mind place manage.',\n",
              " 'This discussion fact cover brother let someone scene.',\n",
              " 'Son yourself increase free night point action cut.',\n",
              " 'Effort attack feel nearly short box four how notice.',\n",
              " 'Story create street two look listen.',\n",
              " 'Population loss physical throughout Mr friend.',\n",
              " 'Until argue minute north question new affect officer forward trouble somebody.',\n",
              " 'Wide exactly all worker phone success.',\n",
              " 'Paper cost bring site final tax report even beautiful theory he stop few.',\n",
              " 'Few born size sing tree kitchen agent lot matter couple type run.',\n",
              " 'Financial force show better word might yeah day already hold ten break.',\n",
              " 'Usually reach organization beautiful level animal minute probably fine.',\n",
              " 'Serve police decide customer expert mother significant provide evening church boy when nice.',\n",
              " 'Deal go five center region exist each.',\n",
              " 'Find throughout music anything ahead tough.',\n",
              " 'Black approach interview condition other or.',\n",
              " 'Pattern fine stage require provide move wind sense letter capital spend.',\n",
              " 'Best financial popular short like water century time election guy contain.',\n",
              " 'Small think law air little goal leave color should page.',\n",
              " 'Meet if research blood news audience few.',\n",
              " 'Husband including per nature wind himself future sport opportunity six itself.',\n",
              " 'Name door production back us off main option leg never.',\n",
              " 'Computer what attorney board sport side her management produce bed stage.',\n",
              " 'Tough player a chair chance most hope official crime race first now tree.',\n",
              " 'Truth view response trip wrong old particularly member summer.',\n",
              " 'Artist too whose a nice without body executive all.',\n",
              " 'Reduce hour fish him high nation production little could his under.',\n",
              " 'Child young prove care author administration return main join wrong be.',\n",
              " 'Team throw receive us perhaps lawyer interest star his difficult interesting.',\n",
              " 'Official suggest door maybe improve national.',\n",
              " 'Almost also low happy oil which bag room money teacher.',\n",
              " 'Let back three because line score whether back plant.',\n",
              " 'Fine apply gas sing light mention light safe inside whether sometimes eye along.',\n",
              " 'See risk nor article list college appear wrong speak person expert bar measure.',\n",
              " 'Edge past every either scientist page travel school process.',\n",
              " 'Space end red machine son television garden base certain value.',\n",
              " 'Study sell include himself produce rise cold.',\n",
              " 'Same generation politics sense break cold human feeling second sell mouth here relationship.',\n",
              " 'Enjoy most itself eye something high firm morning what best most government.',\n",
              " 'Particular present evening establish sort effort once leave push drop public.',\n",
              " 'Mind question year finish action across attack in.',\n",
              " 'Billion land detail exist cover agency begin voice prevent structure wear point.',\n",
              " 'Beat painting heavy shake possible sort continue.',\n",
              " 'Receive education level view police two everybody.',\n",
              " 'Realize property show either sit everyone artist home you election spend.',\n",
              " 'Key man up particular condition man century shoulder.',\n",
              " 'Pass blood kid else alone audience road since.',\n",
              " 'To chance policy usually professor entire.',\n",
              " 'Toward off middle vote make job such sit size music.',\n",
              " 'His ready sister building movement yard.',\n",
              " 'Radio hundred place where before movement which ball least short.',\n",
              " 'Computer always his course receive to piece grow.',\n",
              " 'Those just country along agent you draw.',\n",
              " 'As music film move strong last yet already argue skin.',\n",
              " 'If deep president mission vote thank.',\n",
              " 'Chance often under already center president likely truth animal red candidate common.',\n",
              " 'Toward star best particularly structure ask.',\n",
              " 'Box organization past as dark front structure.',\n",
              " 'Food wish office case student soldier share or friend building center.',\n",
              " 'Collection have close during old card social place heavy citizen they.',\n",
              " 'According conference become prepare thought indicate southern.',\n",
              " 'Realize deal policy mission include visit particular also conference matter wear physical.',\n",
              " 'Girl above dog brother morning believe gun seven music.',\n",
              " 'Less phone decade apply both chance such treatment.',\n",
              " 'Computer prove amount population expect itself free source serve analysis science understand.',\n",
              " 'Citizen ahead method audience dog know often industry.',\n",
              " 'Discover body direction down include customer through available one approach.',\n",
              " 'Certain until lawyer hold carry rest place wish dark camera realize.',\n",
              " 'Exactly book letter industry set detail.',\n",
              " 'Page smile point particularly color wife talk beat tax.',\n",
              " 'Television describe list leg address into their easy its develop until watch.',\n",
              " 'Together individual analysis yard safe mean international hour special recent better manager bar.',\n",
              " 'Really image design grow dream your.',\n",
              " 'Look fight reflect teach section agency.',\n",
              " 'Less catch reflect continue the phone region ability physical his real.',\n",
              " 'Allow international especially watch my some skin ball thing save area war.',\n",
              " 'Thousand book half people half compare next attack remember daughter.',\n",
              " 'Draw box long voice oil where decide seat different good.',\n",
              " 'Me institution approach health laugh may stop like mother.',\n",
              " 'Tonight later happy pull really within third could this beautiful hospital condition.',\n",
              " 'Body every recent many themselves minute.',\n",
              " 'Age indicate radio use listen information scene again country against soon strong mind from.',\n",
              " 'Garden position for order recent success knowledge fight car smile commercial employee machine.',\n",
              " 'Show another good lay coach under Republican expect win.',\n",
              " 'Claim bring year off kid hard day.',\n",
              " 'Program within challenge large wish move.',\n",
              " 'Turn identify material certainly leader floor above.',\n",
              " 'Wish former relate listen face want wonder off chair north trade kind.',\n",
              " 'Rule too cause nearly final husband subject.',\n",
              " 'Group for part crime money sit short cultural base support quality.',\n",
              " 'Wish hour make owner memory argue project.',\n",
              " 'Challenge take hard health expect goal within them because road know.',\n",
              " 'Sound eye south wife interest to cause onto beat debate listen.',\n",
              " 'Would at whether series because important trial increase new report sense carry.',\n",
              " 'Strategy face make state few one management science.',\n",
              " 'Agree able enjoy what strong line president throughout.',\n",
              " 'Conference trade population agreement share manage wife out gun lose job.',\n",
              " 'Physical live reason build mention offer suddenly clear around.',\n",
              " 'Leave really group apply guess player western any factor police.',\n",
              " 'Message short consumer behind sell myself.',\n",
              " 'Step rate feeling rate read benefit oil statement actually million.',\n",
              " 'Single include TV clear design me story somebody next ready.',\n",
              " 'Suffer Republican reduce sort individual trouble bring capital admit give reality catch.',\n",
              " 'Threat our shake garden report agreement sport develop task central dinner.',\n",
              " 'Decide wonder interesting several born affect machine.',\n",
              " 'Amount blue soldier message arrive budget education at property senior site.',\n",
              " 'Day top continue goal before suffer walk we girl civil may rock drop.',\n",
              " 'Attention standard shake more respond who commercial senior above rise under turn surface.',\n",
              " 'Hand operation keep whatever Congress great here Democrat dinner both world buy.',\n",
              " 'Mind many guess explain reveal bank management.',\n",
              " 'Exist outside find wish know network fact talk country attorney.',\n",
              " 'Voice happen actually purpose public how mission put budget house reason within.',\n",
              " 'Ask window full organization wrong but study rise.',\n",
              " 'Share she order series song wall green project wear.',\n",
              " 'Memory challenge lawyer business majority discuss wall ahead scene store marriage ago.',\n",
              " 'Him quickly check perform benefit baby seem should.',\n",
              " 'Dark product make energy gas teacher national weight all involve trip.',\n",
              " 'Late table kind along computer process single those clearly issue.',\n",
              " 'Resource maintain body push process rate occur live take.',\n",
              " 'Argue enjoy opportunity help put short expect article opportunity campaign hand special.',\n",
              " 'Agree through game best generation group goal product easy possible or travel assume.',\n",
              " 'Boy college Mrs also price institution method inside after.',\n",
              " 'Onto worry help hope occur space beyond push from me share fund.',\n",
              " 'Federal wide cut player wind away sure degree enter father of source person.',\n",
              " 'Response official option event note most interview.',\n",
              " 'Somebody prepare few sound item music customer I person law.',\n",
              " 'Congress affect reflect television officer defense while score level view mouth pass shoulder.',\n",
              " 'Various risk art customer leg drive second she such improve team.',\n",
              " 'Plant suffer environment expert civil rather.',\n",
              " 'Image box court early still less nice job positive.',\n",
              " 'Dark evening ahead smile everyone nearly.',\n",
              " 'White magazine after teacher base own.',\n",
              " 'Too imagine guy price bed wall.',\n",
              " 'Door number matter building professional oil simple.',\n",
              " 'Edge this draw business southern forget once hope security door institution certain.',\n",
              " 'Degree ever impact television argue mouth record both.',\n",
              " 'Interest radio white these view guy resource start again whom paper success.',\n",
              " 'Real small dream need finally when.',\n",
              " 'Total rate movement door kind account whether until truth feeling.',\n",
              " 'Father teacher civil keep first speech popular smile ever.',\n",
              " 'Statement wait likely include subject response theory.',\n",
              " 'Station recognize media goal own spend scene.',\n",
              " 'Receive seven political contain kitchen political able customer figure office book.',\n",
              " 'Might wide store shake suggest rate society floor long.',\n",
              " 'End reach step son cup increase consider.',\n",
              " 'War this difference way type positive phone trade wind cup.',\n",
              " 'Anyone peace outside chance when color note add.',\n",
              " 'Itself turn law purpose budget require course technology site explain management candidate.',\n",
              " 'Outside yet executive quality industry impact certainly face.',\n",
              " 'Dog late eat old positive beat light the window.',\n",
              " 'Rather require remain save eight believe arrive four dog traditional you.',\n",
              " 'Remember special accept mean herself within provide car throughout American conference college manage.',\n",
              " 'There car fish most center bring analysis campaign the strong.',\n",
              " 'Unit executive theory party seven enough fine throughout firm yes.',\n",
              " 'New type PM key country approach consumer.',\n",
              " 'Employee relationship job yet until American ground remember magazine manage suffer term.',\n",
              " 'Glass data exist strong seek state none.',\n",
              " 'Defense your above short Congress turn east marriage behind forget expect wonder business.',\n",
              " 'Opportunity week student child ball store process law western order.',\n",
              " 'Forget analysis performance laugh water yourself.',\n",
              " 'Can tell soon executive sometimes season natural own begin effort drive side human.',\n",
              " 'System clear single expect sell pressure.',\n",
              " 'Fear song save TV tough page grow.',\n",
              " 'Story mention majority those live none institution.',\n",
              " 'Specific pass its international American game less difference rather choice manager.',\n",
              " 'Positive base life bad soon feel worker range feel eat into notice necessary true.',\n",
              " 'Blue interesting behind produce nothing effect effort bank me box product conference.',\n",
              " 'Successful and indicate region finish right serious last.',\n",
              " 'Game truth special decision back word else pull its.',\n",
              " 'Accept bring commercial local reality than.',\n",
              " 'Rise field spend pattern real white push source because career course staff receive.',\n",
              " 'Teacher decide possible power job personal so course.',\n",
              " 'Show challenge instead bring total school knowledge machine after.',\n",
              " 'One cut notice street anything account piece require woman support say.',\n",
              " 'Room yourself already hundred message right very toward test discussion art affect office.',\n",
              " 'As throughout individual list manager voice get recently again explain court gas discussion.',\n",
              " 'Onto rate two table resource life third rich.',\n",
              " 'Where strategy pull same somebody son suddenly perform executive see.',\n",
              " 'Can current paper beyond indeed year field decide another adult thing ground.',\n",
              " 'Company teacher me southern front box dinner no.',\n",
              " 'Election future great another there environment character real middle prove relationship unit.',\n",
              " 'Sometimes while sense window sit participant teach big none medical cold.',\n",
              " 'That treat church factor kid media run.',\n",
              " 'Child hair standard but dark wide shoulder.',\n",
              " 'Early speak game measure be head.',\n",
              " 'Guess professor charge send instead direction soon including important learn system.',\n",
              " 'Want kind show response military attorney full I sign its.',\n",
              " 'Service produce political total around place require produce mind fast I.',\n",
              " 'Them return finish general still too particular chair identify popular thought person peace.',\n",
              " 'Recently thought sit identify culture feeling already free rise science call.',\n",
              " 'Exist behavior necessary miss serious civil agreement someone or drop similar risk.',\n",
              " 'Book art health phone great answer prepare by fear say law work.',\n",
              " 'Not thus physical mouth other go expect size resource public research mind easy.',\n",
              " 'Might court sing lawyer chair international include begin interesting candidate.',\n",
              " 'Land hard moment open million house enough material.',\n",
              " 'You ready way rule indicate clear media machine leader whose message.',\n",
              " 'Brother defense list second want hard weight own impact building occur American.',\n",
              " 'Brother figure hear family agreement central six.',\n",
              " 'Any thus threat democratic standard major business give that individual of.',\n",
              " 'Laugh full help strong street car catch PM seven project chance road become.',\n",
              " 'Professor important do house must when three save position tend religious occur someone.',\n",
              " 'Night buy nice court peace officer apply now country.',\n",
              " 'Me affect probably mother while ever day stop stuff often be move.',\n",
              " 'I and technology age join increase teacher fish either boy.',\n",
              " 'My experience consumer shoulder child weight question.',\n",
              " 'Pass foot agree around hope floor.',\n",
              " 'Throw election walk tonight appear dream others door meet mean we.',\n",
              " 'Art let imagine machine imagine do though especially white.',\n",
              " 'East never size fight image base player.',\n",
              " 'Situation central music collection early weight which new.',\n",
              " 'A let stop eye will a.',\n",
              " 'Event economy quite yourself successful defense subject example claim move attorney bed.',\n",
              " 'Store rise your there decision measure soon.',\n",
              " 'Play woman remain event production focus decision where foreign trial.',\n",
              " 'Position ability live top pull including time.',\n",
              " 'Several Mrs skin power back all story public public good spend still.',\n",
              " 'Hit stuff speech worker by have cover act sea serve.',\n",
              " 'Course staff personal space determine woman whose already manage region.',\n",
              " 'Decide cultural start how thank notice management necessary process not radio north assume.',\n",
              " 'Second camera value talk thing rock ever.',\n",
              " 'Yeah realize mouth education nice law.',\n",
              " 'Political wall appear voice item yet ever quite level guess service.',\n",
              " 'Another truth mother first hot free they space.',\n",
              " 'Within interest avoid economic clearly financial personal benefit.',\n",
              " 'It agency something various subject east list when strategy start mind door.',\n",
              " 'Simply people shake personal often beat.',\n",
              " 'True help three really site artist.',\n",
              " 'Area particularly it big argue appear sure I pay in ten.',\n",
              " 'Action himself somebody they people fund visit situation law foreign court bill organization.',\n",
              " 'Or subject toward call meeting green.',\n",
              " 'Right know during someone art find job where senior find those simply.',\n",
              " 'Light owner fact wife military price certain.',\n",
              " 'Medical strong teach instead crime customer training size game.',\n",
              " 'Reason word outside former official white pattern industry class lawyer smile among.',\n",
              " 'Turn police really level defense lose shoulder spring.',\n",
              " 'Day contain wrong guy available air boy fact create one.',\n",
              " 'Analysis ahead cup company those responsibility fund never condition again.',\n",
              " 'Treat again quality her skin book very figure drive.',\n",
              " 'Produce wait with young think there assume certain under some.',\n",
              " 'Mouth reason fish involve player TV several onto.',\n",
              " 'Family chance easy picture evidence call meet once major road six social.',\n",
              " 'Ask meet seem population meeting material less focus hear reason resource manager environmental.',\n",
              " 'Point so power debate thus later doctor despite interesting help church.',\n",
              " 'Effort be seem far million discover American mention from later.',\n",
              " 'Important source first him conference doctor population grow bar successful mention.',\n",
              " 'Skill unit better author although customer cultural.',\n",
              " 'Economic seat shoulder suddenly course page case talk respond myself.',\n",
              " 'Across federal state situation identify if oil pretty line.',\n",
              " 'Writer week tend dinner rich decide do only need light sport future.',\n",
              " 'Fine could show recently decide last next.',\n",
              " 'Catch them figure scene matter probably great different international sell.',\n",
              " 'Federal only nothing allow cause with yes nothing sometimes trial off hospital.',\n",
              " 'Daughter hospital move could board notice later thus behavior bit.',\n",
              " 'Concern step owner agree current treat history day fact modern lawyer happy action.',\n",
              " 'Teacher improve church book movie long attention western tend candidate.',\n",
              " 'Finally stand professor city offer financial data respond.',\n",
              " 'Every account central ask human space moment travel these least office.',\n",
              " 'Explain thing lead red Republican father party.',\n",
              " 'Indeed conference pay it his probably recognize believe.',\n",
              " 'Dream that event physical factor trouble.',\n",
              " 'Training in seven building hard sense mean single.',\n",
              " 'Late education media left available reason see high second talk however.',\n",
              " 'Economy remember carry prove less leave.',\n",
              " 'Nature drug wear cell star success color.',\n",
              " 'Parent concern buy scientist collection provide.',\n",
              " 'Quality child group describe alone push.',\n",
              " 'Kind answer play mission production process bill real.',\n",
              " 'Appear above significant short up hear draw before instead writer front.',\n",
              " 'Quite as when benefit structure professional right analysis.',\n",
              " 'Blue force no couple debate must voice building degree ground community I.',\n",
              " 'Activity defense detail price everything perhaps analysis those in should.',\n",
              " 'Work big movie wrong sure commercial where outside wonder recent question win.',\n",
              " 'Forward play this fish surface lot friend.',\n",
              " 'Treatment large memory score me relate actually again serve buy door investment during.',\n",
              " 'Art hear father charge daughter also type.',\n",
              " 'Write kitchen theory care fish skin always social increase spend seek director run.',\n",
              " 'Drug much trade professor eat reach rest part high focus.',\n",
              " 'Picture ask man west appear yeah voice by community nature somebody.',\n",
              " 'Door back right find return each computer eat.',\n",
              " 'Office whose cut television loss week growth help likely.',\n",
              " 'Measure same set standard soldier after high take serve TV organization.',\n",
              " 'Need compare herself figure exist no lose.',\n",
              " 'Carry light choice couple actually may rise man understand wait.',\n",
              " 'Himself film would author those yeah buy usually class several.',\n",
              " 'Side seem give remember play happy around history interest.',\n",
              " 'Drug alone spend piece put recently population end lay.',\n",
              " 'Effect own weight success activity side popular.',\n",
              " 'Huge only too million country institution stop education few whose.',\n",
              " 'Only safe sell under thank body of something sport especially.',\n",
              " 'Us huge final would staff ability attorney recent.',\n",
              " 'Indicate explain issue computer control care main me book note defense cut.',\n",
              " 'Speak court work the key tree body player.',\n",
              " 'Fall help everybody garden one long pull.',\n",
              " 'Act entire western program smile among decision.',\n",
              " 'Heart mind while entire magazine series.',\n",
              " 'Investment he three yourself stage wait professor her arm green form beyond lead.',\n",
              " 'Rise thousand catch own than evidence recognize spring happy peace probably.',\n",
              " 'Method produce about point walk focus plant them wide save question do.',\n",
              " 'Hundred partner bank into use us would tax toward safe family crime.',\n",
              " 'Thank then size respond all marriage beautiful.',\n",
              " 'Would level to western lot music during color want record black year ahead.',\n",
              " 'Total short detail election live today but career movement rise.',\n",
              " 'Somebody four difference office under ask gas.',\n",
              " 'President size whom join do else fact born future or.',\n",
              " 'Seat break happy table west officer ability artist.',\n",
              " 'Couple hold interest side something value call professional opportunity blood across system.',\n",
              " 'Certain wall student matter lay own certainly program soon reflect.',\n",
              " 'Floor maybe read event summer off piece democratic factor whom arrive special check.',\n",
              " 'Summer various different save type simply task road.',\n",
              " 'Worker process summer yard nature front question wrong serious.',\n",
              " 'Author risk executive type red nature best food social tend approach.',\n",
              " 'Leader clear case receive fact certain design security same.',\n",
              " 'Gun task big size teach heavy.',\n",
              " 'Quickly collection argue green listen war bring middle full its chance.',\n",
              " 'Each budget however few other common seat simply yard provide bed.',\n",
              " 'Ten practice every president happen build bar majority protect meeting age.',\n",
              " 'Would look really behind or himself yourself reflect fear by foot research television.',\n",
              " 'Continue spend after new movie speech major million once research so buy.',\n",
              " 'Whole today Congress out conference never song but.',\n",
              " 'Offer present because either send be by.',\n",
              " 'Hair name institution war a feel watch mind situation.',\n",
              " 'Knowledge officer reason mission worry goal Mrs decide between standard down could.',\n",
              " 'Task Democrat care need option everyone rock instead near.',\n",
              " 'High tough hundred bar effect international reason movie audience.',\n",
              " 'Yet recent cover head price star painting information child.',\n",
              " 'Her who easy establish mother range image forget become training sing.',\n",
              " 'Than difficult act help why her bit.',\n",
              " 'Compare rock fill start majority more red.',\n",
              " 'Necessary parent to color water hope generation scientist whose.',\n",
              " 'Necessary think I or else rather require price central nothing environment truth.',\n",
              " 'Religious eat participant religious consumer worry sometimes maybe every into.',\n",
              " 'Figure teach water image fine bed bag role.',\n",
              " 'Close arm sea never manage them while.',\n",
              " 'Quality usually carry marriage rate quality mother by add couple story.',\n",
              " 'Research reflect see each school week.',\n",
              " 'Range amount large collection us shake tough company happen card government anything.',\n",
              " 'Here health both trial economic much short brother federal family defense scene.',\n",
              " 'Hour type upon where middle throw very throughout summer arm accept leave fear.',\n",
              " 'Accept three control great big man be.',\n",
              " 'Together improve tree according show economic likely hear hair throughout movie especially.',\n",
              " 'Prevent keep cause section accept third remember book expect card inside.',\n",
              " 'Too civil current look professor entire inside nearly son research.',\n",
              " 'Seem sister hundred rise score stay capital whatever society call.',\n",
              " 'Matter should door question garden with scene its face magazine.',\n",
              " 'Easy check memory economic short ten yes easy star cup relationship.',\n",
              " 'Red maybe Congress yeah option play director.',\n",
              " 'Husband event court certainly adult current ten.',\n",
              " 'Imagine fill plan discuss from look member popular fight especially.',\n",
              " 'Wall represent east time consider a produce focus experience.',\n",
              " 'Training beyond continue way hair fight best add necessary.',\n",
              " 'Former scientist guess single more he practice.',\n",
              " 'Once beautiful blood picture own American why this.',\n",
              " 'Cover knowledge better walk people feeling listen set.',\n",
              " 'Result analysis court nearly education theory table trade window thus large response.',\n",
              " 'Attack industry use mean against out recent can animal not some.',\n",
              " 'Scientist however range that will close seek his.',\n",
              " 'Husband even contain civil design recent these so lay remain.',\n",
              " 'Else system fast environmental budget difference move factor policy walk everyone card.',\n",
              " 'Politics eat statement movement ability girl.',\n",
              " 'Win foot watch this enough card together far world personal action green room.',\n",
              " 'Computer will Mr without sing sister blood second high.',\n",
              " 'Thank plant nearly stage determine environmental ok space send.',\n",
              " 'Land role its chance look many least.',\n",
              " 'Country make role positive again clear concern hour.',\n",
              " 'Could century interview lawyer population I right case seek activity between himself body.',\n",
              " 'Shake popular analysis eat base central.',\n",
              " 'Outside society act social my stand system be cause service throughout spring film look.',\n",
              " 'Argue reality physical but stay bill father memory student.',\n",
              " 'Ability difference dinner history government expert TV.',\n",
              " 'Rather resource top man yard different what example baby free.',\n",
              " 'Type turn time page concern most outside quickly change project.',\n",
              " 'Person expert then even material hard enter trade sometimes.',\n",
              " 'Technology within sing chair challenge land.',\n",
              " 'Spring both into risk certain follow camera should good management loss win.',\n",
              " 'Soldier four soon president early industry market move mouth start his ok instead.',\n",
              " 'Since specific despite beautiful gun data sure gun listen card body treat guess.',\n",
              " 'Far century table will tree drug still.',\n",
              " 'Section bring receive central run receive.',\n",
              " 'He reduce production available study that air half bad baby notice.',\n",
              " 'Change consumer sea security recognize federal in front sit receive expert.',\n",
              " 'Art politics page community civil how interest.',\n",
              " 'Never stop try maybe remember interest church win miss within by.',\n",
              " 'Hundred argue hot state wish painting baby realize.',\n",
              " 'Finish politics still close sound position crime board back owner suggest agreement.',\n",
              " 'Clear blood deep action travel could cut upon drive.',\n",
              " 'With north nor so animal fire want.',\n",
              " 'Wonder seem when matter fire hospital.',\n",
              " 'Wind reflect best imagine scientist big space change onto him.',\n",
              " 'Than also claim radio bad personal well discuss democratic race cell responsibility year.',\n",
              " 'Might rock prepare us game size fund growth task issue three similar.',\n",
              " 'Dream young parent when note yes best address short finally.',\n",
              " 'Material lawyer college fast attention office government.',\n",
              " 'Condition sign election list eight theory.',\n",
              " 'Vote will major guy expert important people.',\n",
              " 'Kid mention person finish base including late.',\n",
              " 'Per popular scientist each start account.',\n",
              " 'Fact citizen human authority hold left behavior.',\n",
              " 'Life movement stand board Congress board where however item husband ask.',\n",
              " 'You main reduce live everything although choose like policy floor.',\n",
              " 'Write similar artist speak smile without.',\n",
              " 'Approach test well raise establish player base attorney.',\n",
              " 'Bank them later information degree throw contain approach time investment white.',\n",
              " 'Clearly glass industry little read claim recent great realize.',\n",
              " 'Statement night throw cup reveal official certain professional statement same.',\n",
              " 'Add to value material first society purpose enjoy reveal write.',\n",
              " 'Plant police official already second could recent.',\n",
              " 'Over democratic decide course quickly western have hair.',\n",
              " 'To maybe test record power lay improve goal my.',\n",
              " 'Wind from unit learn health need class job expect process quite plant.',\n",
              " 'Visit town between because student bed administration usually billion seek perhaps name plant.',\n",
              " 'Ok allow face inside development lawyer high crime light buy whose trial.',\n",
              " 'Traditional population six how vote site medical environment probably film total.',\n",
              " 'Pull above training allow ago so subject million scientist fish color.',\n",
              " 'Year drop wind cover popular stock soon official can player within community tough.',\n",
              " 'Citizen discuss report call brother officer hot several true study city follow.',\n",
              " 'Behavior join pick order agreement remain turn.',\n",
              " 'Occur agent safe work play sing cost.',\n",
              " 'Father movement early sister skill side process ever.',\n",
              " 'Physical point often billion learn other blood.',\n",
              " 'Energy Congress back suddenly tree debate beyond somebody including.',\n",
              " 'Where baby reach heart finish traditional speak conference act condition note parent.',\n",
              " 'Bring garden get yet outside above.',\n",
              " 'Score unit cover ahead age memory charge term boy describe foreign detail.',\n",
              " 'Environment loss well give necessary family seat.',\n",
              " 'Job watch two economic cup suffer response which bill soldier onto close.',\n",
              " 'West maintain third interest section staff performance parent.',\n",
              " 'Current good today standard last threat when education important page theory.',\n",
              " 'Good air conference follow so group authority prevent head single business five.',\n",
              " 'Response degree nothing focus discussion at.',\n",
              " 'Own money bill everyone part third teacher avoid throughout.',\n",
              " 'Radio itself spend cup anyone management another ever budget laugh over.',\n",
              " 'Him office expect popular task write treatment expect success idea time truth although.',\n",
              " 'Attorney believe sort rich ever send.',\n",
              " 'Bag simple management another fear worker management political treat successful visit.',\n",
              " 'Ahead answer action black follow reach job.',\n",
              " 'Because right speech staff Mr above read appear.',\n",
              " 'Book water avoid forget partner speech.',\n",
              " 'Recognize understand on build floor challenge once sure time.',\n",
              " 'Property miss drive long majority exactly significant lot begin she represent.',\n",
              " 'Next their process same day back will art actually democratic.',\n",
              " 'Could bit decade opportunity month teach set find law child.',\n",
              " 'Black candidate true history laugh per data hundred attention institution rather week.',\n",
              " 'Possible challenge then seat drive thus cost agreement product laugh enter until base.',\n",
              " 'Deep however issue free kid have any him up create country.',\n",
              " 'Order morning management item race position where detail.',\n",
              " 'Time offer draw mother every third.',\n",
              " 'Hot big safe they environmental day size girl explain others safe.',\n",
              " 'Continue traditional performance school system reach color.',\n",
              " 'Coach forward lay while program into.',\n",
              " 'Concern enough baby quickly table order.',\n",
              " 'On major easy body standard note wrong structure moment cold chair behind.',\n",
              " 'Sound friend make go nation professional effect learn still.',\n",
              " 'Report through simple tax total other both rate rock.',\n",
              " 'Challenge improve detail yes ground all.',\n",
              " 'Scientist wind grow season create western police whole theory quickly tonight last when.',\n",
              " 'Company travel give former operation war everybody course often reduce street but.',\n",
              " 'Note society get body across until chair race model face newspaper.',\n",
              " 'Field explain son administration American executive or apply.',\n",
              " 'Above good street anyone case these size maybe when.',\n",
              " 'Choice beat establish you culture one ball despite list great speech PM institution.',\n",
              " 'Throw turn others community job then source.',\n",
              " 'Raise current career never feeling beat note.',\n",
              " 'Leave contain site street benefit money reason mean rate group government level which leave.',\n",
              " 'Ago short because cell trade skill oil health per tonight there apply suddenly.',\n",
              " 'Idea accept space themselves least approach area.',\n",
              " 'Four best fact loss former article science.',\n",
              " 'School apply day century science manager difference put system feeling financial writer.',\n",
              " 'South perhaps customer attack check they.',\n",
              " 'Best daughter listen strategy kitchen argue business identify work star success national.',\n",
              " 'Race teacher pay it player continue stand price color score national live face.',\n",
              " 'Where manage property hospital recently blue indicate.',\n",
              " 'Challenge exist build hope oil alone practice price know traditional great.',\n",
              " 'Life rich everybody word group task me.',\n",
              " 'Total modern message company charge pretty none least teach cause.',\n",
              " 'Type attention stuff low while paper Congress remain medical.',\n",
              " 'Else recently open oil once stop attack ahead run discuss professor material.',\n",
              " 'Food discuss sign true somebody black thing rock himself wind two artist.',\n",
              " 'Boy suggest authority shake paper subject type fly recognize.',\n",
              " 'Card PM news cultural make quickly different score its more.',\n",
              " 'Beat agency where benefit almost cell accept similar.',\n",
              " 'National author continue role treat politics many strategy now list goal peace next.',\n",
              " 'Soon keep personal them notice camera military.',\n",
              " 'Brother discover own former difference wait two.',\n",
              " 'Hospital group their citizen explain move drop military particularly.',\n",
              " 'Human arm recently book likely true enjoy air full.',\n",
              " 'Customer thousand arrive daughter stage form serious treatment artist.',\n",
              " 'Authority way toward reflect she along wonder wear our partner ball necessary.',\n",
              " 'Establish among along medical practice it field.',\n",
              " 'Again area similar specific move team radio scene.',\n",
              " 'Lot hit help by red near break brother past tough goal gas truth.',\n",
              " 'Discussion open dinner section thousand soldier nothing yard address.',\n",
              " 'Spend baby camera Congress analysis glass pretty each factor.',\n",
              " 'Huge price prevent baby voice day relate spend today teach kitchen few happen.',\n",
              " 'Fall president money environment recently me approach too relationship perform evidence data case.',\n",
              " 'Discover score decision head staff center within recognize practice law box material.',\n",
              " 'Establish open feel whole arrive take.',\n",
              " 'Manager television his and day continue issue appear figure must.',\n",
              " 'Visit travel senior from stock energy send describe agree rise.',\n",
              " 'Its into role save arm body hold return question teach visit less occur.',\n",
              " 'Shoulder employee whether level yeah draw traditional exactly radio ever your side fast.',\n",
              " 'House past gun process site special part buy nothing fly enough condition leg.',\n",
              " 'Across already grow point news impact often bag today necessary well.',\n",
              " 'Conference she everybody than camera piece chair peace anyone boy although.',\n",
              " 'Team oil among response article research else either question tax government responsibility.',\n",
              " 'Doctor board medical both back daughter now stop race author interview executive agency.',\n",
              " 'Small friend impact present likely wind perform civil and us treatment agent participant.',\n",
              " 'Member sit meet ok general Democrat store allow risk high.',\n",
              " 'Western when yeah not young piece safe.',\n",
              " 'Run summer month anything line modern kid especially structure fall during during.',\n",
              " 'Discuss fire win realize knowledge whatever improve bag night baby.',\n",
              " 'President painting large industry notice step by Mrs simply imagine.',\n",
              " 'Program painting somebody game brother impact measure chance management thing cup conference law.',\n",
              " 'Building enjoy never us sea call alone issue.',\n",
              " 'Wrong car term truth toward great I news.',\n",
              " 'Budget today together option pattern yes and school great.',\n",
              " 'Treat piece scientist job serious record safe rich operation star meeting.',\n",
              " 'Time order have power here just meet.',\n",
              " 'Evidence significant discussion manage answer military modern meet up expect himself serious well.',\n",
              " 'Sport same writer decision mind offer.',\n",
              " 'Fire girl close explain main difference college voice else paper blood discuss everything.',\n",
              " 'Deal stuff senior agree total whether music.',\n",
              " 'According strategy ago data walk number rule minute.',\n",
              " 'Far body relationship suddenly know it enjoy ten year rule bring.',\n",
              " 'Sound season develop avoid church friend law save public available.',\n",
              " 'Throughout although beyond relate miss couple newspaper study personal we.',\n",
              " 'Account carry heavy wall pull enter charge sport safe executive cup then week tax.',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-SgLDedylMD",
        "outputId": "99cd3b6b-1b4c-4b9a-f9a9-2976a7aa29c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "v3R2UnVRyq6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer(num_words=10000)"
      ],
      "metadata": {
        "id": "SZSy27-Ny1kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=tokenizer.texts_to_sequences(texts)"
      ],
      "metadata": {
        "id": "9XUgpG9WzA40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uUBWAJ5zFg1",
        "outputId": "4b71f9f4-07bb-4585-f8dc-d2dce77f41ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[738, 228, 739, 821, 378, 191, 650],\n",
              " [330, 29, 379, 487, 192, 782, 229, 740, 282, 42, 822],\n",
              " [230, 30, 331, 117, 741, 29, 231, 22],\n",
              " [651, 91, 283, 590, 284, 118, 285, 652, 119, 120, 783, 784, 332],\n",
              " [424, 193, 23, 425, 16, 43, 785, 426, 742],\n",
              " [333, 956, 286, 121, 334, 743],\n",
              " [957, 696, 92, 335, 653, 75, 122, 427, 428, 76, 591, 232, 194],\n",
              " [592, 233, 915, 697, 336, 593, 698, 120, 429, 123, 699],\n",
              " [744, 870, 700, 195, 337, 338],\n",
              " [5, 60, 44, 594, 339, 234, 488, 287, 288, 31, 654, 289, 16],\n",
              " [538, 430, 340, 61, 290, 235, 340, 952, 786],\n",
              " [697, 45, 964, 431, 696, 871, 936, 432],\n",
              " [380, 291, 76, 118, 823, 787, 152, 539, 341],\n",
              " [46, 655, 489, 32, 656, 196, 24, 197, 342, 788, 153, 236],\n",
              " [490, 491, 492, 62, 595, 824, 343, 745, 237, 2, 330, 596],\n",
              " [540, 292, 238, 433, 825, 124, 344, 541, 542, 77, 434, 381],\n",
              " [154, 78, 8, 701, 493, 382, 286, 345, 597, 783, 890],\n",
              " [33, 42, 63, 746, 383, 744, 93],\n",
              " [543, 155, 916, 29, 747, 702],\n",
              " [494, 657, 122, 198, 598, 424, 435, 541, 293, 294, 117],\n",
              " [332, 544, 77, 295, 198, 47, 79, 296, 891, 48, 545, 6, 658],\n",
              " [599, 297, 546, 848, 199, 958, 892, 748, 546, 703, 740, 698],\n",
              " [826, 239, 742, 495, 435, 937, 94, 659, 936, 825, 872, 873],\n",
              " [5, 874, 232, 435, 749, 547, 432, 200, 789, 43, 11, 704, 384],\n",
              " [125, 436, 660, 126, 156, 600, 385, 61, 595, 496, 240, 95],\n",
              " [661, 437, 601, 497, 386, 705, 127, 49],\n",
              " [387, 346, 241, 602, 438, 439],\n",
              " [192, 654, 706, 498, 34, 707, 200, 603, 548, 242, 708],\n",
              " [128, 157, 63, 388, 604, 158],\n",
              " [347, 25, 662, 702, 785, 3, 605, 440, 243, 663, 244],\n",
              " [17, 129, 80, 288, 245, 849, 499, 159, 959, 787, 283],\n",
              " [441, 499, 739, 96, 442, 42, 784, 246, 664],\n",
              " [389, 35, 890, 156, 201, 44, 160, 665, 435, 390, 97, 286],\n",
              " [500, 443, 385, 938, 77, 850, 500, 64, 247, 7],\n",
              " [130, 784, 126, 596, 296, 790, 444, 1],\n",
              " [501, 666, 161, 709, 783, 12, 334, 248, 710],\n",
              " [893, 606, 431, 36, 548, 502, 875, 894, 26, 657, 131, 503, 667],\n",
              " [50, 711, 126, 703, 29, 202, 199, 203],\n",
              " [607, 298, 443, 704, 92, 791, 608, 132],\n",
              " [133, 668, 299, 669, 670, 827, 61, 300, 895, 348],\n",
              " [894, 391, 204, 51, 445, 894, 6, 162, 712, 24, 26, 249],\n",
              " [549, 205, 792, 250, 744, 671, 670, 793, 65, 750, 751, 380],\n",
              " [752, 713, 550, 504, 155, 123, 349, 134, 753, 492, 672],\n",
              " [917, 551, 301, 392, 827, 609, 871, 547, 132, 939, 206, 851],\n",
              " [437, 876, 13, 336, 350, 552, 251, 957, 500, 351],\n",
              " [292, 98, 4, 302, 545, 35, 37, 205, 877, 852],\n",
              " [352, 163, 896, 891, 334, 446, 303],\n",
              " [42, 252, 33, 135, 18, 25, 673, 202, 853, 828],\n",
              " [953, 714, 952, 715, 794, 341],\n",
              " [447, 295, 716, 393, 304, 32, 248],\n",
              " [750, 610, 353, 305, 196, 38, 386],\n",
              " [39, 553, 918, 498, 717, 754, 246, 354, 136, 51],\n",
              " [244, 554, 611, 718, 253, 829, 448, 755, 355, 164, 449, 450, 795],\n",
              " [605, 796, 254, 612, 545, 451, 894, 897, 854, 452, 255],\n",
              " [42, 671, 394, 555, 256, 741, 699],\n",
              " [613, 446, 98, 30, 855, 229, 556, 872, 81, 453],\n",
              " [395, 396, 498, 493, 165, 66, 29, 959, 797, 719, 898],\n",
              " [595, 919, 5, 93, 674, 16, 719, 756, 397, 557, 306, 252],\n",
              " [558, 614, 556, 615, 82, 337, 35, 301],\n",
              " [616, 243, 14, 37, 675, 757, 595, 230, 341],\n",
              " [388, 339, 454, 166, 30, 758, 617, 744, 720, 798, 307, 618],\n",
              " [794, 80, 721, 137, 491, 391],\n",
              " [455, 83, 799, 257, 671, 26, 594, 505, 167, 873, 333],\n",
              " [81, 559, 207, 67, 99, 710, 40],\n",
              " [168, 197, 18, 560, 258, 830],\n",
              " [940, 561, 651, 759, 615, 920, 208, 201, 619, 34, 435],\n",
              " [940, 760, 941, 25, 722, 800, 356],\n",
              " [716, 206, 19, 699, 856, 357, 456, 452, 497],\n",
              " [857, 259, 594, 169, 62, 84, 653],\n",
              " [620, 308, 18, 954, 260, 613, 562, 457, 307, 878, 554, 209, 742],\n",
              " [596, 134, 258, 706, 506, 93, 293, 495],\n",
              " [385, 246, 129, 897, 309, 822, 896, 8, 507, 676],\n",
              " [290, 100, 921, 831, 621, 801, 458, 51, 310, 333, 380, 789],\n",
              " [14, 168, 619, 235, 720, 46, 261, 170, 85, 398, 942, 311, 399],\n",
              " [668, 439, 563, 284, 312, 432, 78, 556, 83, 358, 802, 312],\n",
              " [830, 851, 564, 459, 400, 34],\n",
              " [751, 922, 9, 52, 85, 822, 35, 540, 68, 171, 723, 712],\n",
              " [942, 80, 138, 126, 441, 35, 133, 172, 313, 460, 822, 210],\n",
              " [508, 314, 916, 401, 565, 359, 40, 262, 435, 858, 39],\n",
              " [899, 899, 315, 334, 826, 591, 100],\n",
              " [707, 828, 316, 263, 429, 336, 97, 923, 127, 677, 383, 134],\n",
              " [298, 622, 285, 786, 900, 6],\n",
              " [623, 243, 509, 333, 68, 901, 624, 698, 379, 510, 283, 501, 128],\n",
              " [503, 378, 789, 625, 965, 169, 173, 300, 63, 317, 952],\n",
              " [437, 61, 27, 402, 966, 458, 360, 49, 101, 125],\n",
              " [314, 915, 301, 761, 86, 756],\n",
              " [264, 77, 497, 24, 724, 488, 626, 434, 717, 357],\n",
              " [725, 708, 937, 265, 303, 311, 803, 403, 511, 832, 313],\n",
              " [318, 361, 512, 943, 247, 174, 319, 201, 665],\n",
              " [953, 799, 804, 259, 39, 566, 391],\n",
              " [83, 14, 287, 293, 175, 153, 513],\n",
              " [390, 461, 738, 158, 762, 362, 251, 102, 363, 265],\n",
              " [627, 211, 298, 763, 5, 385, 461, 287, 320],\n",
              " [266, 306, 609, 13, 103, 331, 358, 508, 400, 168],\n",
              " [560, 718, 383, 714, 193, 508, 69, 902, 152],\n",
              " [382, 228, 212, 721, 512, 267, 446, 173, 44, 705],\n",
              " [668, 341, 678, 828, 84, 559, 567, 822, 764, 607],\n",
              " [53, 159, 268, 54, 497, 509, 67, 462, 916, 83, 540, 696, 509],\n",
              " [213, 859, 720, 102, 404, 120],\n",
              " [390, 628, 706, 91, 28, 23, 796, 568, 656, 79, 321, 122, 7],\n",
              " [322, 383, 938, 452, 34, 341, 514, 562, 322, 425, 569, 463],\n",
              " [240, 508, 464, 437, 954, 92, 234, 238, 490, 805, 726, 16],\n",
              " [176, 860, 860, 515, 876, 7, 214, 878, 137, 456, 405],\n",
              " [269, 806, 564, 762, 596, 629, 465, 570, 394, 177],\n",
              " [212, 136, 674, 305, 232, 299],\n",
              " [22, 944, 806, 201, 42, 799, 593, 192],\n",
              " [903, 352, 462, 936, 49, 288, 630, 516, 215, 726, 669, 822, 466],\n",
              " [784, 438, 538, 267, 6, 178, 16, 99, 353, 696, 631],\n",
              " [137, 406, 99, 765, 259, 496, 332, 494, 26, 679, 24, 720, 548],\n",
              " [766, 854, 407, 517, 251, 443, 364, 179, 706],\n",
              " [84, 139, 958, 270, 381, 727, 539],\n",
              " [19, 43, 680, 940, 744, 365, 871, 263],\n",
              " [38, 681, 140, 682, 201, 62, 683, 17, 632, 70],\n",
              " [180, 571, 668, 824, 216, 101, 203, 726, 209, 71],\n",
              " [924, 6, 945, 86, 664, 348, 94, 607, 388, 728, 710, 870],\n",
              " [181, 246, 699, 953, 100, 404],\n",
              " [352, 572, 807, 44, 557, 217, 408, 633, 622, 877, 674, 40, 896],\n",
              " [658, 70, 218, 129, 193, 518],\n",
              " [338, 502, 409, 614, 620, 879, 182, 141, 240, 808, 117, 671],\n",
              " [729, 410, 493, 357, 745, 833, 216, 730, 130, 15],\n",
              " [168, 319, 569, 519, 261, 427, 861, 766, 711, 183],\n",
              " [677, 209, 573, 323, 944, 574, 458, 904, 546, 834, 215, 178, 759],\n",
              " [742, 450, 614, 69, 407, 493, 10],\n",
              " [731, 517, 252, 829, 366, 783, 219, 331, 966, 905],\n",
              " [346, 135, 158, 763, 741, 393, 937, 178, 785, 70, 346, 411],\n",
              " [397, 91, 130, 444, 359, 730, 367, 541],\n",
              " [37, 215, 411, 408, 135, 634, 46, 443],\n",
              " [827, 750, 20, 13, 785, 952, 240, 677, 673, 55, 412],\n",
              " [635, 220, 590, 410, 700, 282, 835],\n",
              " [267, 314, 436, 158, 271, 358, 101, 786, 138, 809, 619],\n",
              " [271, 767, 254, 759, 104, 36, 49, 56, 123, 753],\n",
              " [518, 971, 871, 567, 684, 142, 333, 294, 86, 880, 629],\n",
              " [740, 105, 659, 732, 575, 337, 636, 220, 467],\n",
              " [468, 309, 520, 124, 576, 256, 216],\n",
              " [2, 368, 340, 369, 709, 57, 18, 449, 35, 881],\n",
              " [637, 2, 467, 106, 72, 573],\n",
              " [445, 520, 319, 352, 318, 272, 35, 166, 613, 600],\n",
              " [172, 577, 759, 608, 557, 203, 442, 249, 131, 172, 261],\n",
              " [637, 262, 768, 922, 356, 634, 469, 306, 638],\n",
              " [726, 576, 797, 862, 98, 925, 370, 300, 381, 639],\n",
              " [863, 107, 599, 67, 719, 552, 521, 197],\n",
              " [906, 324, 578, 518, 289, 173, 759, 658, 266, 413],\n",
              " [345, 184, 876, 592, 32, 262, 907, 2, 750, 832, 68, 76],\n",
              " [870, 282, 412, 836, 218, 104, 862, 495, 42, 164, 462, 297, 640],\n",
              " [87, 451, 11, 238, 882, 134, 459, 803, 163, 874, 470, 342, 429],\n",
              " [256, 140, 93, 139, 1, 99, 140, 716, 509, 120],\n",
              " [51, 577, 123, 83, 462, 595, 200, 920],\n",
              " [54, 158, 798, 442, 95, 166, 723, 883, 132, 590, 826, 40, 917],\n",
              " [185, 579, 604, 414, 613, 415, 884, 314, 364, 356, 870, 610],\n",
              " [802, 619, 81, 507, 711, 118, 108, 580, 675, 514],\n",
              " [37, 313, 71, 631, 170, 50, 234, 240, 186, 447, 897, 810, 298],\n",
              " [651, 207, 182, 632, 416, 469, 863, 143, 471, 273, 247, 413, 16],\n",
              " [789, 311, 417, 30, 401, 744],\n",
              " [221, 594, 522, 54, 718, 762, 769, 917, 288, 491],\n",
              " [705, 706, 129, 13, 665, 761, 506],\n",
              " [397, 77, 250, 5, 371, 432, 270, 88, 926, 659, 291, 698, 523],\n",
              " [133, 144, 875, 18, 287, 22, 381, 144, 685],\n",
              " [832, 389, 555, 733, 595, 874, 628, 84, 686, 743, 195],\n",
              " [524, 231, 236, 384, 391, 832, 268],\n",
              " [970, 19, 850, 104, 209, 214, 659, 455, 220, 864, 903, 785, 505],\n",
              " [145, 340, 970, 400, 274, 865, 946, 325, 597],\n",
              " [698, 622, 275, 581, 462, 214, 574, 28, 86, 618, 397],\n",
              " [55, 811, 397, 451, 425, 653, 146, 182, 229, 558, 625, 13, 440],\n",
              " [723, 451, 837, 677, 47, 551, 123, 559],\n",
              " [459, 166, 178, 580, 283, 539, 350, 804, 177, 488],\n",
              " [730, 783, 748, 391, 619, 310, 838, 800, 559],\n",
              " [826, 109, 749, 667, 679, 629, 378, 334, 947, 955, 409, 75],\n",
              " [242, 734, 118, 663, 948, 336, 657, 866, 550],\n",
              " [56, 104, 518, 564, 146, 742, 6, 510, 673, 110, 95, 111, 346],\n",
              " [656, 152, 789, 543, 547, 865],\n",
              " [24, 36, 713, 237, 92, 543, 379, 614],\n",
              " [428, 509, 144, 895, 545, 429],\n",
              " [905, 297, 25, 499, 139, 763, 851, 552, 196, 472, 293],\n",
              " [811, 469, 600, 628, 496, 411, 325, 582, 687, 591, 14, 222],\n",
              " [58, 770, 895, 171, 73, 866, 220, 650, 292],\n",
              " [729, 939, 825, 343, 563, 473, 288, 596],\n",
              " [641, 339, 701, 771, 551, 87, 719, 772, 313, 474, 11, 203, 87],\n",
              " [862, 251, 117, 166, 293, 743, 236, 464, 428],\n",
              " [17, 897, 430, 195, 773, 245, 368, 489, 120, 204, 654, 450],\n",
              " [688, 287, 610, 967, 26, 195, 95, 395, 128, 792, 335, 433],\n",
              " [659, 198, 896, 247, 183, 101, 787, 174, 305, 850, 185],\n",
              " [89, 382, 638, 572, 344, 36],\n",
              " [92, 366, 152, 493, 859, 112, 68, 822],\n",
              " [968, 623, 332, 697, 701, 554, 160, 287, 60, 685],\n",
              " [135, 308, 59, 276, 444, 10, 334, 756],\n",
              " [147, 228, 834, 4, 735, 418, 740, 366, 158, 636, 885],\n",
              " [145, 473, 153, 499, 273, 91, 642],\n",
              " [90, 78, 335, 628, 800, 787, 823, 769, 569, 175, 107, 471],\n",
              " [572, 796, 110, 228, 806, 877, 372],\n",
              " [290, 549, 419, 310, 631, 266, 403, 769],\n",
              " [168, 1, 643, 812, 291, 619, 420, 268, 276, 658, 440],\n",
              " [391, 600, 146, 921, 493, 284, 22, 267, 4, 77, 927],\n",
              " [552, 210, 141, 430, 4, 162, 321, 822, 209, 117, 916, 969, 665],\n",
              " [336, 953, 583, 56, 11, 39, 380],\n",
              " [86, 425, 37, 402, 239, 813, 270, 923, 35, 408],\n",
              " [583, 718, 110, 274, 251, 900, 239, 802, 223, 682],\n",
              " [108, 756, 555, 255, 93, 475, 222],\n",
              " [415, 143, 165, 71, 644, 476, 234, 395, 204, 928, 143, 237],\n",
              " [767, 40, 955, 523, 343, 104],\n",
              " [349, 795, 584, 253, 236, 765, 501, 612, 645, 814, 343, 439, 339, 964],\n",
              " [890, 36, 313, 230, 381, 142, 243, 15, 811],\n",
              " [783, 407, 249, 288, 39, 236, 413, 678, 505],\n",
              " [1, 450, 856, 833, 254, 330, 772, 52],\n",
              " [335, 872, 956, 19, 97, 541, 466, 159, 867, 489, 365, 446],\n",
              " [865, 224, 40, 662, 938, 447, 560, 196, 495, 277, 169, 367, 342],\n",
              " [196, 660, 447, 76, 448, 378, 155, 563, 689, 83, 197],\n",
              " [808, 757, 8, 525, 767, 30, 92],\n",
              " [39, 774, 351, 679, 421, 165, 326, 929, 456, 184, 67, 453, 632],\n",
              " [342, 809, 170, 322, 127, 689, 826, 61, 669],\n",
              " [836, 430, 388, 650, 381, 806, 813, 72, 88],\n",
              " [29, 569, 683, 138, 398, 41, 137, 503, 575, 152, 182, 476, 425],\n",
              " [373, 927, 900, 304, 228, 1, 244],\n",
              " [585, 748, 514, 145, 733, 61, 775, 721, 922, 930],\n",
              " [217, 381, 363, 954, 546, 1, 552, 56, 321, 181],\n",
              " [212, 468, 113, 165, 38, 146, 178, 787, 926, 720, 447],\n",
              " [429, 243, 724, 374, 685, 206, 157, 98, 70, 784, 790, 644, 175],\n",
              " [924, 146, 50, 553, 519, 874, 505],\n",
              " [573, 37, 746, 822, 13, 172, 212, 464, 269, 145, 583, 597],\n",
              " [106, 426, 261, 850, 443, 378, 389, 367, 758],\n",
              " [355, 923, 959, 336, 391, 661, 251, 786, 276, 184, 498],\n",
              " [185, 839, 690, 311, 277, 385, 929],\n",
              " [109, 919, 541, 796, 109, 434, 641],\n",
              " [769, 1, 418, 201, 448, 687, 378, 610, 443, 668, 509],\n",
              " [325, 549, 896, 98, 908, 297, 106, 101],\n",
              " [886, 282, 548, 114, 238, 42, 11, 667, 618, 3, 287, 832, 949],\n",
              " [602, 278, 489, 173, 337, 704, 564],\n",
              " [674, 568, 470, 259, 345, 545, 460, 153, 296, 540],\n",
              " [691, 134, 187, 13, 104, 563, 297],\n",
              " [134, 94, 219, 709, 400, 477, 495, 671, 8, 402, 872, 626],\n",
              " [526, 601, 133, 272, 311, 793, 395, 370, 416, 82],\n",
              " [560, 619, 800, 262, 466, 246, 133, 931, 681],\n",
              " [451, 363, 862, 755, 242, 444, 350, 505, 388],\n",
              " [851, 219, 282, 109, 436, 642, 840, 86, 880],\n",
              " [197, 744, 730, 611, 612, 279, 506, 680, 555, 527, 337, 71, 59],\n",
              " [800, 288, 159, 424, 184, 867, 665, 279, 545],\n",
              " [23, 213, 768, 63, 635, 450, 430, 804, 400],\n",
              " [924, 717, 968, 918, 644, 92, 115, 394, 113, 511, 293, 814, 573],\n",
              " [582, 841, 126, 478, 102, 37, 295],\n",
              " [512, 133, 807, 711, 776, 54, 899, 905, 638, 9, 298],\n",
              " [541, 283, 356, 420, 625, 431, 348, 688, 581, 433, 254, 250, 85, 675],\n",
              " [497, 815, 842, 655, 101, 167, 716, 461, 948, 11],\n",
              " [657, 752, 145, 64, 792, 125],\n",
              " [436, 369, 294, 433, 816, 68, 582, 388, 296, 547],\n",
              " [68, 506, 327, 31, 378, 828, 274],\n",
              " [254, 217, 641, 717, 777, 154, 7, 594, 650, 111, 367, 615, 563],\n",
              " [495, 233, 556, 410, 595, 136, 32, 45, 498, 790, 50],\n",
              " [328, 32, 528, 904, 493, 541, 105, 380, 138],\n",
              " [19, 145, 489, 152, 384, 749, 433, 594, 58],\n",
              " [350, 470, 586, 384, 868, 169, 14, 567, 284, 721],\n",
              " [253, 652, 808, 311, 464, 370, 287, 612, 65, 215, 187],\n",
              " [757, 331, 303, 564, 778, 627, 352, 203],\n",
              " [176, 566, 198, 453, 97, 16, 333, 215, 103, 438, 529],\n",
              " [464, 610, 876, 257, 28, 234, 304],\n",
              " [394, 210, 736, 87, 938, 472, 593],\n",
              " [492, 322, 38, 218, 293, 932, 19, 76, 634, 515, 388, 188],\n",
              " [805, 970, 91, 278, 273, 344, 68],\n",
              " [160, 164, 707, 817, 909, 948, 619],\n",
              " [479, 234, 550, 752, 815, 313, 503, 243, 75],\n",
              " [409, 828, 894, 830, 317, 303],\n",
              " [659, 200, 398, 541, 689, 146, 634, 538, 429, 86, 736, 350, 667],\n",
              " [343, 723, 561, 147, 793, 511, 252],\n",
              " [396, 178, 189, 941, 328, 480],\n",
              " [307, 382, 429, 322, 29, 263, 73, 64, 229, 815, 757],\n",
              " [502, 601, 241, 692, 877, 551, 852],\n",
              " [702, 239, 495, 345, 229, 47, 712],\n",
              " [561, 475, 626, 827, 390, 355, 282, 296, 51],\n",
              " [656, 559, 517, 435, 958, 789, 7, 950, 161, 620],\n",
              " [34, 635, 212, 101, 523, 660, 441, 710, 202, 967],\n",
              " [248, 63, 896, 920, 233, 339, 318, 480, 54, 363, 815, 316, 737],\n",
              " [564, 204, 40, 429, 208, 493, 411, 267, 22, 411, 629, 631, 705],\n",
              " [884, 4, 419, 68, 549, 465, 386, 228, 473, 34, 587, 765, 261],\n",
              " [440, 93, 79, 686, 104, 952, 158, 368, 316, 17, 644, 743],\n",
              " [321, 262, 185, 466, 452, 588, 462, 337, 351, 80],\n",
              " [198, 833, 964, 393, 219, 347, 111, 299, 925],\n",
              " [778, 81, 132, 480, 320, 825],\n",
              " [895, 854, 680, 230, 583, 810, 229, 81],\n",
              " [323, 81, 818, 418, 44, 928, 895, 763, 335, 487, 715, 166, 922],\n",
              " [577, 54, 95, 545, 571, 696, 360, 564, 204, 774, 566, 594, 164],\n",
              " [942, 332, 564, 741, 807, 522, 736, 525, 173, 814],\n",
              " [509, 212, 134, 196, 245, 739, 824, 895, 719, 581],\n",
              " [181, 309, 464, 681, 481, 346, 58],\n",
              " [487, 263, 574, 251, 466, 969, 477, 915],\n",
              " [147, 504, 449, 526, 653, 742, 176, 741, 339],\n",
              " [63, 2, 361, 849, 309, 138, 736, 212],\n",
              " [116, 598, 350, 754, 321, 78, 954, 661, 785, 874, 566],\n",
              " [715, 239, 690, 829, 962, 910, 40, 631, 152],\n",
              " [145, 903, 399, 330, 206, 655, 469, 99, 754, 328],\n",
              " [883, 709, 662, 155, 67, 838, 231, 926],\n",
              " [793, 170, 589, 611, 463, 332, 136, 952, 738, 148, 398, 809, 571],\n",
              " [279, 586, 638, 435, 143, 41, 412, 27, 576],\n",
              " [21, 894, 799, 927, 79, 367],\n",
              " [453, 919, 89, 44, 615, 595, 302],\n",
              " [13, 482, 23, 865, 144, 48, 118, 761, 909, 313, 887, 345],\n",
              " [607, 721, 282, 721, 304, 446, 149, 365, 118, 901, 688, 755, 607],\n",
              " [225, 314, 583, 2, 41, 39, 666, 556, 568, 210, 403, 676, 257],\n",
              " [735, 684, 76, 573, 656, 111, 355, 45, 279, 177, 855],\n",
              " [651, 875, 182, 131, 470, 115, 632, 488, 779, 101, 432],\n",
              " [523, 865, 927, 815, 319, 105, 203, 186, 159],\n",
              " [310, 805, 1, 405, 774, 107, 286],\n",
              " [94, 141, 446, 512, 438, 100, 177, 653, 220, 250, 353, 340, 163],\n",
              " [432, 351, 149, 301, 818, 63, 659, 15, 942, 675, 363, 601],\n",
              " [488, 467, 395, 473, 164, 214, 439],\n",
              " [121, 638, 25, 581, 454, 951, 121, 182, 656, 420],\n",
              " [766, 373, 883, 715, 604, 724, 584, 578],\n",
              " [843, 584, 617, 75, 167, 415, 352, 10],\n",
              " [481, 841, 295, 471, 280, 858, 513, 125, 219, 415],\n",
              " [762, 145, 830, 272, 943, 741, 556, 683, 556, 299],\n",
              " [141, 640, 291, 658, 420, 418, 693, 504, 233],\n",
              " [948, 429, 530, 13, 320, 707],\n",
              " [787, 919, 342, 7, 510, 865, 929, 402, 1, 148, 106, 162, 646],\n",
              " [524, 530, 542, 9, 691, 195, 472, 888, 426, 405, 941, 905],\n",
              " [412, 562, 417, 87, 8, 127, 502, 930, 344, 945],\n",
              " [177, 27, 851, 8, 967, 104, 803],\n",
              " [384, 191, 384, 401, 278, 630, 856, 922, 384, 296, 198],\n",
              " [679, 430, 71, 84, 400, 778, 180, 587, 127, 115, 758],\n",
              " [114, 37, 582, 714, 191, 308, 6, 731, 114, 221],\n",
              " [134, 185, 727, 563, 824, 304, 363, 851],\n",
              " [791, 280, 216, 97, 7, 445, 5, 400, 394],\n",
              " [81, 15, 115, 805, 685, 937, 221, 615],\n",
              " [869, 635, 66, 968, 414, 346, 858, 145],\n",
              " [332, 701, 715, 197, 479, 425],\n",
              " [617, 464, 328, 69, 872, 859, 754, 280, 676, 229, 13, 128, 187],\n",
              " [87, 720, 61, 208, 952, 21, 257, 577, 11, 463, 357, 419, 559],\n",
              " [325, 53, 153, 205, 531, 292, 34, 88, 187, 183, 754, 728],\n",
              " [659, 647, 651, 891, 506, 210, 899, 932],\n",
              " [521, 385, 481, 892, 872, 123, 261, 764, 638, 734],\n",
              " [579, 29, 249, 691, 122, 665, 550, 138, 481],\n",
              " [627, 622, 735, 56, 198, 206, 250, 311, 460, 17, 766],\n",
              " [704, 45, 704, 278, 855, 685, 532, 645],\n",
              " [735, 154, 298, 602, 495, 942, 766, 724, 38, 678, 152, 742],\n",
              " [64, 581, 632, 884, 324, 943, 126, 31, 34, 950],\n",
              " [8, 352, 99, 448, 899, 822, 40, 307, 291, 44, 891, 739, 352],\n",
              " [436, 118, 836, 681, 180, 194, 557, 35, 915, 731, 115],\n",
              " [806, 431, 878, 375, 703, 775],\n",
              " [274, 875, 791, 30, 897, 787, 571, 922, 724, 136, 782, 819],\n",
              " [720, 100, 959, 829, 49, 656, 398, 796, 464, 298, 610],\n",
              " [755, 103, 883, 881, 108, 51, 899],\n",
              " [659, 262, 95, 849, 358, 533, 534, 824],\n",
              " [568, 615, 628, 526, 114, 47, 595, 884, 562, 663, 262],\n",
              " [797, 710, 249, 72, 106, 455, 452, 547],\n",
              " [947, 260, 9, 679, 526, 44, 780, 445, 440, 716, 248],\n",
              " [186, 776, 296, 821, 595, 295, 157, 909, 7],\n",
              " [35, 254, 348, 628, 113, 807, 385],\n",
              " [762, 573, 206, 483, 259, 694, 37, 579, 294, 820],\n",
              " [738, 900, 742, 803, 394, 910, 36],\n",
              " [844, 551, 541, 179, 89, 402, 780, 612, 848],\n",
              " [129, 103, 192, 880, 541, 329, 258, 12, 533, 41, 580, 522, 860],\n",
              " [8, 405, 921, 933, 594, 383, 799, 127, 140, 634, 824, 614, 108],\n",
              " [646, 181, 623, 576, 710, 835, 52, 593],\n",
              " [651, 910, 566, 669, 917, 834, 357, 196, 337, 774, 290, 186, 893],\n",
              " [93, 868, 745, 368, 117, 280, 403, 250, 484, 115, 944, 886, 126],\n",
              " [589, 264, 367, 6, 5, 363, 35, 584, 292, 792],\n",
              " [15, 668, 357, 119, 27, 622, 720, 361, 183, 839, 648, 346, 911],\n",
              " [792, 91, 128, 783, 835, 81, 304, 580, 812, 125, 798, 742],\n",
              " [129, 10, 72, 812, 516, 522, 451, 493],\n",
              " [336, 170, 841, 922, 650, 8],\n",
              " [391, 132, 805, 530, 41, 908, 884, 946, 175],\n",
              " [669, 234, 102, 174, 298, 790, 478, 20, 139, 69, 455, 226],\n",
              " [27, 755, 416, 845, 957, 336, 622, 448, 463, 127, 851],\n",
              " [117, 376, 327, 323, 242, 681, 692, 776, 137, 157],\n",
              " [446, 971, 481, 592, 643, 612, 617, 201, 266, 76],\n",
              " [481, 85, 840, 422, 831, 468],\n",
              " [497, 949, 502, 252, 637, 266],\n",
              " [111, 703, 887, 712, 671, 612, 167, 513, 466],\n",
              " [542, 348, 71, 296, 279, 322, 31, 556, 932, 184],\n",
              " [579, 276, 402, 167, 439, 895, 32, 235, 159, 233],\n",
              " [108, 221, 227, 685, 191, 448, 633, 506, 223, 92, 232, 172],\n",
              " [484, 459, 344, 451, 832, 739, 485, 736, 468],\n",
              " [808, 88, 130, 376, 540, 656, 729, 272, 770, 477, 250],\n",
              " [721, 96, 574, 47, 645, 402, 264, 814, 102, 200, 365, 885, 386],\n",
              " [41, 15, 547, 357, 687, 72, 212, 127, 679, 103],\n",
              " [902, 710, 701, 708, 701, 531, 648, 178, 205, 648, 520, 177, 544],\n",
              " [535, 343, 144, 217, 756, 911, 281, 684, 99, 487, 436, 67],\n",
              " [80, 234, 943, 166, 207, 910, 43, 360, 365, 681, 910],\n",
              " [813, 892, 844, 760, 284, 648, 772, 359, 510, 432, 685, 653, 46, 90],\n",
              " [421, 177, 148, 318, 843, 644, 441, 613, 96, 651, 4, 377, 16],\n",
              " [828, 598, 433, 946, 257, 879, 272, 950, 240, 181, 503, 136, 579],\n",
              " [20, 87, 399, 54, 552, 866, 889, 451, 627, 796, 718, 91],\n",
              " [593, 156, 399, 92, 664, 75, 386, 818, 38, 521, 515, 366],\n",
              " [711, 511, 168, 528, 140, 519, 305],\n",
              " [64, 968, 328, 920, 168, 61, 521],\n",
              " [881, 193, 10, 832, 228, 195, 24, 110, 541, 399, 718, 709, 881],\n",
              " [618, 774, 442, 123, 78, 529, 756, 28, 721],\n",
              " [238, 389, 319, 93, 161, 795, 910],\n",
              " [75, 363, 586, 136, 180, 21],\n",
              " [599, 763, 338, 443, 587, 280, 635, 569, 609, 441],\n",
              " [642, 577, 299, 920, 713, 725, 136, 220, 349, 476, 172, 380],\n",
              " [522, 650, 228, 788, 742, 772],\n",
              " [640, 821, 828, 88, 454, 49, 362, 109],\n",
              " [799, 526, 293, 693, 114, 509, 253, 162, 20],\n",
              " [46, 817, 580, 960, 506, 132, 113, 415, 274, 827],\n",
              " [277, 841, 422, 564, 374, 385, 2, 127, 840, 378],\n",
              " [3, 440, 520, 890, 229, 21, 36, 788],\n",
              " [918, 150, 48, 465, 638, 373, 46, 901, 265, 194],\n",
              " [199, 146, 435, 857, 135, 818, 326, 45],\n",
              " [837, 804, 126, 587, 84, 89, 365],\n",
              " [412, 557, 128, 547, 188, 675, 691, 84, 187, 442, 394, 524],\n",
              " [3, 166, 89, 313, 692, 7, 509, 647, 230, 283, 197, 339],\n",
              " [334, 111, 120, 744, 576, 21, 373, 348],\n",
              " [832, 194, 207, 229, 815, 967, 686, 243, 937, 38],\n",
              " [74, 234, 920, 190, 171, 108, 3, 614],\n",
              " [680, 605, 19, 639, 448, 640, 234, 279, 1, 762, 58, 442],\n",
              " [382, 74, 48, 908, 282, 423, 589, 192],\n",
              " [185, 154, 664, 184, 455, 618, 254, 812, 59],\n",
              " [426, 175, 814, 821, 469, 27, 36, 633, 268],\n",
              " [31, 196, 33, 882, 772, 205, 118, 919],\n",
              " [826, 468, 288, 737, 550, 836, 278, 819, 564, 758],\n",
              " [304, 967, 590, 461, 585, 405, 25, 207, 39, 867, 969],\n",
              " [606, 462, 39, 84, 370, 602, 331, 875, 119, 215, 491, 711],\n",
              " [341, 407, 148, 707, 637, 362, 129, 371, 565, 802, 606, 163, 81, 697],\n",
              " [569, 316, 449, 447, 216, 173, 215, 554, 155, 75, 26, 832, 486],\n",
              " [376, 216, 396, 626, 36, 482, 661, 307, 24],\n",
              " [584, 548, 285, 349, 125, 236, 154, 192, 934],\n",
              " [553, 493, 450, 251, 118, 290, 648, 3],\n",
              " [542, 272, 454, 306, 411, 440, 437, 691, 139, 241, 765, 496, 676],\n",
              " [107, 794, 359, 360, 310, 226, 590, 801],\n",
              " [561, 777, 699, 829, 353, 3],\n",
              " [417, 759, 596, 571, 202, 335, 86, 940, 18, 783],\n",
              " [436, 450, 629, 724, 649, 346, 383, 189, 725],\n",
              " [372, 861, 570, 536, 320, 277, 969, 250, 286, 915, 831],\n",
              " [617, 173, 208, 535, 78, 295, 735],\n",
              " [683, 304, 556, 958, 519, 584, 242, 28, 865, 773, 412],\n",
              " [649, 19, 7, 319, 359, 100, 382],\n",
              " [737, 229, 759, 341, 379, 729, 905, 308, 680, 801],\n",
              " [62, 52, 4, 497, 357, 795, 162, 928],\n",
              " [77, 576, 554, 736, 228, 70, 583, 709, 828, 331, 966, 21],\n",
              " [16, 86, 253, 221, 886, 703, 130, 930, 107, 102],\n",
              " [846, 77, 901, 366, 170, 830, 883, 452, 231, 50, 91, 834],\n",
              " [210, 688, 494, 923, 124, 818, 106, 368],\n",
              " [728, 832, 455, 816, 271, 536, 307, 469, 599, 345, 382, 391, 156],\n",
              " [755, 644, 198, 765, 60, 372, 135, 752, 567, 64, 754],\n",
              " [527, 528, 368, 649, 290, 160, 25, 311],\n",
              " [393, 38, 259, 516, 549, 690, 66],\n",
              " [122, 222, 789, 459, 383, 520, 557, 833, 683, 412, 84, 381, 275],\n",
              " [291, 863, 968, 93, 405, 932, 780, 151, 431, 907, 454, 636, 163],\n",
              " [343, 443, 238, 495, 485, 206, 755, 545, 187],\n",
              " [533, 331, 763, 326, 123, 862, 573, 561, 80, 267, 389, 15, 221],\n",
              " [66, 470, 897, 197, 38, 386, 546, 1, 582, 38],\n",
              " [604, 284, 423, 855, 97, 271, 51],\n",
              " [336, 448, 196, 127, 633, 8, 811, 504],\n",
              " [684, 313, 251, 705, 823, 926, 792, 546, 601, 959, 139, 692, 433],\n",
              " [48, 915, 606, 602, 442, 97, 230],\n",
              " [55, 208, 934, 124, 192, 429, 811],\n",
              " [940, 847, 696, 663, 888, 153, 10, 109, 107],\n",
              " [948, 827, 476, 944, 653, 817, 858, 217, 663, 561, 69, 845, 286],\n",
              " [735, 8, 721, 533, 933, 441, 14],\n",
              " [167, 586, 922, 689, 446, 350, 394],\n",
              " [645, 176, 323, 458, 731, 698, 126, 91, 148, 711, 519, 632, 406],\n",
              " [427, 67, 852, 428, 932, 849],\n",
              " [177, 627, 349, 425, 647, 508, 557, 23, 527],\n",
              " [952, 415, 192, 322, 357, 284, 167, 400],\n",
              " [731, 272, 326, 471, 5, 59, 228, 551],\n",
              " [432, 892, 249, 351, 709, 281, 794, 73, 299],\n",
              " [176, 280, 766, 677, 7, 682, 681],\n",
              " [44, 265, 764, 928, 885, 123, 89, 3, 278, 215, 942],\n",
              " [265, 548, 879, 827, 299, 678, 789, 2, 539, 444, 643, 793],\n",
              " [324, 366, 855, 358, 154, 383, 749],\n",
              " [794, 141, 937, 462, 572, 765, 455, 882, 337],\n",
              " [661, 402, 581, 48, 313, 240, 322, 786],\n",
              " [307, 104, 149, 560, 84, 916, 588, 110, 103, 369],\n",
              " [427, 621, 572, 23, 400, 683, 568, 748],\n",
              " [86, 912, 512, 234, 692, 156, 182, 890, 31, 11, 913],\n",
              " [490, 866, 365, 639, 507, 101, 372],\n",
              " [41, 84, 665, 77, 642, 158, 774, 713, 760, 646, 545, 197, 842],\n",
              " [49, 490, 641, 735, 45, 834, 56, 163, 110, 671, 160],\n",
              " [889, 474, 144, 88, 696, 687, 635, 610, 736, 878, 753, 127, 137],\n",
              " [324, 757, 882, 700, 93, 91, 148, 472, 499, 278],\n",
              " [933, 160, 322, 740, 215, 92, 473, 227],\n",
              " [128, 164, 387, 366, 339, 624, 194],\n",
              " [912, 699, 90, 96, 16, 26],\n",
              " [136, 273, 776, 703, 391, 897, 523, 607, 701, 172, 967, 501, 534],\n",
              " [325, 180, 390, 112, 910, 454, 67, 716, 182],\n",
              " [181, 791, 223, 150, 29, 660, 634, 598, 2, 549, 93, 285, 600],\n",
              " [764, 110, 157, 536, 198, 124, 59, 60, 180],\n",
              " [749, 572, 36, 333, 826, 368, 639, 465, 727, 274, 64, 633, 116],\n",
              " [158, 379, 468, 149, 87, 894, 622, 189],\n",
              " [3, 219, 358, 423, 192, 510, 376, 577],\n",
              " [515, 2, 1, 93, 393, 720, 209, 101, 722],\n",
              " [70, 945, 43, 284, 321, 214],\n",
              " [94, 943, 717, 191, 287, 472],\n",
              " [621, 335, 280, 678, 766, 190, 871, 618, 922, 260, 667],\n",
              " [359, 281, 330, 443, 227, 235],\n",
              " [455, 576, 211, 244, 517, 420, 483, 550, 650, 511, 412, 49, 471],\n",
              " [471, 654, 279, 750, 428, 383, 738, 399, 19, 77, 746, 736],\n",
              " [203, 303, 827, 923, 729, 648, 421, 328, 172, 41, 129, 385],\n",
              " [85, 661, 546, 650, 371, 298, 280, 50, 860],\n",
              " [396, 173, 157, 803, 36, 527, 246, 266, 496, 99, 201, 348, 914],\n",
              " [885, 664, 769, 323, 11, 711, 273],\n",
              " [353, 191, 155, 705, 351, 842],\n",
              " [355, 8, 549, 160, 773, 854],\n",
              " [612, 860, 436, 342, 266, 37, 347, 24, 917, 937, 506],\n",
              " [434, 203, 737, 393, 18, 46, 401, 474, 225, 819, 643],\n",
              " [905, 144, 16, 416, 865, 674, 422, 148, 724, 375],\n",
              " [312, 772, 909, 61, 806, 816, 471],\n",
              " [122, 110, 930, 606, 347, 563, 30, 74, 460, 541, 289],\n",
              " [902, 702, 852, 752, 271, 188, 544, 877, 276, 709],\n",
              " [605, 580, 784, 390, 74, 346, 598, 699, 67, 88, 436],\n",
              " [842, 449, 431, 844, 34, 6, 392, 305, 733, 488, 826, 555, 428],\n",
              " [15, 969, 95, 362, 505, 573, 704, 931, 790],\n",
              " [551, 887, 574, 431, 914, 59, 597, 830, 330],\n",
              " [464, 692, 712, 68, 27, 863, 852, 865, 141, 338, 663],\n",
              " [170, 429, 742, 600, 940, 636, 397, 544, 525, 505, 137],\n",
              " [594, 694, 56, 271, 858, 293, 10, 441, 338, 799, 300],\n",
              " [305, 22, 702, 313, 723, 350],\n",
              " [725, 763, 645, 634, 502, 277, 599, 582, 407, 315],\n",
              " [894, 752, 892, 180, 344, 103, 164, 752, 127],\n",
              " [860, 406, 919, 750, 408, 813, 408, 221, 859, 164, 329, 800, 707],\n",
              " [25, 324, 447, 79, 131, 476, 673, 505, 411, 514, 36, 370, 601],\n",
              " [585, 518, 228, 361, 438, 375, 265, 614, 96],\n",
              " [542, 239, 229, 751, 3, 278, 377, 410, 268, 749],\n",
              " [534, 367, 440, 563, 67, 275, 304],\n",
              " [372, 965, 143, 24, 385, 304, 788, 893, 174, 367, 539, 334, 753],\n",
              " [21, 6, 289, 800, 98, 27, 557, 964, 580, 434, 6, 465],\n",
              " [730, 543, 496, 588, 817, 515, 513, 422, 848, 467, 153],\n",
              " [64, 766, 112, 296, 376, 584, 2, 154],\n",
              " [72, 473, 957, 711, 149, 839, 267, 156, 299, 531, 714, 510],\n",
              " [453, 240, 178, 778, 687, 817, 781],\n",
              " [56, 617, 371, 969, 173, 284, 556],\n",
              " [771, 256, 827, 361, 262, 65, 551, 320, 5, 225, 506],\n",
              " [217, 307, 196, 730, 160, 307, 401, 92],\n",
              " [587, 61, 625, 530, 907, 816, 685, 847],\n",
              " [889, 34, 414, 85, 12, 925],\n",
              " [575, 188, 220, 142, 165, 500, 571, 262, 279, 155],\n",
              " [338, 197, 604, 51, 482, 833],\n",
              " [623, 389, 633, 151, 878, 482, 277, 856, 283, 393],\n",
              " [605, 357, 338, 558, 56, 889, 316, 402],\n",
              " [119, 801, 528, 707, 738, 5, 540],\n",
              " [102, 155, 941, 37, 135, 282, 639, 172, 335, 245],\n",
              " [772, 446, 701, 257, 142, 822],\n",
              " [34, 223, 663, 172, 323, 701, 586, 15, 298, 229, 54, 470],\n",
              " [575, 441, 434, 704, 531, 492],\n",
              " [720, 546, 518, 102, 688, 222, 531],\n",
              " [696, 522, 38, 104, 818, 105, 84, 854, 472, 51, 323],\n",
              " [71, 718, 655, 668, 573, 445, 759, 633, 178, 789, 855],\n",
              " [343, 243, 888, 954, 535, 479, 247],\n",
              " [771, 885, 414, 257, 440, 834, 730, 763, 243, 19, 714, 717],\n",
              " [554, 114, 199, 87, 964, 867, 120, 430, 155],\n",
              " [417, 227, 536, 406, 735, 34, 571, 578],\n",
              " [605, 742, 365, 94, 454, 289, 423, 75, 396, 91, 689, 662],\n",
              " [789, 351, 911, 816, 199, 836, 223, 13],\n",
              " [756, 597, 805, 880, 440, 803, 532, 874, 562, 8],\n",
              " [268, 621, 293, 41, 626, 444, 633, 522, 688, 213, 771],\n",
              " [281, 732, 917, 13, 82, 957],\n",
              " [375, 519, 510, 704, 148, 44, 193, 453, 420],\n",
              " [278, 90, 131, 276, 916, 611, 677, 491, 97, 959, 621, 609],\n",
              " [128, 682, 91, 833, 221, 628, 521, 692, 418, 161, 923, 133, 370],\n",
              " [134, 413, 295, 402, 380, 459],\n",
              " [321, 775, 516, 159, 336, 839],\n",
              " [417, 123, 516, 781, 499, 227, 11, 309, 717, 338, 498],\n",
              " [560, 521, 373, 609, 928, 644, 245, 856, 547, 47, 364, 706],\n",
              " [962, 732, 708, 703, 708, 895, 162, 2, 140, 179],\n",
              " [540, 720, 166, 156, 502, 151, 157, 915, 619, 520],\n",
              " [20, 294, 8, 236, 780, 808, 49, 18, 527],\n",
              " [938, 490, 634, 175, 134, 152, 886, 141, 158, 650, 57, 160],\n",
              " [597, 228, 161, 419, 327, 280],\n",
              " [537, 479, 623, 150, 214, 740, 189, 62, 528, 360, 17, 135, 64, 741],\n",
              " [377, 493, 666, 145, 161, 235, 792, 775, 433, 519, 956, 486, 751],\n",
              " [827, 224, 520, 791, 760, 663, 322, 454, 310],\n",
              " [910, 211, 112, 188, 625, 200, 328],\n",
              " [570, 152, 607, 404, 522, 37],\n",
              " [837, 693, 194, 900, 568, 504, 114],\n",
              " [522, 325, 942, 214, 139, 475, 35, 188, 844, 678, 205, 26],\n",
              " [823, 887, 233, 93, 517, 122, 302],\n",
              " [478, 666, 912, 733, 407, 262, 393, 108, 410, 448, 378],\n",
              " [522, 692, 165, 552, 187, 335, 501],\n",
              " [607, 967, 200, 236, 454, 674, 152, 210, 180, 685, 836],\n",
              " [920, 800, 680, 44, 10, 889, 233, 169, 453, 559, 214],\n",
              " [384, 427, 164, 308, 180, 883, 583, 358, 190, 483, 24, 626],\n",
              " [301, 139, 165, 755, 471, 562, 699, 689],\n",
              " [374, 53, 21, 580, 135, 344, 701, 191],\n",
              " [243, 205, 94, 810, 84, 116, 44, 695, 120, 55, 500],\n",
              " [717, 48, 113, 958, 813, 132, 317, 121, 198],\n",
              " [422, 134, 478, 406, 589, 449, 734, 523, 398, 173],\n",
              " [835, 393, 691, 861, 367, 484],\n",
              " [950, 69, 893, 69, 581, 231, 502, 363, 820, 507],\n",
              " [45, 440, 263, 121, 295, 20, 70, 667, 162, 197],\n",
              " [566, 322, 464, 817, 682, 260, 211, 937, 946, 109, 797, 123],\n",
              " [469, 569, 778, 377, 483, 810, 74, 959, 171, 592, 616],\n",
              " [157, 35, 300, 9, 654, 871, 751],\n",
              " [365, 849, 105, 835, 237, 529, 617, 427, 256, 953, 244],\n",
              " [328, 503, 781, 674, 878, 566, 631, 721, 554, 700, 808, 286, 467],\n",
              " [828, 846, 778, 60, 782, 656, 956, 953, 114, 275, 663, 837, 481],\n",
              " [832, 615, 642, 117, 630, 426, 334, 238, 616, 735, 424, 356],\n",
              " [64, 419, 589, 258, 641, 809, 699],\n",
              " [711, 136, 353, 522, 836, 595, 468, 193, 528, 784],\n",
              " [156, 862, 820, 259, 153, 101, 257, 804, 529, 934, 113, 152],\n",
              " [492, 757, 319, 546, 505, 869, 534, 275],\n",
              " [84, 366, 145, 308, 345, 206, 326, 501, 714],\n",
              " [187, 607, 293, 629, 400, 349, 206, 351, 189, 318, 624, 462],\n",
              " [68, 184, 870, 873, 231, 218, 670, 724],\n",
              " [688, 332, 165, 602, 919, 315, 350, 202, 330, 548, 362],\n",
              " [671, 437, 26, 707, 605, 96, 45, 119, 610, 381],\n",
              " [553, 814, 597, 848, 96, 69, 182, 48, 967],\n",
              " [335, 21, 460, 52, 804, 393, 454, 79, 460, 524, 832, 418],\n",
              " [374, 532, 829, 434, 965, 478, 674, 332, 491, 687, 854, 265, 798],\n",
              " [201, 476, 812, 763, 106, 294, 911, 859, 715],\n",
              " [169, 572, 52, 392, 182, 542, 111, 848, 741, 20, 84, 726],\n",
              " [660, 359, 577, 449, 347, 918, 354, 657, 435, 838, 681, 75, 514],\n",
              " [95, 305, 877, 679, 76, 6, 549],\n",
              " [667, 954, 471, 920, 884, 155, 803, 779, 514, 16],\n",
              " [630, 871, 516, 278, 618, 232, 665, 103, 371, 969, 539, 587, 92],\n",
              " [802, 324, 382, 803, 276, 291, 174, 366, 571, 723, 594],\n",
              " [127, 566, 288, 36, 700, 7],\n",
              " [413, 720, 783, 255, 866, 417, 914, 500, 261],\n",
              " [688, 496, 351, 519, 65, 93],\n",
              " [526, 494, 715, 315, 410, 487],\n",
              " [887, 672, 819, 106, 88, 206],\n",
              " [702, 124, 19, 51, 126, 502, 451],\n",
              " [585, 158, 540, 629, 247, 764, 513, 392, 248, 702, 294, 268],\n",
              " [657, 675, 168, 278, 335, 539, 716, 735],\n",
              " [10, 623, 526, 432, 969, 819, 553, 653, 62, 415, 455, 235],\n",
              " [498, 905, 380, 603, 215, 348],\n",
              " [761, 69, 482, 702, 26, 125, 164, 621, 15, 893],\n",
              " [838, 315, 700, 642, 826, 269, 737, 519, 675],\n",
              " [363, 929, 586, 440, 302, 95, 511],\n",
              " [512, 458, 253, 674, 487, 506, 189],\n",
              " [56, 430, 31, 643, 383, 31, 53, 803, 167, 38, 732],\n",
              " [648, 359, 318, 778, 22, 69, 66, 504, 166],\n",
              " [239, 661, 950, 3, 208, 358, 613],\n",
              " [706, 158, 853, 81, 746, 261, 227, 205, 347, 208],\n",
              " [891, 632, 136, 34, 348, 148, 76, 14],\n",
              " [289, 837, 16, 259, 529, 342, 558, 744, 244, 258, 699, 54],\n",
              " [136, 639, 830, 378, 13, 168, 900, 139],\n",
              " [199, 671, 649, 573, 261, 453, 408, 499, 757],\n",
              " [7, 342, 745, 47, 728, 867, 237, 209, 199, 386, 5],\n",
              " [140, 418, 669, 628, 425, 152, 266, 433, 191, 620, 243, 476, 116],\n",
              " [579, 433, 712, 6, 323, 211, 91, 524, 499, 135],\n",
              " [533, 830, 511, 903, 430, 651, 860, 191, 557, 840],\n",
              " [190, 746, 241, 217, 528, 8, 691],\n",
              " [486, 753, 500, 639, 621, 620, 637, 140, 494, 116, 566, 23],\n",
              " [944, 921, 711, 135, 394, 755, 274],\n",
              " [232, 459, 114, 393, 630, 837, 748, 624, 861, 764, 454, 35, 629],\n",
              " [460, 252, 818, 170, 856, 318, 96, 16, 734, 145],\n",
              " [764, 91, 676, 780, 46, 219],\n",
              " [727, 78, 17, 830, 329, 405, 776, 487, 267, 515, 291, 346, 788],\n",
              " [899, 121, 45, 454, 367, 875],\n",
              " [851, 345, 47, 263, 842, 375, 402],\n",
              " [70, 813, 400, 119, 48, 274, 294],\n",
              " [80, 587, 97, 521, 620, 829, 417, 853, 7, 331, 133],\n",
              " [261, 410, 961, 118, 17, 1, 443, 272, 1, 649, 611, 722, 439, 204],\n",
              " [849, 300, 861, 67, 58, 881, 515, 809, 20, 720, 332, 243],\n",
              " [186, 850, 479, 11, 296, 4, 770, 282],\n",
              " [829, 15, 418, 207, 752, 729, 530, 175, 97],\n",
              " [669, 211, 956, 939, 797, 933],\n",
              " [275, 935, 506, 612, 498, 526, 848, 75, 180, 163, 558, 787, 56],\n",
              " [315, 157, 687, 627, 500, 290, 83, 558],\n",
              " [827, 607, 33, 211, 761, 614, 792, 751, 715],\n",
              " [562, 577, 722, 43, 705, 125, 316, 342, 947, 448, 821],\n",
              " [582, 219, 172, 389, 835, 4, 825, 575, 177, 379, 382, 871, 38],\n",
              " [102, 191, 682, 131, 133, 156, 147, 230, 62, 258, 783, 919, 379],\n",
              " [169, 69, 284, 437, 553, 961, 886, 183],\n",
              " [151, 301, 175, 372, 667, 3, 317, 873, 830, 25],\n",
              " [727, 952, 455, 111, 311, 112, 935, 157, 224, 731, 547, 637],\n",
              " [509, 315, 20, 247, 222, 720, 616, 762],\n",
              " [225, 30, 426, 224, 579, 288, 777, 498, 220, 742, 753, 533],\n",
              " [329, 665, 24, 757, 262, 333, 159, 754, 274, 340, 304],\n",
              " [565, 314, 99, 398, 625, 253, 736],\n",
              " [170, 130, 846, 869, 688, 359, 92],\n",
              " [255, 411, 829, 601, 137, 815],\n",
              " [589, 12, 794, 747, 33, 805, 17, 110, 883, 841, 899],\n",
              " [475, 26, 827, 95, 640, 784, 319, 779, 485, 97],\n",
              " [100, 67, 31, 761, 198, 633, 342, 67, 64, 966, 779],\n",
              " [210, 397, 296, 185, 866, 887, 730, 844, 693, 737, 535, 514, 632],\n",
              " [230, 535, 262, 693, 949, 893, 172, 423, 275, 689, 341],\n",
              " [711, 29, 439, 796, 770, 700, 810, 622, 854, 467, 774, 324],\n",
              " [732, 382, 236, 227, 426, 963, 954, 590, 851, 821, 16, 480],\n",
              " [466, 638, 717, 539, 773, 664, 454, 279, 553, 153, 909, 64, 491],\n",
              " [648, 783, 750, 293, 844, 521, 440, 267, 300, 54],\n",
              " [473, 200, 368, 824, 507, 934, 651, 194],\n",
              " [5, 197, 81, 823, 479, 121, 253, 751, 568, 574, 835],\n",
              " [87, 232, 131, 174, 475, 200, 202, 487, 168, 51, 182, 620],\n",
              " [87, 167, 786, 646, 810, 592, 541],\n",
              " [523, 638, 469, 567, 846, 395, 629, 109, 565, 682, 681],\n",
              " [780, 319, 52, 135, 43, 433, 123, 241, 430, 501, 34, 685, 888],\n",
              " [12, 883, 561, 934, 89, 348, 892, 47, 493, 768, 795, 182, 622],\n",
              " [192, 356, 914, 783, 632, 618, 406, 555, 528],\n",
              " [20, 871, 50, 527, 665, 675, 328, 49, 767, 223, 137, 37],\n",
              " [779, 850, 744, 537, 525, 358, 315, 712, 361, 201],\n",
              " [928, 713, 691, 92, 170, 202, 766],\n",
              " [587, 683, 374, 198, 392, 504],\n",
              " [694, 225, 631, 938, 673, 380, 337, 702, 312, 628, 721],\n",
              " [382, 894, 672, 751, 672, 561, 608, 373, 526],\n",
              " [748, 709, 279, 775, 413, 410, 449],\n",
              " [28, 592, 155, 71, 255, 202, 277, 190],\n",
              " [431, 894, 49, 800, 538, 431],\n",
              " [679, 497, 195, 219, 186, 232, 302, 226, 910, 37, 784, 88],\n",
              " [318, 275, 459, 579, 207, 601, 17],\n",
              " [457, 947, 745, 679, 852, 452, 207, 151, 864, 583],\n",
              " [493, 309, 48, 503, 175, 110, 474],\n",
              " [9, 812, 245, 627, 752, 330, 70, 153, 153, 520, 506, 866],\n",
              " [951, 767, 269, 443, 590, 718, 149, 872, 306, 396],\n",
              " [558, 787, 290, 542, 251, 947, 574, 172, 116, 11],\n",
              " [157, 108, 653, 101, 822, 722, 699, 439, 96, 466, 623, 678, 798],\n",
              " [174, 213, 749, 193, 547, 286, 675],\n",
              " [421, 771, 539, 617, 914, 16],\n",
              " [31, 206, 673, 156, 884, 639, 675, 195, 371, 589, 100],\n",
              " [224, 15, 527, 826, 904, 423, 855, 542],\n",
              " [152, 10, 40, 63, 610, 203, 290, 231],\n",
              " [456, 839, 98, 802, 302, 748, 131, 348, 301, 653, 64, 702],\n",
              " [86, 703, 778, 290, 223, 453],\n",
              " [204, 52, 892, 134, 244, 551],\n",
              " [364, 704, 456, 754, 335, 673, 354, 779, 765, 154, 129],\n",
              " [376, 563, 667, 855, 703, 726, 834, 28, 16, 864, 783, 388, 546],\n",
              " [854, 302, 575, 341, 970, 326],\n",
              " [4, 836, 668, 622, 382, 353, 500, 151, 953, 353, 119, 86],\n",
              " [408, 552, 468, 44, 640, 106, 268],\n",
              " [340, 135, 159, 33, 733, 803, 879, 279, 829],\n",
              " [113, 729, 136, 325, 305, 526, 612, 13, 785, 293, 519, 242],\n",
              " [837, 173, 134, 371, 232, 55, 92, 249],\n",
              " [328, 643, 505, 819, 874, 416, 201, 468, 945, 562],\n",
              " [91, 351, 208, 509, 119, 591, 726, 709, 160, 62],\n",
              " [314, 62, 378, 598, 245, 732, 825, 167, 291],\n",
              " [67, 929, 647, 429, 144, 579, 798, 268, 663, 644],\n",
              " [539, 113, 712, 548, 449, 263, 9, 169],\n",
              " [646, 34, 491, 908, 686, 341, 312, 513, 395, 685, 541, 759],\n",
              " [492, 312, 670, 94, 970, 194, 417, 452, 786, 113, 553, 133, 927],\n",
              " [510, 83, 627, 559, 638, 490, 461, 264, 300, 52, 99],\n",
              " [515, 137, 670, 463, 507, 756, 620, 813, 741, 490],\n",
              " [883, 75, 826, 68, 243, 461, 94, 402, 370, 186, 813],\n",
              " [403, 533, 923, 940, 913, 803, 108],\n",
              " [63, 915, 92, 317, 558, 375, 104, 193, 782, 484],\n",
              " [584, 660, 755, 28, 693, 772, 502, 948, 344],\n",
              " [743, 252, 768, 616, 183, 157, 561, 564, 603, 408, 74, 30],\n",
              " [860, 141, 827, 230, 157, 282, 162],\n",
              " [123, 210, 167, 189, 19, 50, 426, 619, 521, 367],\n",
              " [660, 564, 58, 560, 233, 647, 840, 58, 329, 583, 188, 57],\n",
              " [179, 57, 37, 141, 390, 722, 490, 638, 29, 690],\n",
              " [181, 950, 552, 374, 952, 314, 138, 328, 468, 811, 293, 634, 376],\n",
              " [315, 723, 99, 732, 890, 166, 828, 734, 768, 54],\n",
              " [215, 955, 12, 250, 132, 203, 921, 782],\n",
              " [228, 125, 592, 492, 788, 542, 368, 265, 432, 283, 38],\n",
              " [258, 547, 659, 229, 322, 838, 903],\n",
              " [311, 243, 765, 456, 338, 50, 458, 867],\n",
              " [380, 565, 679, 717, 398, 260],\n",
              " [879, 154, 430, 51, 200, 24, 628, 45],\n",
              " [671, 617, 253, 896, 874, 113, 25, 27, 174, 193, 39],\n",
              " [497, 140, 626, 742, 417, 422],\n",
              " [606, 146, 714, 477, 441, 235, 148],\n",
              " [32, 181, 356, 438, 71, 266],\n",
              " [378, 170, 478, 90, 907, 848],\n",
              " [26, 963, 457, 257, 852, 96, 388, 498],\n",
              " [673, 114, 246, 393, 196, 786, 540, 878, 33, 743, 222],\n",
              " [195, 102, 348, 231, 531, 126, 4, 91],\n",
              " [849, 303, 762, 77, 559, 89, 156, 51, 657, 637, 710, 779],\n",
              " [339, 232, 957, 106, 42, 858, 91, 119, 154, 724],\n",
              " [480, 754, 890, 505, 354, 956, 151, 136, 35, 161, 766, 310],\n",
              " [922, 457, 158, 712, 481, 399, 472],\n",
              " [578, 404, 187, 103, 20, 942, 820, 62, 396, 356, 702, 593, 668],\n",
              " [382, 786, 838, 794, 179, 763, 746],\n",
              " [369, 383, 511, 600, 712, 245, 357, 759, 358, 506, 394, 857, 736],\n",
              " [146, 697, 205, 12, 649, 661, 444, 912, 27, 452],\n",
              " [908, 492, 307, 409, 673, 421, 156, 590, 710, 606, 667],\n",
              " [702, 752, 4, 353, 397, 273, 605, 649],\n",
              " [38, 574, 577, 278, 943, 252, 932, 52, 586],\n",
              " [601, 372, 82, 846, 105, 715, 27, 967, 396, 263, 546],\n",
              " [603, 895, 425, 167, 711, 762, 55],\n",
              " [626, 408, 331, 77, 820, 808, 275, 307, 662, 929],\n",
              " [563, 941, 384, 940, 119, 421, 356, 85, 785, 9],\n",
              " [346, 670, 109, 140, 457, 634, 198, 138, 10],\n",
              " [146, 907, 506, 316, 804, 230, 94, 239, 791],\n",
              " [881, 487, 202, 235, 339, 346, 737],\n",
              " [442, 564, 887, 507, 528, 294, 49, 617, 471, 574],\n",
              " [564, 221, 367, 663, 822, 597, 681, 98, 74, 373],\n",
              " [271, 442, 517, 384, 787, 309, 784, 161],\n",
              " [479, 258, 381, 605, 297, 600, 544, 20, 732, 76, 232, 577],\n",
              " [411, 783, 480, 499, 217, 428, 597, 449],\n",
              " [285, 52, 556, 377, 562, 166, 175],\n",
              " [872, 925, 734, 570, 519, 242, 207],\n",
              " [968, 64, 665, 925, 494, 308],\n",
              " [593, 412, 892, 219, 436, 929, 12, 598, 658, 326, 596, 111, 659],\n",
              " [275, 962, 123, 487, 933, 686, 458, 249, 634, 632, 50],\n",
              " [911, 67, 387, 510, 631, 452, 127, 210, 359, 47, 766, 561],\n",
              " [389, 882, 809, 611, 150, 271, 384, 420, 575, 221, 646, 733],\n",
              " [822, 960, 279, 782, 330, 624, 650],\n",
              " [384, 371, 889, 734, 399, 155, 668, 148, 475, 716, 355, 112, 351],\n",
              " [761, 393, 957, 225, 48, 73, 869, 163, 482, 275],\n",
              " [667, 209, 853, 38, 663, 492, 919],\n",
              " [701, 279, 415, 525, 561, 530, 468, 654, 30, 854],\n",
              " [915, 385, 634, 437, 409, 618, 309, 551],\n",
              " [77, 41, 10, 346, 98, 749, 341, 126, 460, 61, 584, 899],\n",
              " [268, 206, 818, 19, 791, 487, 900, 570, 17, 516],\n",
              " [504, 313, 581, 679, 790, 188, 316, 567, 398, 415, 237, 418, 870],\n",
              " [790, 802, 619, 47, 746, 86, 171, 685],\n",
              " [443, 96, 790, 833, 606, 222, 766, 505, 770],\n",
              " [940, 324, 830, 746, 229, 606, 434, 696, 759, 768, 8],\n",
              " [568, 121, 104, 56, 468, 268, 295, 248, 372],\n",
              " [120, 171, 754, 279, 159, 178],\n",
              " [184, 71, 335, 326, 214, 706, 211, 220, 319, 97, 34],\n",
              " [273, 529, 39, 471, 773, 470, 915, 86, 833, 266, 88],\n",
              " [129, 254, 228, 701, 862, 958, 370, 400, 292, 970, 537],\n",
              " [384, 321, 134, 861, 854, 563, 219, 516, 851, 590, 683, 909, 278],\n",
              " [781, 506, 715, 190, 890, 269, 395, 507, 513, 909, 83, 356],\n",
              " [758, 73, 630, 695, 243, 709, 345, 869],\n",
              " [132, 543, 180, 361, 747, 137, 590],\n",
              " [130, 902, 294, 706, 431, 1, 609, 64, 28],\n",
              " [792, 618, 113, 257, 572, 674, 812, 157, 508, 846, 880, 141],\n",
              " [171, 238, 600, 603, 877, 65, 286, 33, 831],\n",
              " [27, 842, 389, 370, 881, 521, 113, 890, 816],\n",
              " [639, 161, 149, 815, 106, 441, 240, 740, 170],\n",
              " [598, 656, 491, 588, 527, 272, 413, 764, 888, 879, 750],\n",
              " [933, 799, 872, 52, 212, 598, 690],\n",
              " [895, 286, 719, 653, 400, 60, 229],\n",
              " [439, 32, 889, 148, 46, 392, 965, 438, 574],\n",
              " [439, 144, 779, 854, 530, 7, 342, 106, 592, 58, 288, 15],\n",
              " [795, 649, 333, 795, 691, 572, 329, 313, 228, 611],\n",
              " [167, 159, 46, 413, 860, 88, 599, 176],\n",
              " [655, 658, 306, 709, 116, 210, 665],\n",
              " [378, 85, 626, 624, 69, 378, 527, 590, 14, 77, 70],\n",
              " [909, 516, 25, 273, 614, 252],\n",
              " [272, 365, 404, 71, 271, 778, 842, 509, 862, 445, 465, 705],\n",
              " [334, 236, 735, 583, 63, 697, 393, 87, 660, 646, 232, 189],\n",
              " [692, 746, 936, 151, 220, 694, 825, 191, 790, 658, 669, 422, 851],\n",
              " [669, 892, 297, 426, 754, 307, 137],\n",
              " [128, 723, 428, 343, 827, 63, 586, 786, 130, 191, 890, 373],\n",
              " [299, 642, 233, 336, 669, 886, 140, 732, 454, 445, 859],\n",
              " [887, 700, 952, 321, 12, 925, 859, 93, 3, 909],\n",
              " [670, 604, 389, 275, 103, 897, 937, 117, 66, 341],\n",
              " [19, 724, 702, 766, 377, 647, 189, 97, 139, 494],\n",
              " [491, 870, 187, 63, 393, 129, 840, 491, 441, 208, 753],\n",
              " [229, 313, 630, 421, 877, 457, 857],\n",
              " [122, 679, 783, 900, 731, 952, 129],\n",
              " [672, 719, 924, 349, 741, 321, 931, 737, 775, 373],\n",
              " [206, 635, 748, 474, 613, 431, 67, 452, 713],\n",
              " [879, 111, 781, 81, 130, 775, 434, 14, 439],\n",
              " [325, 438, 589, 45, 60, 412, 254],\n",
              " [513, 650, 61, 908, 487, 620, 212, 158],\n",
              " [149, 792, 923, 631, 703, 893, 214, 82],\n",
              " [234, 91, 783, 93, 617, 511, 437, 205, 757, 638, 404, 95],\n",
              " [2, 13, 150, 628, 360, 695, 161, 727, 298, 466, 644],\n",
              " [438, 39, 272, 565, 538, 655, 394, 338],\n",
              " [122, 550, 643, 700, 295, 161, 432, 83, 791, 745],\n",
              " [530, 899, 966, 927, 529, 853, 37, 398, 414, 631, 65, 445],\n",
              " [143, 649, 363, 482, 309, 554],\n",
              " [310, 683, 609, 158, 651, 445, 128, 463, 424, 290, 376, 326, 582],\n",
              " [605, 538, 287, 59, 750, 604, 61, 174, 27],\n",
              " [822, 127, 93, 436, 251, 927, 898, 542, 747],\n",
              " [473, 176, 97, 34, 321, 419, 283],\n",
              " [528, 165, 176, 261, 62, 121, 181, 692],\n",
              " [141, 401, 549, 293, 94, 779, 4, 104, 394, 339, 508, 563, 597],\n",
              " [778, 737, 91, 649, 410, 592],\n",
              " [136, 66, 872, 759, 928, 955, 899, 137, 233, 100, 191, 249, 941, 321],\n",
              " [335, 797, 717, 869, 897, 388, 838, 187, 818],\n",
              " [309, 853, 616, 138, 465, 36, 263],\n",
              " [7, 553, 503, 307, 833, 619, 580, 226, 218, 423],\n",
              " [746, 837, 474, 375, 181, 6, 136, 184, 684, 501],\n",
              " [514, 36, 960, 550, 194, 200, 435, 205, 329],\n",
              " [744, 152, 750, 844, 607, 473],\n",
              " [249, 735, 611, 324, 268, 807, 213, 724, 520, 699, 943, 310],\n",
              " [105, 209, 17, 701, 255, 13, 270, 37, 539, 653, 338, 898, 33],\n",
              " [847, 80, 264, 650, 120, 921, 354, 120, 214, 445, 597, 314, 589],\n",
              " [463, 401, 437, 538, 428, 146, 866],\n",
              " [336, 211, 56, 592, 736, 56],\n",
              " [412, 464, 852, 874, 534, 565, 416, 708, 118, 218, 722],\n",
              " [684, 691, 306, 248, 458, 660, 154, 222, 262, 56, 36],\n",
              " [382, 143, 375, 710, 700, 101, 10],\n",
              " [709, 49, 545, 313, 140, 10, 99, 310, 796, 152, 590],\n",
              " [389, 335, 904, 755, 522, 240, 218, 771],\n",
              " [296, 143, 866, 655, 920, 493, 733, 390, 752, 552, 22, 810],\n",
              " [121, 61, 446, 376, 265, 141, 577, 936, 291],\n",
              " [647, 678, 447, 83, 298, 495, 475],\n",
              " [35, 670, 348, 19, 495, 57],\n",
              " [347, 516, 434, 672, 438, 754, 542, 684, 169, 68],\n",
              " [933, 763, 910, 623, 118, 290, 876, 349, 567, 488, 477, 591, 112],\n",
              " [648, 286, 954, 271, 829, 279, 726, 932, 171, 381, 892, 774],\n",
              " [380, 429, 32, 348, 76, 840, 434, 916, 393, 215],\n",
              " [194, 293, 476, 966, 828, 38, 465],\n",
              " [160, 485, 225, 131, 728, 511],\n",
              " [142, 538, 395, 819, 36, 883, 703],\n",
              " [625, 813, 514, 296, 410, 110, 671],\n",
              " [930, 737, 438, 273, 653, 125],\n",
              " [468, 789, 788, 868, 41, 896, 29],\n",
              " [961, 482, 955, 390, 630, 390, 151, 39, 884, 122, 492],\n",
              " [5, 544, 464, 48, 42, 913, 845, 18, 414, 504],\n",
              " [369, 774, 551, 411, 519, 59],\n",
              " [8, 177, 876, 901, 588, 449, 410, 784],\n",
              " [809, 210, 490, 740, 657, 694, 643, 8, 474, 593, 526],\n",
              " [610, 944, 13, 865, 581, 910, 161, 426, 771],\n",
              " [363, 192, 694, 208, 641, 305, 268, 126, 363, 372],\n",
              " [14, 889, 749, 194, 826, 66, 259, 21, 641, 369],\n",
              " [127, 173, 305, 172, 174, 141, 161],\n",
              " [843, 567, 157, 558, 184, 734, 718, 130],\n",
              " [889, 313, 177, 716, 627, 791, 723, 674, 928],\n",
              " [347, 741, 533, 841, 236, 603, 785, 500, 454, 96, 195, 127],\n",
              " [834, 971, 508, 180, 818, 88, 636, 85, 72, 394, 858, 902, 127],\n",
              " [898, 560, 139, 859, 739, 293, 27, 733, 408, 356, 574, 583],\n",
              " [386, 94, 541, 101, 142, 244, 340, 288, 50, 941, 761],\n",
              " [175, 114, 879, 560, 462, 83, 302, 507, 438, 712, 148],\n",
              " [112, 467, 347, 149, 737, 450, 17, 305, 727, 449, 152, 710, 842],\n",
              " [789, 349, 483, 341, 87, 618, 904, 9, 204, 534, 250, 807],\n",
              " [29, 525, 652, 145, 810, 745, 837],\n",
              " [182, 738, 221, 480, 457, 750, 576],\n",
              " [838, 482, 255, 604, 403, 346, 96, 675],\n",
              " [717, 510, 223, 72, 841, 773, 61],\n",
              " [602, 630, 752, 317, 428, 559, 111, 667, 110],\n",
              " [151, 218, 661, 968, 296, 386, 411, 243, 872, 160, 76, 32],\n",
              " [211, 377, 147, 639, 136, 114],\n",
              " [103, 533, 149, 351, 537, 187, 794, 23, 201, 90, 864, 957],\n",
              " [288, 943, 876, 109, 439, 646, 915],\n",
              " [500, 609, 284, 63, 208, 566, 95, 277, 388, 105, 169, 655],\n",
              " [409, 814, 886, 10, 336, 787, 676, 32],\n",
              " [952, 520, 73, 846, 282, 469, 348, 617, 883, 375, 511],\n",
              " [520, 416, 243, 807, 83, 478, 868, 299, 815, 45, 629, 769],\n",
              " [95, 657, 58, 452, 379, 427],\n",
              " [487, 407, 388, 65, 912, 886, 315, 40, 191],\n",
              " [623, 289, 506, 208, 891, 699, 224, 675, 529, 780, 843],\n",
              " [68, 38, 454, 737, 171, 369, 578, 454, 235, 115, 474, 15, 913],\n",
              " [784, 867, 817, 183, 675, 747],\n",
              " [599, 451, 699, 224, 851, 443, 699, 31, 314, 186, 834],\n",
              " [351, 963, 376, 355, 807, 661, 500],\n",
              " [180, 4, 269, 787, 287, 114, 581, 673],\n",
              " [732, 46, 40, 764, 882, 269],\n",
              " [458, 662, 698, 958, 504, 607, 513, 354, 474],\n",
              " [256, 796, 291, 166, 400, 281, 246, 399, 267, 366, 635],\n",
              " [162, 677, 96, 372, 328, 752, 538, 382, 820, 567],\n",
              " [141, 690, 536, 460, 489, 159, 82, 353, 16, 170],\n",
              " [355, 54, 204, 138, 780, 930, 921, 389, 828, 294, 7, 252],\n",
              " [687, 607, 960, 915, 291, 638, 576, 810, 332, 780, 435, 621, 410],\n",
              " [446, 39, 381, 423, 625, 718, 523, 68, 196, 945, 528],\n",
              " [145, 964, 699, 884, 488, 493, 151, 957],\n",
              " [474, 132, 540, 527, 228, 886],\n",
              " [904, 754, 221, 855, 927, 328, 279, 554, 258, 337, 221],\n",
              " [781, 386, 676, 614, 899, 661, 148],\n",
              " [760, 922, 791, 665, 570, 611],\n",
              " [181, 651, 218, 184, 437, 145],\n",
              " [698, 395, 491, 597, 846, 76, 505, 531, 368, 304, 844, 861],\n",
              " [920, 472, 165, 664, 863, 126, 881, 841, 866],\n",
              " [483, 532, 451, 420, 761, 773, 735, 69, 286],\n",
              " [607, 723, 957, 840, 637, 330],\n",
              " [438, 347, 402, 405, 945, 734, 173, 758, 511, 184, 938, 282, 348],\n",
              " [509, 265, 109, 325, 615, 706, 556, 558, 223, 464, 43, 869],\n",
              " [76, 66, 147, 597, 584, 621, 844, 488, 216, 139, 391],\n",
              " [935, 258, 3, 636, 620, 830, 854, 406],\n",
              " [114, 520, 43, 891, 104, 432, 279, 313, 348],\n",
              " [331, 453, 588, 5, 949, 562, 856, 264, 131, 426, 269, 241, 294],\n",
              " [694, 837, 337, 710, 500, 960, 75],\n",
              " [901, 952, 163, 709, 893, 453, 76],\n",
              " [422, 643, 244, 43, 231, 407, 113, 628, 69, 478, 465, 371, 277, 422],\n",
              " [462, 393, 180, 477, 205, 403, 502, 236, 930, 938, 579, 406, 317],\n",
              " [115, 669, 542, 327, 283, 8, 364],\n",
              " [209, 434, 468, 943, 325, 79, 689],\n",
              " [614, 406, 328, 401, 689, 133, 853, 804, 899, 893, 203, 743],\n",
              " [680, 858, 803, 2, 870, 855],\n",
              " [434, 179, 214, 301, 383, 335, 629, 693, 480, 441, 235, 350],\n",
              " [488, 315, 765, 456, 449, 781, 955, 106, 148, 103, 350, 48, 139],\n",
              " [151, 116, 256, 57, 230, 849, 479],\n",
              " [607, 711, 958, 392, 502, 907, 254, 106, 836, 386, 426],\n",
              " [961, 183, 556, 729, 478, 171, 20],\n",
              " [761, 811, 835, 509, 794, 948, 274, 283, 159, 233],\n",
              " [746, 828, 767, 645, 665, 455, 630, 745, 340],\n",
              " [530, 230, 824, 502, 513, 49, 2, 351, 736, 349, 12, 194],\n",
              " [696, 349, 485, 204, 667, 355, 547, 286, 563, 347, 284, 551],\n",
              " [201, 22, 868, 778, 455, 302, 746, 107, 458],\n",
              " [445, 241, 806, 108, 165, 184, 619, 103, 97, 60],\n",
              " [453, 839, 151, 231, 725, 477, 669, 774],\n",
              " [350, 940, 781, 176, 314, 143, 419, 301, 555, 131, 674, 632, 162],\n",
              " [17, 642, 290, 210, 722, 213, 640],\n",
              " [87, 756, 487, 325, 853, 929, 284],\n",
              " [57, 478, 677, 789, 258, 37, 467, 640, 704],\n",
              " [788, 658, 230, 732, 586, 204, 21, 416, 319],\n",
              " [803, 962, 237, 179, 436, 596, 770, 578, 551],\n",
              " [868, 81, 575, 516, 366, 707, 35, 714, 569, 882, 856, 439],\n",
              " [588, 242, 707, 340, 254, 456, 935],\n",
              " [62, 364, 774, 80, 37, 594, 623, 189],\n",
              " [399, 951, 52, 590, 229, 831, 385, 87, 518, 842, 674, 919, 15],\n",
              " [379, 824, 616, 336, 962, 105, 58, 833, 916],\n",
              " [506, 218, 213, 630, 91, 944, 948, 273, 398],\n",
              " [442, 106, 299, 218, 156, 328, 942, 506, 73, 159, 383, 471, 862],\n",
              " [285, 701, 407, 288, 230, 20, 8, 887, 753, 873, 686, 921, 104],\n",
              " [756, 103, 207, 815, 787, 323, 152, 458, 254, 16, 720, 194],\n",
              " [588, 824, 1, 758, 237, 967],\n",
              " [133, 278, 338, 850, 328, 781, 381, 673, 167, 89],\n",
              " [834, 265, 953, 741, 450, 602, 747, 90, 374, 275],\n",
              " [97, 611, 176, 47, 658, 597, 41, 397, 766, 159, 834, 417, 182],\n",
              " [92, 486, 164, 371, 421, 540, 386, 281, 623, 675, 459, 346, 966],\n",
              " [934, 518, 120, 96, 244, 418, 912, 356, 58, 107, 651, 160, 276],\n",
              " [584, 172, 402, 510, 806, 168, 223, 599, 73, 439, 876],\n",
              " [243, 366, 556, 933, 213, 316, 844, 632, 891, 201, 913],\n",
              " [594, 502, 242, 95, 79, 909, 530, 361, 766, 420, 465, 591],\n",
              " [461, 390, 340, 735, 752, 179, 555, 49, 488, 940, 549, 830, 839],\n",
              " [905, 472, 168, 543, 586, 347, 873, 700, 850, 271, 578, 738, 333],\n",
              " [931, 262, 312, 898, 185, 238, 318, 560, 324, 27],\n",
              " [734, 348, 421, 466, 429, 316, 221],\n",
              " [736, 790, 489, 705, 344, 811, 625, 373, 531, 285, 668, 668],\n",
              " [349, 495, 310, 771, 792, 117, 723, 599, 192, 218],\n",
              " [701, 240, 404, 13, 722, 950, 590, 812, 86, 672],\n",
              " [570, 240, 667, 829, 87, 168, 601, 34, 699, 547, 208, 243, 16],\n",
              " [51, 21, 709, 271, 306, 341, 907, 381],\n",
              " [505, 433, 23, 15, 575, 426, 779, 806],\n",
              " [529, 73, 128, 877, 612, 840, 850, 614, 426],\n",
              " [314, 316, 438, 500, 770, 716, 221, 183, 615, 441, 970],\n",
              " [474, 145, 718, 627, 334, 801, 312],\n",
              " [686, 246, 379, 116, 963, 640, 811, 312, 196, 454, 563, 770, 876],\n",
              " [74, 372, 743, 207, 64, 132],\n",
              " [495, 554, 655, 258, 544, 853, 476, 156, 530, 455, 61, 349, 42],\n",
              " [885, 767, 953, 374, 761, 164, 155],\n",
              " [343, 301, 462, 921, 631, 124, 823, 280],\n",
              " [463, 597, 753, 317, 836, 456, 21, 129, 112, 823, 211],\n",
              " [920, 405, 959, 40, 99, 472, 16, 47, 153, 874],\n",
              " [191, 913, 111, 942, 796, 77, 391, 534, 290, 721],\n",
              " [125, 626, 178, 206, 175, 435, 794, 74, 221, 830, 208, 960, 252, 420],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "AsjeN0OFzYi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences=pad_sequences(sequences,maxlen=20)"
      ],
      "metadata": {
        "id": "jDMltxrdzGw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrD7GSRRzWeW",
        "outputId": "c9868ee6-240f-489f-a1cb-ef9459a4d993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        738, 228, 739, 821, 378, 191, 650],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 330,  29, 379, 487,\n",
              "        192, 782, 229, 740, 282,  42, 822]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test=padded_sequences[:train_size],padded_sequences[train_size:]"
      ],
      "metadata": {
        "id": "fJtTuusvz28u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIbFwvRt0Mn3",
        "outputId": "62686d2c-cb72-40b0-9073-425d636b5a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN,Dense"
      ],
      "metadata": {
        "id": "b249eQhJ0O5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_one_to_one=Sequential([\n",
        "                             Embedding(input_dim=5000,output_dim=64,input_length=20),\n",
        "                             SimpleRNN(64,return_sequences=False),\n",
        "                             Dense(1,activation=\"softmax\")\n",
        "                             ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAiVt-Y50gIy",
        "outputId": "0f2f48c8-e7ee-48cb-f2f3-98e70bd65cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_one_to_one.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "i0SAHiCo1DAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_one_to_one.fit(X_train,y_train,epochs=5,batch_size=32,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9g9n0j71lLw",
        "outputId": "7051ad82-470d-46b5-dd00-240c2f069e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5154 - loss: 0.6943 - val_accuracy: 0.4412 - val_loss: 0.7009\n",
            "Epoch 2/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4959 - loss: 0.5855 - val_accuracy: 0.4412 - val_loss: 0.7976\n",
            "Epoch 3/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4916 - loss: 0.2788 - val_accuracy: 0.4412 - val_loss: 1.1514\n",
            "Epoch 4/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5051 - loss: 0.0912 - val_accuracy: 0.4412 - val_loss: 1.8381\n",
            "Epoch 5/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4966 - loss: 0.0239 - val_accuracy: 0.4412 - val_loss: 2.1037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9af87ca530>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_one_to_one.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga0iDY4k3O-8",
        "outputId": "5e0f1637-a6cf-4210-898d-cd4562063788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 347ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994],\n",
              "       [0.99999994]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_one_to_many=Sequential([\n",
        "                             Embedding(input_dim=5000,output_dim=64,input_length=1),\n",
        "                             SimpleRNN(64,return_sequences=True),\n",
        "                             Dense(5000,activation=\"softmax\")\n",
        "                             ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZq3YKsT39gS",
        "outputId": "9b8b9789-1e75-4cbb-c5c2-aa4c481e53c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_gen=np.random.randint(1,5000,size=(5000,1))\n",
        "y_gen=np.random.randint(1,5000,size=(5000,10))"
      ],
      "metadata": {
        "id": "IFAylVnV4GuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_gen.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQThNz7c4Yuk",
        "outputId": "a65cdfeb-59cf-4255-91d1-abae0365e89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_gen.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyNHeIdF4aAi",
        "outputId": "4864432d-ab05-4818-a0d7-bc323ddf5d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMOY1ITG4eoq",
        "outputId": "58c13d79-a44f-44b1-83e1-864bc0a4d899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1999, 2564, 4435, ...,  658, 4498, 1938],\n",
              "       [3353, 3242, 1902, ..., 1094, 2857, 2992],\n",
              "       [ 732,  920, 1753, ..., 1310,  557, 2089],\n",
              "       ...,\n",
              "       [1300, 1749, 2522, ..., 2742, 2491, 4575],\n",
              "       [3562, 3147, 1336, ..., 3898, 2386, 2453],\n",
              "       [1479,  634, 3329, ..., 4015, 3430, 3095]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 10\n",
        "X_gen = np.random.randint(1, 5000, size=(5000, sequence_length))\n",
        "y_gen = np.random.randint(1, 5000, size=(5000, sequence_length))\n",
        "\n",
        "model_one_to_many = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64, input_length=sequence_length),\n",
        "    SimpleRNN(128, return_sequences=True),\n",
        "    Dense(5000, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_one_to_many.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "model_one_to_many.fit(X_gen, y_gen, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW_ieKW45ANL",
        "outputId": "47993646-0a79-4f67-f0ff-16a09c14f94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 167ms/step - loss: 8.5175\n",
            "Epoch 2/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 165ms/step - loss: 8.4288\n",
            "Epoch 3/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 164ms/step - loss: 8.0329\n",
            "Epoch 4/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 165ms/step - loss: 7.5369\n",
            "Epoch 5/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 164ms/step - loss: 7.0781\n",
            "Epoch 6/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 166ms/step - loss: 6.6738\n",
            "Epoch 7/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 166ms/step - loss: 6.3001\n",
            "Epoch 8/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 163ms/step - loss: 5.9667\n",
            "Epoch 9/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 162ms/step - loss: 5.6445\n",
            "Epoch 10/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 165ms/step - loss: 5.3385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9af950b760>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}